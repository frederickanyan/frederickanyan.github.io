[
  {
    "objectID": "quantposts/practical prelims/practical.html",
    "href": "quantposts/practical prelims/practical.html",
    "title": "Things to do before fitting a growth model",
    "section": "",
    "text": "Some practical preliminary steps are useful for performing longitudinal data analyses. Some preliminary steps might even already show whether the data will support your hypothesized growth function or to fit a different growth function. Here, I go through some of the practical things to do before performing longitudinal data analyses (using wide or long dataset).\n\n\n\n\n\n\nIt is important to consider whether the measured variables meet different measurement assumptions, including\n\n\n\n\nReliability of the measurement instrument over repeated observations since a good indication of reliability over repeated observations suggests longitudinal reliability of the instrument. Cronbach’s \\(α\\) at each time point can be calculated to show reliability of the measurement instrument. This, however, does not mean that there is reliable change within individuals over time.\nRelated to reliability of the measurement instrument is ensuring that the changes observed are true changes in individuals and not changes in the measurement instrument or changes in the meaning of the attribute under study over repeated observation. Measurement invariance testing can be used useful here, but could also be difficult when repeated observations spans over several years (ages) as the meaning of attributes/constructs may differ for people of different ages\n\n\n\nYou can read more about things to do before fitting growth models in the reference below:\n\nGrimm, K. J., Ram, N., & Estabrook, R. (2016). Growth modelling: Structural equation and multilevel modelling approaches. Guilford Publications.\n\nLoad packages\n\nCodesuppressPackageStartupMessages({\nlibrary(psych)  #For practical preliminaries: univariate and bivariate descriptive stats\nlibrary(tidyr) #For reshaping data\nlibrary(lcsm)   #For plotting longitudinal trajectories in a wide data set\nlibrary(ggplot2) #For plotting longitudinal trajectories in long data set\n})\n\nWarning: package 'psych' was built under R version 4.3.3\n\n\n\n\nWIDE DATASET\nLONG DATASET\n\n\n\n\nCode## Read data \ndata &lt;- read.csv(\"/Volumes/anyan-1/frederickanyan.github.io/quantpost_data/data.csv\")\n#Create new data set with only your main outcome variables\nlonely &lt;- data[, c(\"personid\", \"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\")]\n\n\n1. Examine univariate and bivariate statistics\n\nCode#Examine descriptive statistics.\ndescribe(lonely[, 2:6])#univariate descriptives\n\n      vars   n mean   sd median trimmed  mad min  max range skew kurtosis   se\nlone1    1 398 1.46 0.46   1.32    1.38 0.34   1 3.75  2.75 1.81     3.95 0.02\nlone2    2 395 1.47 0.52   1.31    1.38 0.31   1 5.00  4.00 2.22     7.22 0.03\nlone3    3 390 1.53 0.52   1.36    1.44 0.37   1 3.78  2.78 1.52     2.27 0.03\nlone4    4 413 1.35 0.47   1.22    1.25 0.25   1 4.92  3.92 3.05    12.75 0.02\nlone5    5 409 1.32 0.39   1.20    1.24 0.25   1 3.43  2.43 2.45     7.22 0.02\n\n\nFirst thing to notice from the descriptive statistics is the number and pattern of missing data. It can also be noticed that, the means and standard deviations show a simple pattern with increases in the feeling of loneliness from T1 through to T3, and begins to decline afterwards though to T5 coupled with increases in variation and then a decline after T3.\nIt can be noticed already from the means that a linear growth function might not accurately characterize the trajectory in the data.\n2. Describe covariance and correlation matrices\n\nCode#bivariate descriptives\ncov(lonely[, 2:6], use='pairwise.complete.obs') #covariance matrix\n\n           lone1      lone2      lone3      lone4      lone5\nlone1 0.21451070 0.14910019 0.09978644 0.08198277 0.05209327\nlone2 0.14910019 0.27059267 0.13796998 0.10077467 0.06904941\nlone3 0.09978644 0.13796998 0.27223396 0.10690494 0.08475463\nlone4 0.08198277 0.10077467 0.10690494 0.21720685 0.07542655\nlone5 0.05209327 0.06904941 0.08475463 0.07542655 0.15471723\n\n\nThe feasibility of estimating a growth model can also be already determined by examining the covariance matrix. If the covariances between two adjacent time points (T1 and T2; T2 and T3; T3 and T4; T4 and T5) are higher than non-adjacent time points, this could likely indicate non-negative slope variance. For example, in our covariance matrix the observed covariances between two adjacent time points are 0.15, 0.14, 0.11 and 0.08. These covariances are sometimes higher but also smaller than non-adjacent time points and thus, does not easily determine that there would be no negative slope variance.\n\nCodecor(lonely[, 2:6], use='pairwise.complete.obs') #correlation matrix\n\n          lone1     lone2     lone3     lone4     lone5\nlone1 1.0000000 0.6153198 0.4666493 0.3902312 0.3027420\nlone2 0.6153198 1.0000000 0.5184437 0.4142563 0.3557064\nlone3 0.4666493 0.5184437 1.0000000 0.4944602 0.4240808\nlone4 0.3902312 0.4142563 0.4944602 1.0000000 0.4342628\nlone5 0.3027420 0.3557064 0.4240808 0.4342628 1.0000000\n\n\nThe correlations over time provide unique information for longitudinal analysis. Here, most of the correlations show modest associations, indicating that the level of stability of individual differences across time is modest to high.\n3. Supplement main analysis with bivariate scatter plots and correlations\n\nCode#bivariate scatter plots below the diagonal, histograms on the diagonal, and the Pearson correlation above the diagonal.\npairs.panels(lonely[, 2:6], lm = TRUE) #lm = TRUE to fit a regression line\n\n\n\n\nBivariate scatter plots and correlations along with histograms can be supplemented to the main analysis.\n4. Examine longitudinal plots\n\nCodeplot_trajectories(data = lonely,\n                  id_var = \"personid\", \n                  var_list = c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\"),\n                  xlab = \"Year\", ylab = \"Loneliness\",\n                  connect_missing = FALSE,   #Want to plot only complete observations\n                  random_sample_frac = 0.05, #You can select more or less than 5% of the data by adjusting this\n                  title_n = TRUE)\n\nWarning: Removed 9 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 10 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nMake longitudinal plots to show participant’s scores of loneliness indexed on the y-axis and time of observation on the x-axis. Here, you can make one longitudinal plot that visualizes the overall trajectory for all participants and one that visualizes the trajectory for a subset of the participants.\n5. Examine separate individual longitudinal plots\n\nCodeplot_trajectories(data = lonely,\n                  id_var = \"personid\", \n                  var_list = c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\"),\n                  xlab = \"Year\", ylab = \"Loneliness\",\n                  connect_missing = FALSE,   #Want to plot only complete observations\n                  random_sample_frac = 0.025, #You can select more or less than 5% of the data by adjusting this\n                  title_n = TRUE) +\n facet_wrap(~personid)\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nMy personal choice has been to show separate individual longitudinal plots, but you can decide to show whichever one works for you.\n\n\n\n\nCode## Reshape from wide to long using tidyr\nlonelylong &lt;- lonely %&gt;%\n              pivot_longer(cols = 2:6,\n                           names_to = \"loneyearly\",\n                           values_to = \"value\")\n\n\n1. Examine univariate and bivariate statistics\n\nCode#Examine descriptive statistics using the wide data set.\ndescribe(lonely[, 2:6]) #univariate descriptives\n\n      vars   n mean   sd median trimmed  mad min  max range skew kurtosis   se\nlone1    1 398 1.46 0.46   1.32    1.38 0.34   1 3.75  2.75 1.81     3.95 0.02\nlone2    2 395 1.47 0.52   1.31    1.38 0.31   1 5.00  4.00 2.22     7.22 0.03\nlone3    3 390 1.53 0.52   1.36    1.44 0.37   1 3.78  2.78 1.52     2.27 0.03\nlone4    4 413 1.35 0.47   1.22    1.25 0.25   1 4.92  3.92 3.05    12.75 0.02\nlone5    5 409 1.32 0.39   1.20    1.24 0.25   1 3.43  2.43 2.45     7.22 0.02\n\n\nFirst thing to notice from the descriptive statistics is the number and pattern of missing data. It can also be noticed that, the means and standard deviations show a simple pattern with increases in the feeling of loneliness from T1 through to T3, and begins to decline afterwards though to T5 coupled with increases in variation and then a decline after T3.\nIt can be noticed already from the means that a linear growth function might not accurately characterize the trajectory in the data.\n2. Describe covariance and correlation matrices\n\nCode#bivariate descriptives\ncov(lonely[, 2:6], use='pairwise.complete.obs') #covariance matrix\n\n           lone1      lone2      lone3      lone4      lone5\nlone1 0.21451070 0.14910019 0.09978644 0.08198277 0.05209327\nlone2 0.14910019 0.27059267 0.13796998 0.10077467 0.06904941\nlone3 0.09978644 0.13796998 0.27223396 0.10690494 0.08475463\nlone4 0.08198277 0.10077467 0.10690494 0.21720685 0.07542655\nlone5 0.05209327 0.06904941 0.08475463 0.07542655 0.15471723\n\n\nThe feasibility of estimating a growth model can also be already determined by examining the covariance matrix. If the covariances between two adjacent time points (T1 and T2; T2 and T3; T3 and T4; T4 and T5) are higher than non-adjacent time points, this could likely indicate non-negative slope variance. For example, in our covariance matrix the observed covariances between two adjacent time points are 0.15, 0.14, 0.11 and 0.08. These covariances are sometimes higher but also smaller than non-adjacent time points and thus, does not easily determine that there would be no negative slope variance.\n\nCodecor(lonely[, 2:6], use='pairwise.complete.obs') #correlation matrix\n\n          lone1     lone2     lone3     lone4     lone5\nlone1 1.0000000 0.6153198 0.4666493 0.3902312 0.3027420\nlone2 0.6153198 1.0000000 0.5184437 0.4142563 0.3557064\nlone3 0.4666493 0.5184437 1.0000000 0.4944602 0.4240808\nlone4 0.3902312 0.4142563 0.4944602 1.0000000 0.4342628\nlone5 0.3027420 0.3557064 0.4240808 0.4342628 1.0000000\n\n\nThe correlations over time provide unique information for longitudinal analysis. Here, most of the correlations show modest associations, indicating that the level of stability of individual differences across time is modest to high.\n3. Supplement main analysis with bivariate scatter plots and correlations\n\nCode#bivariate scatter plots below the diagonal, histograms on the diagonal, and the Pearson correlation above the diagonal.\npairs.panels(lonely[, 2:6], lm = TRUE) #lm = TRUE to fits regression line\n\n\n\n\nBivariate scatter plots and correlations along with histograms can be supplemented to the main analysis.\n4. Examine longitudinal plots\n\nCode#Longitudinal plots with the long data set\nggplot(data = lonelylong[which(lonelylong$personid &lt; 26),], #Select the first 25 participants to show\n       aes(x = loneyearly, y = value, group = personid)) +\n       geom_line() +\n       #geom_smooth(method = lm, se = FALSE, size = 1) +\n       xlab(\"Time of observation\") +\n       ylab(\"Loneliness\")\n\nWarning: Removed 17 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\nMake longitudinal plots to show participant’s scores of loneliness indexed on the y-axis and time of observation on the x-axis. Here, you can make one longitudinal plot that visualizes the overall trajectory for all participants and one that visualizes the trajectory for a subset of the participants.\n5. Include separate individual trajectories\n\nCode#Longitudinal plots with the long data set\nggplot(data = lonelylong[which(lonelylong$personid &lt; 6),], #Select only five participants \n       aes(x = loneyearly, y = value, group = personid)) +\n       geom_line() +     \n       #geom_smooth(method = lm, se = FALSE, size = 1) +\n       xlab(\"Time of observation\") +\n       ylab(\"Loneliness\")+\nfacet_wrap(~personid)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\nMy personal choice has been to show separate individual longitudinal plots, but you can decide to show whichever one works for you."
  },
  {
    "objectID": "quantposts/two occasion/two.html",
    "href": "quantposts/two occasion/two.html",
    "title": "Analyses of Two Occasion Data",
    "section": "",
    "text": "This tutorial compares different models of change when presented with data collected at two time points - which could be pre-test and post test data or some other form of observational data.\n1. Difference Score Model of Change\nThe Raw Change Model also called the Difference Score Model is probably the most obvious and common. A researcher computes change between two time points by subtracting T1 scores from T2 scores (T2 - T1). Resulting from this subtraction whether greater or lesser is the change that has occurred between two time points. The Difference Score Model examine between-person differences in the change that has occurred within individuals from T1 to T2. Common in this model of change is to use the computed (resulting) change or difference (D), that is, T2 - T1 = D, as an outcome in subsequent analysis - which is why it is often called the Difference Score Model\nThis approach is, however, heavily criticized and has a rather bad reputation even until today, and started with Cronbach & Furby, 1970\n\n\n\n\n\n\n“Raw change” or “raw gain” scores formed by subtracting pretest scores from posttest scores lead to fallacious conclusions, primarily because such scores are systematically related to any random error of measurement. Although the unsuitability of such scores has long been discussed, they are still employed, even by some otherwise sophisticated investigators. Cronbach & Furby, 1970, p. 68\n\n\n\nThe Difference Score Model is badly reputed mainly for the following:\n\nHigh correlation between T1 scores and the computed D scores. With very high T1 scores, the D tends to be highly negatively correlated.\nMeasurement error contained in T1 and T2 scores become attenuated in the computed D scores, greatly limiting the reliability of the computed D scores.\n\nSome authors have suggested ways to mitigate the problems of the Difference Score Model including, to account for the confounding effects of T1 when using the computed D scores in subsequent analysis. See Rogosa & Willett, 1983; Gottman & Rushe, 1993\n2. Autoregressive Model of Change\nThe Autoregressive Model of Change focuses on the end state by using T2 as the DV and T1 as the predictor. This model responds to questions about individual differences in change by regressing T2 on T1, and does not answer questions about intraindividual change same as for many panel models. The regression coefficient resulting from regressing a variable at later time point on itself at an earlier time point is called the autoregressive effect. In this case, the regression of T2 on T1 is the autoregressive effect, which describes the stability of individual differences from T1 to T2.\n\nA larger coefficient means that individual differences have not changed much from T1 to T2 - higher stability.\nA smaller autoregressive coefficient means that there has been a larger change in individual differences from T1 to T2 - lower stability.\n\nThe Autoregressive Model of Change has had some appeal since the 70s and obviously since the criticisms of the Difference Score Model by Cronbach & Furby, 1970, p. 68. The appealing feature of the The Autoregressive Model of Change stems from the fact that when T2 is regressed on T1 (autoregressive effect), the remaining variance or the residual variance in T2 can be predicted by other variables in which case, this becomes the prediction of the stable portion of variable T, say our variable is T measured at T1 and T2. This is what cross-lagged effects are most useful for, as for example, T2 can be regressed on both T1 and X1, which means X1 will predict T2 when controlling for prior levels of T at T1. So, X1 effectively predicts the stable portion or the residual variance of T (at T2) - which is why this mode is sometimes called residual change model.\nIn the Autoregressive Cross-lagged Panel Models, controlling for prior levels of a variable while predicting the residual variance by another variable allows a researcher to rule out the possibility that a cross-lagged effect is confounded by the fact that the predictor (X) and outcome (T) are both correlated at T1. That is, the reason X1 predicts T2 is because X and T are correlated at T1 - this cannot hold when controlling for the prior levels of T. Most Autoregressive Model of Change and the Autoregressive Cross-lagged Panel Models have appeared in both observed or latent variable modeling.\n3. Latent Difference Score Model of Change\nThe Latent Difference Score also called the Latent Change Score Model is seen by some methodologists as a framework on its own for modelling change with the capability for testing within-person change hypotheses and between-person differences in within-person change. Like the Autoregressive Models of Change, this Latent Change Score Model can accommodate bivariate information in which two variables are modeled concurrently with cross-lagged effects. The Latent Change Score Model starts by decomposing an observed variable into a latent true score and a latent residual score. This model incorporates the autoregressive effect into the latent true score such that the true score at T2 is a function of the latent true score at T1, plus the amount of change that has occurred between T1 and T2. The Latent Change Score Model extends over four successive models of change namely, no change, constant change, proportional change and dual change. The dual change combines both constant and proportional change components. In my opinion, the Latent Change Score Model is useful when bivariate information is incorporated thereby responding to questions about the nature and sequence of subsequent changes in x versus y. In other words, which variable between x and y is a leading indicator of subsequent changes in the other variable?\nResearchers must think very carefully of their theories of change when selecting between the different existing models. The Latent Change Score Model while offering greater flexibility in modelling within-person changes and between-person differences in within-person change, emphasizes time-dependent associations when bivariate or multivariate information is incorporated, and this must be carefully considered to benefit from this modelling framework.\nLoad packages\n\nCodesuppressPackageStartupMessages({\nlibrary(lcsm)   #For analyzing the latent change score model\nlibrary(ggplot2) #For visualization \n})\n\n\nRead data\n\nCodedata &lt;- read.csv(\"/Volumes/anyan-1/frederickanyan.github.io/quantpost_data/data.csv\")\ndata &lt;- data[, c(\"personid\", \"lone3\", \"lone5\")] #Create new data set with only your main outcome variables\nnames(data) &lt;- c(\"id\", \"loneT1\", \"loneT2\") #Rename variables to represent T1 and T2\n\n\n\n\nDifference Score Model\nAutoregressive Model\nLatent Change Score Model\n\n\n\nDetermine the difference score (T2-T1 = D)\n\nCodedata$lonediff &lt;- data$loneT2-data$loneT1 #You can attach the new variable lonediff to the data with $\n\n\nNow regress D on T1\n\nCodediffM &lt;- lm(formula = lonediff ~ 1 + loneT1,\n             data = data,\n             na.action = na.exclude)\nsummary(diffM)\n\n\nCall:\nlm(formula = lonediff ~ 1 + loneT1, data = data, na.action = na.exclude)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75462 -0.17873 -0.07593  0.08014  2.10763 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.83528    0.05658   14.76   &lt;2e-16 ***\nloneT1      -0.68587    0.03502  -19.59   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3489 on 367 degrees of freedom\n  (73 observations deleted due to missingness)\nMultiple R-squared:  0.5111,    Adjusted R-squared:  0.5098 \nF-statistic: 383.7 on 1 and 367 DF,  p-value: &lt; 2.2e-16\n\n\nThe Intercept (0.83) is the expected value of the change in loneliness for an individual with a score of 0 = at T1. The slope of loneT1 indicates the expected negative difference in within-person change (-0.68) for a unit change in loneliness at T1.\n\nCodeggplot(data = data, aes(x = loneT1, y = lonediff)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", formula = y ~ 1 + x, \n              se = TRUE, fullrange = TRUE, color = \"blue\", linewidth = 1.5) +\n  xlab(\"Loneliness T1\") + \n  ylab(\"Difference in Loneliness T2 and T1\") +\n  ggtitle(\"The Difference score Model\")\n\nWarning: Removed 73 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 73 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nThe plot above represents the slope better.\n\n\nRegress T2 on T1\n\nCodearM &lt;- lm(formula = loneT2 ~ 1 + loneT1,\n            data = data,\n            na.action = na.exclude)\nsummary(arM)\n\n\nCall:\nlm(formula = loneT2 ~ 1 + loneT1, data = data, na.action = na.exclude)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75462 -0.17873 -0.07593  0.08014  2.10763 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.83528    0.05658  14.762   &lt;2e-16 ***\nloneT1       0.31413    0.03502   8.971   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3489 on 367 degrees of freedom\n  (73 observations deleted due to missingness)\nMultiple R-squared:  0.1798,    Adjusted R-squared:  0.1776 \nF-statistic: 80.48 on 1 and 367 DF,  p-value: &lt; 2.2e-16\n\n\nThe Intercept (0.83) is the expected value of loneliness at T2 for an individual with a score of 0 = at T1. The slope of loneT1 (0.31) indicates the stability of between-person differences from T1 to T2. The autoregressive coefficient show that individual differences in loneliness is moderately stable between the two time points as the autoregressive coefficient is about moderate size.\nRemember T1 and T2 were originally (lone3 at T3) and (lone5 at T5), which means that the distance between time points is longer than it would be for adjacent time points (lone3 at T3 and lone4 at T4 versus lone4 at T4 and lone5 at T5). The longer time that elapses between measurement occasions, the higher it is that the autoregressive effect dissipates and thereby resulting in less stability of individual differences from one occasion to the next. Therefore, the time lag between time points is very crucial in panel models since this may have implications for when hypothesized autoregressive or cross-lagged effects may disappear.\nAlternatively, we expect a positive difference of (0.31) in loneliness at T2 for a every unit change in loneliness at T1\n\nCodeggplot(data = data, aes(x = loneT1, y = loneT2)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", formula= y ~ 1 + x, \n              se = TRUE, fullrange = TRUE, color=\"blue\", linewidth = 1.5) +\n  xlab(\"Loneliness T1\") + \n  ylab(\"Loneliness T2\") +\n  ggtitle(\"The Autoregressive Model of Chang\")\n\nWarning: Removed 73 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 73 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nThe plot represents the expected positive difference in loneliness at T2 for a every unit change in loneliness at T1\n\n\nTBC"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Longitudinal analyses of the Mental health, Vulnerability, and Protective factors among Norwegian Afghanistan Veterans\n\n\n\n\n\n\n\nveterans\n\n\nresilience\n\n\nmental health\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2023\n\n\nFrederick Anyan\n\n\n\n\n\n\n  \n\n\n\n\nResilience to Loneliness for Mental and Physical Health outcomes(RESLON-MPH)\n\n\n\n\n\n\n\nresilience\n\n\nloneliness\n\n\nsocial isolation\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2022\n\n\nFrederick Anyan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Differences in resilience profiles between military veterans and the general population: An exploratory latent profile analysis using the HUNT-4 survey\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\n\n\n\n\n  \n\n\n\n\nSymptoms and prevalence of common mental disorders in a heterogenous outpatient sample: an investigation of clinical characteristics and latent subgroups\n\n\n\n\n\n\n\nMental Health\n\n\nCognitve Theory\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThe behavioural regulation in exercise questionnaire (BREQ): psychometric properties and associations with physical activity outcomes in a Norwegian sample of physically active adults\n\n\n\n\n\n\n\nMental Health\n\n\nCognitve Theory\n\n\n\n\n\n\n\n\n\n\n\nSep 6, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThe network structure of dysfunctional metacognitions, CAS strategies, and symptoms\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2023\n\n\n\n\n\n\n  \n\n\n\n\nMeasuring Resilience in Long-term Sick-listed Individuals: Validation of the Resilience Scale for Adults\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n  \n\n\n\n\nProspective Relations Between Dysfunctional Metacognitive Beliefs, Metacognitive Strategies, and Anxiety: Results From a Four-Wave Longitudinal Mediation Model\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nFeb 17, 2023\n\n\n\n\n\n\n  \n\n\n\n\nChange in interpersonal problems and metacognitive beliefs as predictors of improvement in patients with generalized anxiety disorder\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\n\n\n\n\n  \n\n\n\n\nIncidence of mental disorders in the general population aged 1–30 years disaggregated by gender and socioeconomic status\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nTesting the longitudinal effect of metacognitive beliefs on the trajectory of work ability\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2022\n\n\n\n\n\n\n  \n\n\n\n\nThe network structure of dysfunctional metacognition: Analysis of the MCQ-30\n\n\n\n\n\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nResilience patterns of Swiss adolescents before and during the COVID-19 pandemic: a latent transition analysis\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2022\n\n\n\n\n\n\n  \n\n\n\n\nMetacognition, Cognition and Social Anxiety: A Test of Temporal and Reciprocal Relationships\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nResilience profiles across context: A latent profile analysis in a German, Greek, and Swiss sample of adolescents\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2022\n\n\n\n\n\n\n  \n\n\n\n\nSick leave and return to work for patients with anxiety and depression: A longitudinal study of trajectories before, during and after work-focused treatment\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2021\n\n\n\n\n\n\n  \n\n\n\n\nRelevance of well-being, resilience, and health-related quality of life to mental health profiles of European adolescents: results from a cross-sectional analysis of the school-based multinational UPRIGHT project\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLoneliness in social relationships: Mapping the nomological network of loneliness with key conceptual domains and theoretical constructs\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\nLoneliness\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2021\n\n\n\n\n\n\n  \n\n\n\n\nMeasuring Resilience Across Participating Regions in the UPRIGHT EU Horizon 2020 Project: Factor Structure and Psychometric Properties of the Resilience Scale for Adolescents\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nFeb 17, 2021\n\n\n\n\n\n\n  \n\n\n\n\nHousing first, connection second: the impact of professional helping relationships on the trajectories of housing stability for people facing severe and multiple disadvantage\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nWorking Alliance\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2021\n\n\n\n\n\n\n  \n\n\n\n\nPsychometric properties of the Resilience Scale for Adolescents (READ) and Measurement Invariance Across Two Different German-Speaking Samples\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2020\n\n\n\n\n\n\n  \n\n\n\n\nChange in Physical Activity During the Coronavirus Disease 2019 Lockdown in Norway: The Buffering Effect of Resilience on Mental Health\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nDec 15, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDevelopment and validation of the theory-driven School Resilience Scale for Adults: Preliminary results\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nInterpersonal stress, anxiety and depressive symptoms: Results from a moderated mediation analysis with resilience\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nCo-creation and regional adaptation of a resilience-based universal whole-school program in five European regions\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTemporal and Reciprocal Relations Between Worry and Rumination Among Subgroups of Metacognitive Beliefs\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2020\n\n\n\n\n\n\n  \n\n\n\n\nProspective relations between loneliness in different relationships, metacognitive beliefs, worry and common mental health problems\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\nLoneliness\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2020\n\n\n\n\n\n\n  \n\n\n\n\nResilience Moderates Negative Outcome from Stress during the COVID-19 Pandemic: A Moderated-Mediation Approach\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2020\n\n\n\n\n\n\n  \n\n\n\n\nUPRIGHT, a resilience-based intervention to promote mental well-being in schools: study rationale and methodology for a European randomized controlled trial\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMeasuring Resilience Across Australia and Norway: Validation and Psychometric Properties of the English Version of the Resilience Scale for Adults\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2019\n\n\n\n\n\n\n  \n\n\n\n\nSpecificity in mediated pathways by anxiety symptoms linking adolescent stress profiles to depressive symptoms: Results of a moderated mediation approach\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nThe coping mechanism and strategies of hypertension patients in Ghana: The role of religious faith, beleifs and practices\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nQualitative Interview Research\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2017\n\n\n\n\n\n\n  \n\n\n\n\nAnxiety symptoms mediate the relationship between exposure to stressful negative life events and depressive symptoms: A conditional process modelling of the protective effects of resilience\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2017\n\n\n\n\n\n\n  \n\n\n\n\nStress of home life and gender role socializations, family cohesion, and symptoms of anxiety and depression\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2017\n\n\n\n\n\n\n  \n\n\n\n\nAdolescent stress and symptoms of anxiety and depression: Resilience explains and differentiates the relationships\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2016\n\n\n\n\n\n\n  \n\n\n\n\nThe influence of power shifts in data collection and analysis stages : A focus on qualitative research interview\n\n\n\n\n\n\n\nQualitative Interview Research\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2013\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "quantposts.html",
    "href": "quantposts.html",
    "title": "Quant Posts",
    "section": "",
    "text": "Analyses of Two Occasion Data\n\n\n\nChange\n\n\nDifference Score\n\n\nAutoregressive\n\n\n\n\n\n\n\nFrederick Anyan\n\n\nSep 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nThings to do before fitting a growth model\n\n\n\n\n\n\nFrederick Anyan\n\n\nSep 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Sets\n\n\n\nSets\n\n\nVenn diagram\n\n\n\n\n\n\n\nFrederick Anyan\n\n\nJun 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssociation Between Two Categorical Variables\n\n\n\nCategorical variables\n\n\n\n\n\n\n\nFrederick Anyan\n\n\nJun 15, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshops/NTNU_2021_19_20_May/NTNU2021May.html",
    "href": "workshops/NTNU_2021_19_20_May/NTNU2021May.html",
    "title": "Latent Growth Curve Models (LGCM) & Growth Mixture Models (GMM) - Two-day Workshop",
    "section": "",
    "text": "Research questions examining within-person changes or joint within-person changes and between-person differences in the stability and change in individuals’ attributes over time make longitudinal data incredibly useful. Longitudinal data offers many possibilities to describe differences in how and when people change and explain why. Methodological limitations in calculating difference score, taking residualized scores, correlation among repeated measures, and other limitations mean that appropriate growth models must be estimated.\nStructural Equation Modelling (SEM) is a family of related analysis techniques – correlations, regression analyses and factor analyses, using both observed and unobserved (latent) variables to offer a flexible framework for analysing longitudinal data (and cross-sectional data too). Analysing growth models in the SEM framework provide a highly convenient and statistically rigorous framework for applied research in the social, behavioural, and educational sciences.\nThis course is a data analysis course, not a statistics course and will cover basic and advanced longitudinal SEM model using Mplus in a very easy and efficient implementation. Additionally, to make the course more ‘theory- and practice-based’ than ‘equations-based’, the models that will be estimated will be guided by the overarching objectives of longitudinal research described in the seminal work of Baltes and Nasselroade (1979)."
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "",
    "text": "Different analysis techniques allow researchers to examine change in outcome variable(s) across time, including regression methods, mean comparisons and repeated measures ANOVA - although with some limitations. A common practice in developmental research is to assess growth trajectory to understand developmental change - how and when it happens, interindividual differences in how and when it happens, as well as why it happens. Structural Equation Modelling (SEM) is a family of related analysis techniques – correlations, regression analyses and factor analyses, using both observed and unobserved (latent) variables to offer a flexible framework for analyzing developmental change in a highly convenient and statistically rigorous framework for applied research in the social, behavioral, and educational sciences.\nThis workshop will cover basic and advanced longitudinal SEM models using R in a very easy and efficient implementation. To make the workshop more ‘theory- and practice-based’ than ‘equations-based’, the models that will be estimated in this workshop will be guided by the overarching objectives of longitudinal research (see Baltes & Nesselroade, 1979; McArdle, 2012).\nReferences\nDownload Presentation Slides\nFollowing are models shown in the tab groups"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#no-growthlinear-and-quadratic-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#no-growthlinear-and-quadratic-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "No growth/Linear and Quadratic growth models",
    "text": "No growth/Linear and Quadratic growth models\nBasic growth models are described here, including the No growth model or the Intercept only model - which is a logical starting point for growth modelling. We want to reject the no growth modelling as it predicts no overall rate of change across time. The next model is the Linear growth curve model which predicts a linear rate of change across time. The Quadratic growth curve model is a non-linear growth curve model that predicts an overall accelerartion or deceleration in the rate of change when controlling for the linear change across time. Although the Quadratic growth curve model can be a useful alternative when the Linear growth curve model fits poorly or there is some degree of nonlinearity in the observed data, it can present much interpretation difficulty. The Latent basis growth curve model allows the data to define the growth function - discussed in the workshop.\n\nModel 1Model 2Model 3\n\n\nTITLE:  001_No_change_No_growth_Intercept_only_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON; \n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\nESTIMATOR = ML;\n\nMODEL:\n  I|lone1@1 lone2@1 lone3@1 lone4@1 lone5@1;!Fix the loading for the intercept growth factor to 1\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  002_Linear_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\nESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6; !Include a slope growth factor and fix to the time scores of observation\n\nOUTPUT:\n  SAMPSTAT;\n\nPLOT:\n  TYPE = PLOT3;\n  SERIES = lone1 - lone5(S); !You can add a plot of the slope growth function \n\n\nTITLE:  003_Quadratic_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S Q|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6; !Include the quadratic growth function, \n                                                 !but don't include a second-order power term as Mplus will automatically do this for you\n\nOUTPUT:\n  SAMPSTAT;\n\nPLOT:\n  TYPE = PLOT3;\n  SERIES = lone1 - lone5(S);"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#bilinearsplinepiecewisemultiphase-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#bilinearsplinepiecewisemultiphase-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Bilinear/Spline/Piecewise/Multiphase growth models",
    "text": "Bilinear/Spline/Piecewise/Multiphase growth models\nThe Quadratic growth curve model is specified by adding a second-order power of time to the Linear growth curve model, which means that there would be a high correlation between the power terms. This can be resolved by centering the intercept growth factor in the middle of the observation, but becomes more difficult when moving to higher-order polynomials. For this reason, it is recommended to examine the data if a Piecewise growth curve model could be an alternative solution. The most common type is the Bilinear growth curve model which joins two linear growth factors. It also goes by the name Spline growth model and Multiphase growth model. They can accommodate different linear or nonlinear growth functions by segmenting the period of observation with a knot point often called transition points when there are theoretical reasons to separate the observations into discrete phases - hence their name Multiphase growth model. For example, they can be used to model developmental changes that occur during pre-school, primary school and high school with transition points at when a child begins primary school and also at when s/he begins high school.\n\nModel 4_1Model 4_2Model 4_3\n\n\nTITLE:  004_1_Bilinear_spline_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S1|lone1@0 lone2@1 lone3@3 lone4@3 lone5@3;!Slope 1\n  I S2|lone1@0 lone2@0 lone3@0 lone4@1 lone5@3;!Slope 2\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  004_2_Bilinear_spline_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S1|lone1@-3 lone2@-2 lone3@0 lone4@0 lone5@0;!Slope 1\n  I S2|lone1@0 lone2@0 lone3@0 lone4@1 lone5@3;!Slope 2\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  004_3_Bilinear_spline_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S1|lone1@-3 lone2@-3 lone3@-3 lone4@-2 lone5@0;!Slope 1\n  I S2|lone1@-3 lone2@-2 lone3@0 lone4@0 lone5@0;!Slope 2\n\nOUTPUT:\n  SAMPSTAT STAND;"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#growth-models-with-time--varying-and-invariant-predictors-and-distal-outcomes",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#growth-models-with-time--varying-and-invariant-predictors-and-distal-outcomes",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Growth models with time- varying and invariant predictors and distal outcomes",
    "text": "Growth models with time- varying and invariant predictors and distal outcomes\nDynamic predictors that change across time can be incorporated into the growth model to simultaneously estimate the overall rate of change and the change from the time-varying predictors. These dynamic, time-varying predictors account for within-person changes by altering the trajectory of growth in an individual. Between-person differences in the within-person rate of change can be explained by the inclusion of time invariant predictors such as gender or experimental conditions. Growth factors can be hypothesized to predict distal outcomes that are measured after the growth process such as the rate of change in metacognitve therapy predicting recovery status in a 24-month follow up.\n\nModel 5Model 6Model 7Model 8\n\n\nTITLE:  005_Linear_growht_curve_model_with_time_varying_covariate\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5\n  host1 host2 host3 host4 host5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;!Growth for loneliness\n\n!Regress loneliness on time-varying covariate\n  lone1 ON host1;!By adding labels to the parameter estimates\n  lone2 ON host2;!you can test whether TVC effects are constant over time\n  lone3 ON host3;\n  lone4 ON host4;\n  lone5 ON host5;\n\n  !However, if you already assume constant effect of TVC over time\n  !and do not want to test, you can use this model specification\n  !lone1 ON host1(a);!By adding the same label (a) to the parameter estimates\n  !lone2 ON host2(a);!you constrain the effects to be constant across time\n  !lone3 ON host3(a);\n  !lone4 ON host4(a);\n  !lone5 ON host5(a);\n\n!Fix TVC covariance with intercept and slope to zero\n  I S WITH host1-host5@0;\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  006_Linear_growht_curve_model_with_time_invariant_covariates\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5 female;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  I S ON female; !Regress growth factors on the time-invariant covariate\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  007_Linear_growht_curve_model_with_time-invariant and time-varying covariates\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5\n  host1 host2 host3 host4 host5\n  female pdu1 ace1;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  I S ON female pdu1 ace1;!Regress growth factors on time-invariant covariates\n\n  lone1 ON host1(a);!Regress loneliness on TVC\n  lone2 ON host2(a);!Constrain TVC effect to be equal across time\n  lone3 ON host3(a);\n  lone4 ON host4(a);\n  lone5 ON host5(a);\n\n  I S WITH host1-host5@0; !Fix TVC covariance with intercept and slope to zero\n\n  female pdu1 ace1 WITH host1-host5; !Estimate the covaraince between covariates\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  008_Linear_growht_curve_model_with_growth_factors_predicting_distal_outcome\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5 subs5;\n  \nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n    \n  subs5 ON I S; !Regress distal outcome on growth factors and time-invariant predictors\n    \n  !subs5 ON I S female pdu1 ace1;\n\n  !Regress growth factors on time-invariant covariates\n  !I S ON female pdu1 ace1;\n\n  !female pdu1 ace1;\n  ![female pdu1 ace1];\n  !female pdu1 ace1 WITH female pdu1 ace1;\n\nOUTPUT:\n  SAMPSTAT;"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#multiple-group-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#multiple-group-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Multiple group growth models",
    "text": "Multiple group growth models\nA Multiple-group growth model approach offers greater flexibility in explaining between-person differences in the within-person rate of change than the Growth model with time invariant covariate. For example, the Wald test of differences in growth parameters can be tested within the multiple-group approach to explain whether, on average, the experimental group experience greater overall decline than the control group - thus providing insights into how and why individuals differ in their rate of change and by how much difference. The multiple-group approach can inform about differences in all the growth functions’ parameters - including the growth factors means, co/variances and residual variances.\n\nModel 9_1Model 009_2Model 009_3Model 9_4\n\n\nTITLE:  009_1_Multigroup_LGCM_M1_Invariance_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nGROUPING = FEMALE (0 = MALES 1 = FEMALES);\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  !Estimate means of growth factors and label them\n  [I](INT);\n  [S](SLP);\n\n  !Estimate variances of growth factors\n  I(INT_V);\n  S(SLP_V);\n\n  !Estimate covariance of growth factors\n  I WITH S(IS_COV);\n\n  !Estimate residual variance and constrain them equal\n  lone1-lone5(RES);\n\n  !Sequentially testing models means that specific parameters are of interest\n  !For those parameters, we will begin by constraining them to be equal (identical) across both groups\n  !Those parameters are (MEANS OF GROWTH FACTORS, COVARIANCES AND RESIDUAL VARIANCES)\n  !In subsequent models, we will freely estimate those parameters\n\nMODEL MALES:\n  !Growth factor means for males\n  [I](INT);!The INT label will make the males' intercept growth factor identical to the\n  [S](SLP);!The labelling for all the parameters will make them idenitcal for males and\n\n  !Growth factor variances for males\n  I(INT_V);\n  S(SLP_V);\n\n  !Growth factor covariance for males\n  I WITH S(IS_COV);\n\n  !Residual variances for males\n  lone1-lone5(RES);\n\nMODEL FEMALES:\n  !Gorwth factor means for females\n  [I](INT);!The INT label will make the females' intercept growth factor identical to th\n  [S](SLP);\n\n  !Growth factor variances for females\n  I(INT_V);\n  S(SLP_V);\n\n  !Growth factor covariance for females\n  I WITH S(IS_COV);\n\n  !Residual variances for females\n  lone1-lone5(RES);\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  009_2_Multigroup_LGCM_M2_Growth_factor_means\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nGROUPING = FEMALE (0 = MALES 1 = FEMALES);\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  [I](INT);\n  [S](SLP);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\nMODEL MALES:\n  [I](INT_M); !Free growth factor means by using different labels or completely removing\n  [S](SLP_M);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\nMODEL FEMALES:\n  [I](INT_F);!Different labels are used to freely estimate the growth factor means\n  [S](SLP_F);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\n!MODEL TEST:\n  !INT_M = INT_F;\n  !0 = INT_M-INT_F;\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  009_3_Multigroup_LGCM_M3_Growth_factor_means_and covariances\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nGROUPING = FEMALE (0 = MALES 1 = FEMALES);\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  [I](INT);\n  [S](SLP);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\nMODEL MALES:\n  [I S];!First: Growth factor means are freely estimated\n  I S;!Second: Growth factor variances are freely estimated\n\n  I WITH S;!Second: Growth factor covariances are freely estimated\n\n  lone1-lone5(RES);\n\nMODEL FEMALES:\n  [I S];!First: Growth factor means are freely estimated\n  I S;!Second: Growth factor variances are freely estimated\n\n  I WITH S;!Second: Growth factor covariances are freely estimated\n\n  lone1-lone5(RES);\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  009_4_Multigroup_LGCM_M4_Growth_factor_means_and covariances_with_residual_variances\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nGROUPING = FEMALE (0 = MALES 1 = FEMALES);\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  [I](INT);\n  [S](SLP);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\nMODEL MALES:\n  [I S](INT_M SLP_M);!First: Growth factor means are freely estimated\n  I S;!Second: Growth factor variances are freely estimated\n\n  I WITH S;!Second: Growth factor covariances are freely estimated\n\n  lone1-lone5;!Third, residual variances freely estimated\n\nMODEL FEMALES:\n  [I S](INT_F SLP_F);!First: Growth factor means are freely estimated\n  I S;!Second: Growth factor variances are freely estimated\n\nI WITH S;!Second: Growth factor covariances are freely estimated\n\n  lone1-lone5;!Third: residual variances freely estimated\n\n!MODEL TEST:\n!  0 = INT_M - INT_F;\n\nOUTPUT:\n  SAMPSTAT;"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#modelling-co-development-and-multivariate-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#modelling-co-development-and-multivariate-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Modelling co-development and Multivariate growth models",
    "text": "Modelling co-development and Multivariate growth models\nModelling the co-development among different attributes such as the comorbidity of anxiety and depression is becoming more common. Multivariate growth models also called Parallel growth models can accommodate different growth functions among two or more attributes. Care must be taken and theoretical considerations must be prioritized when choosing between Multivariate growth curve models and the Growth curve models with time-varying covariates. The two are related but answer different research questions.\n\nModel 10_1Model 10_2Model 10_3\n\n\nTITLE:  010_1_Parallel_growth_curve_model_anxiety_and_depressive symptoms\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n  MODEL = NOCOV;!Suppress Mplus default correlations between the growth factors\n  !That way, you have control over what variables you want to correlate or\n  \nMODEL:\n  I_ANX S_ANX|anx1@0 anx2@1 anx3@3 anx4@4 anx5@6;!anxiety symptoms growth\n  I_DEP S_DEP|dep1@0 dep2@1 dep3@3 dep4@4 dep5@6;!depressive symptoms\n\n  !Correlate the growth factors\n  I_ANX WITH S_ANX;\n  I_DEP WITH S_DEP;\n\n  I_ANX WITH I_DEP;\n  S_ANX WITH S_DEP;\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  010_2_Parallel_growth_curve_model_anxiety_and_depressive symptoms_autocorrelations\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n  MODEL = NOCOV;!Suppress Mplus default correlations between the growth factors\n  !That way, you have control over what variables you want to correlate or\n  \nMODEL:\n  I_ANX S_ANX|anx1@0 anx2@1 anx3@3 anx4@4 anx5@6;!anxiety symptoms growth\n  I_DEP S_DEP|dep1@0 dep2@1 dep3@3 dep4@4 dep5@6;!depressive symptoms\n\n  !Correlate the growth factors\n  I_ANX WITH S_ANX;\n  I_DEP WITH S_DEP;\n\n  I_ANX WITH I_DEP;\n  S_ANX WITH S_DEP;\n\n  !Within subdomain autocorrelations\n  anx1 anx2 anx3 anx4 PWITH anx2 anx3 anx4 anx5; !PWITH means pair with\n  dep1 dep2 dep3 dep4 PWITH dep2 dep3 dep4 dep5;\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  010_3_Parallel_growth_curve_model_anxiety_and_depressive symptoms_cross_domain_corre\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n  MODEL = NOCOV;!Suppress Mplus default correlations between the growth factors\n  !That way, you have control over what variables you want to correlate or\n  \nMODEL:\n  I_ANX S_ANX|anx1@0 anx2@1 anx3@3 anx4@4 anx5@6;!anxiety symptoms growth\n  I_DEP S_DEP|dep1@0 dep2@1 dep3@3 dep4@4 dep5@6;!depressive symptoms\n\n  !Correlate the growth factors\n  I_ANX WITH S_ANX;\n  I_DEP WITH S_DEP;\n\n  I_ANX WITH I_DEP;\n  S_ANX WITH S_DEP;\n\n  !Cross subdomain correlations\n  anx1 anx2 anx3 anx4 anx5 PWITH dep1 dep2 dep3 dep4 dep5;\n\n\nOUTPUT:\n  SAMPSTAT;"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#sequentially-contingent-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#sequentially-contingent-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Sequentially contingent growth models",
    "text": "Sequentially contingent growth models\nGrowth in one attribute can predict the growth that occur in another attribute later in the developmental process. The rate of change in language development during pre-school may predict the rate of change in language skills during primary school. Sequentially contingent growth models offer flexibility in modelling such relations in the developmental process that occur in different stages, but might be contingent on each other.\n\nModel 11\n\n\nTITLE:  011_Sequentially_contingent_growth_curve_model_anxiety_T1_T5_predicting_depression\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep6 dep7 dep8 dep9 dep10!Time of observations modified for pedagogical reasons\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  anx1 anx2 anx3 anx4 anx5\n  dep6 dep7 dep8 dep9 dep10;!Time of observations modified for pedagogical reasons\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n  MODEL = NOCOV;!Suppress Mplus default correlations between the growth factors\n                    !That way, you have control over what variables you want to correlate or\nMODEL:\n  I_ANX S_ANX|anx1@0 anx2@1 anx3@3 anx4@4 anx5@6;!anxiety symptoms growth\n  I_DEP S_DEP|dep6@0 dep7@1 dep8@2 dep9@3 dep10@4;!Equidistant time scores for depressiv\n\n  !Correlate the growth factors\n  I_ANX WITH S_ANX;\n  I_DEP WITH S_DEP;\n\n  !Add sequqntially contingent growth factors\n  I_DEP S_DEP PON I_ANX S_ANX; !Pair ON\n\nOUTPUT:\n  SAMPSTAT;\n\n\n\n\n\n\n\n\n\nFeel free to contact me at frederick.anyan@ntnu.no for advise or invitation to present workshops in your own institution."
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "",
    "text": "Different analysis techniques allow researchers to examine change in outcome variable(s) across time, including regression methods, mean comparisons and repeated measures ANOVA - although with some limitations. A common practice in developmental research is to assess growth trajectory to understand developmental change - how and when it happens, interindividual differences in how and when it happens, as well as why it happens. Structural Equation Modelling (SEM) is a family of related analysis techniques – correlations, regression analyses and factor analyses, using both observed and unobserved (latent) variables to offer a flexible framework for analyzing developmental change in a highly convenient and statistically rigorous framework for applied research in the social, behavioral, and educational sciences.\nThis workshop will cover basic and advanced longitudinal SEM models using R in a very easy and efficient implementation. To make the workshop more ‘theory- and practice-based’ than ‘equations-based’, the models that will be estimated in this workshop will be guided by the overarching objectives of longitudinal research (see Baltes & Nesselroade, 1979; McArdle, 2012).\nReferences\nDownload Presentation Slides\nFollowing are models shown in the tab groups\nYou can jump to the growth models by clicking on the options to your right"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#practical-preliminaries",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#practical-preliminaries",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Practical preliminaries",
    "text": "Practical preliminaries\nLoad packages\n\nCodesuppressPackageStartupMessages({\n#library(haven) #To read dataset into R. \nlibrary(psych)  #For practical preliminaries: univariate and bivariate descriptive stats\nlibrary(lcsm)   #For plotting longitudinal trajectories from wide data set\nlibrary(lavaan) #For calling sem/cfa/growth functions. We will use the growth() function in the lavaan pacakage, which also has other functions. [See here](https://lavaan.ugent.be)\nlibrary(ggplot2)\n})\n\nWarning: package 'psych' was built under R version 4.3.3\n\n\nWarning: package 'lavaan' was built under R version 4.3.3\n\n\nRead data\n\nCodedata &lt;- read.csv(\"/Volumes/anyan-1/frederickanyan.github.io/quantpost_data/data.csv\")\n#Create new data set with only your main outcome variables\nlonely &lt;- data[, c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\")]\n#To plot longitudinal trajectories, create a new data set of only your outcome variables with id included\nlonelytrajectory &lt;- data[, c(\"personid\", \"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\")]\n\n\n\n\nExamine univariate and bivariate statistics\nLongitudinal plots\n\n\n\n\nCode#Examine descriptive statistics.\ndescribe(lonely) #univariate descriptives \n\n      vars   n mean   sd median trimmed  mad min  max range skew kurtosis   se\nlone1    1 398 1.46 0.46   1.32    1.38 0.34   1 3.75  2.75 1.81     3.95 0.02\nlone2    2 395 1.47 0.52   1.31    1.38 0.31   1 5.00  4.00 2.22     7.22 0.03\nlone3    3 390 1.53 0.52   1.36    1.44 0.37   1 3.78  2.78 1.52     2.27 0.03\nlone4    4 413 1.35 0.47   1.22    1.25 0.25   1 4.92  3.92 3.05    12.75 0.02\nlone5    5 409 1.32 0.39   1.20    1.24 0.25   1 3.43  2.43 2.45     7.22 0.02\n\nCode#bivariate descriptives\ncov(lonely, use='pairwise.complete.obs') #covariance matrix\n\n           lone1      lone2      lone3      lone4      lone5\nlone1 0.21451070 0.14910019 0.09978644 0.08198277 0.05209327\nlone2 0.14910019 0.27059267 0.13796998 0.10077467 0.06904941\nlone3 0.09978644 0.13796998 0.27223396 0.10690494 0.08475463\nlone4 0.08198277 0.10077467 0.10690494 0.21720685 0.07542655\nlone5 0.05209327 0.06904941 0.08475463 0.07542655 0.15471723\n\nCodecor(lonely, use='pairwise.complete.obs') #correlation matrix\n\n          lone1     lone2     lone3     lone4     lone5\nlone1 1.0000000 0.6153198 0.4666493 0.3902312 0.3027420\nlone2 0.6153198 1.0000000 0.5184437 0.4142563 0.3557064\nlone3 0.4666493 0.5184437 1.0000000 0.4944602 0.4240808\nlone4 0.3902312 0.4142563 0.4944602 1.0000000 0.4342628\nlone5 0.3027420 0.3557064 0.4240808 0.4342628 1.0000000\n\nCode#bivariate scatter plots below the diagonal, histograms on the diagonal, and the Pearson correlation above the diagonal.\npairs.panels(lonely, lm = TRUE) #lm = TRUE to fit a regression line if needed\n\n\n\n\nExplanatory test or how to interpret and use results from practical preliminaries can be found here\n\n\n\nCodeplot_trajectories(data = lonelytrajectory,\n                  id_var = \"personid\", \n                  var_list = c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\"),\n                  xlab = \"Year\", ylab = \"Loneliness\",\n                  connect_missing = FALSE,   #Want to plot only complete observations\n                  random_sample_frac = 0.05, #You can select more or less than 5% of the data by adjusting this\n                  title_n = TRUE)\n\nWarning: Removed 9 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 10 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nYou can plot separate individual trajectories\n\nCodeplot_trajectories(data = lonelytrajectory,\n                  id_var = \"personid\", \n                  var_list = c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\"),\n                  xlab = \"Year\", ylab = \"Loneliness\",\n                  connect_missing = FALSE,   #Want to plot only complete observations\n                  random_sample_frac = 0.025, #You can select more or less than 5% of the data by adjusting this\n                  title_n = TRUE) +\n facet_wrap(~personid)\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nExplanatory text or how to interpret and use results from things to do before fitting growth models to longitudinal data can be found here"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#no-growthlinear-and-quadratic-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#no-growthlinear-and-quadratic-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "No growth/Linear and Quadratic growth models",
    "text": "No growth/Linear and Quadratic growth models\nBasic growth models are described here, including the No growth model or the Intercept only model - which is a logical starting point for growth modelling. We want to reject the no growth modelling as it predicts no overall rate of change across time.\nThe next model is the Linear growth model which predicts a linear rate of change across time. The Quadratic growth model is a non-linear growth model that predicts an overall acceleration or deceleration in the rate of change when controlling for the linear change across time.\nAlthough the Quadratic growth model can be a useful alternative when the Linear growth model fits poorly or there is some degree of non-linearity in the observed data, it can present much interpretation difficulty. The Bilinear/Spline/Piecewise/Multiphase model is a great alternative for fitting non-linear trajectories.\nThe Latent basis growth model allows the data to define the growth function - discussed in the workshop.\n\n\nModel 1\nModel 2\nModel 3\n\n\n\n\nCode# 001_No growth model\nnogrowth &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5'\nfit_nogrowth &lt;- growth(nogrowth, data = data)\nsummary(fit_nogrowth, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 37 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         7\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               186.433\n  Degrees of freedom                                13\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.607\n  Tucker-Lewis Index (TLI)                       0.698\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -814.634\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1643.269\n  Bayesian (BIC)                              1669.669\n  Sample-size adjusted Bayesian (SABIC)       1647.466\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.204\n  90 Percent confidence interval - lower         0.179\n  90 Percent confidence interval - upper         0.230\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.172\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i                 1.398    0.018   79.816    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.109    0.010   10.537    0.000\n   .lone2             0.142    0.013   11.035    0.000\n   .lone3             0.167    0.015   11.279    0.000\n   .lone4             0.112    0.011   10.587    0.000\n   .lone5             0.092    0.009   10.119    0.000\n    i                 0.075    0.008    9.531    0.000\n\n\n\n\n\nCode# 002_Linear growth model\nlinear &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5'\nfit_linear &lt;- growth(linear, data = data)\nsummary(fit_linear, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 49 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                75.244\n  Degrees of freedom                                10\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.852\n  Tucker-Lewis Index (TLI)                       0.852\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -759.040\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1538.080\n  Bayesian (BIC)                              1575.795\n  Sample-size adjusted Bayesian (SABIC)       1544.076\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.143\n  90 Percent confidence interval - lower         0.113\n  90 Percent confidence interval - upper         0.174\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.097\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s                -0.015    0.002   -6.246    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i                 1.466    0.024   62.031    0.000\n    s                -0.025    0.004   -5.784    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.059    0.010    5.761    0.000\n   .lone2             0.114    0.011   10.114    0.000\n   .lone3             0.172    0.015   11.659    0.000\n   .lone4             0.114    0.010   11.066    0.000\n   .lone5             0.047    0.010    4.929    0.000\n    i                 0.139    0.015    9.310    0.000\n    s                 0.003    0.001    5.839    0.000\n\n\n\n\n\nCode# 003_Quadratic growth curve model\nquadratic &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n           q =~ 0*lone1 + 1*lone2 + 9*lone3 + 16*lone4 + 36*lone5'\nfit_quadratic &lt;- growth(quadratic, data = data)\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_quadratic, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 76 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                46.671\n  Degrees of freedom                                 6\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.908\n  Tucker-Lewis Index (TLI)                       0.846\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -744.754\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1517.507\n  Bayesian (BIC)                              1570.308\n  Sample-size adjusted Bayesian (SABIC)       1525.902\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.145\n  90 Percent confidence interval - lower         0.108\n  90 Percent confidence interval - upper         0.185\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.998\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.074\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n  q =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             9.000                           \n    lone4            16.000                           \n    lone5            36.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s                -0.020    0.009   -2.179    0.029\n    q                 0.000    0.001    0.265    0.791\n  s ~~                                                \n    q                -0.002    0.001   -1.792    0.073\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i                 1.446    0.024   60.828    0.000\n    s                 0.017    0.014    1.284    0.199\n    q                -0.007    0.002   -3.384    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.037    0.014    2.584    0.010\n   .lone2             0.118    0.012    9.942    0.000\n   .lone3             0.144    0.014   10.115    0.000\n   .lone4             0.099    0.011    8.672    0.000\n   .lone5             0.099    0.027    3.684    0.000\n    i                 0.148    0.019    7.974    0.000\n    s                 0.018    0.007    2.697    0.007\n    q                 0.000    0.000    0.959    0.337"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#nested-model-comparisons",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#nested-model-comparisons",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Nested model comparisons",
    "text": "Nested model comparisons\nModels 1, 2 and 3 can be compared since Models 1 and 2 are nested in (i.e., reduced or constrained forms of) Model 3 (i.e., the full or free model). Model 1 is also a reduced form of Model 2. In this way, the best model to data correspondence can be determined through a Chi squared (\\(\\chi^2\\)) difference test or a likelihood ratio test (LRT). If the LRT or the \\(\\chi^2\\) difference is significant (\\(p &lt; .05\\)), it means that the full model fits the data significantly better than the reduced or constrained model. Therefore, reject the reduced or constrained model in favor of the full model.\n\n\n\n\n\n\nYou should only compare models whose fit indices are acceptable. Therefore, in a real scenario, we would not compare Models 1 and 2 since theY do not reach acceptable model fit.\n\n\n\nIn the examples here, Model 3 is the best model representation of the data (at least, the best fitting model, although the RMSEA and TLI are not good enough). The non-linear growth function in Model 3 reproduces the trajectory observed when examining the mean values in the univariate descriptives. see here\n\nCode#The `anova` function in `lavaan` computes the LRT for nested models.\ncompare_no_linear &lt;- anova(fit_nogrowth, fit_linear)\ncompare_no_linear\n\n\nChi-Squared Difference Test\n\n             Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit_linear   10 1538.1 1575.8  75.244                                          \nfit_nogrowth 13 1643.3 1669.7 186.433     111.19 0.33518       3  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe results (\\(\\chi^2\\)(3) = 111.19, \\(p &lt; .001\\)) show significant difference in model fit between Model 1 (no growth mode, or reduced model) and Model 2 (linear growth, full model). Thus, Model 2, in which the linear growth factor is freely estimated (relative to Model 1) has improved data to model correspondence (or fits better) than Model 1. Therefore, Model 1 or the no growth model is rejected in favor of Model 2, the linear growth model.\nAll models can also be compared to determine the best fitting of the three models as follows\n\nCode#The `anova` function in `lavaan` computes the LRT for nested models.\ncompare_no_linear_qua &lt;- anova(fit_nogrowth, fit_linear, fit_quadratic)\ncompare_no_linear_qua\n\n\nChi-Squared Difference Test\n\n              Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)\nfit_quadratic  6 1517.5 1570.3  46.671                                      \nfit_linear    10 1538.1 1575.8  75.244     28.573 0.13834       4  9.546e-06\nfit_nogrowth  13 1643.3 1669.7 186.433    111.189 0.33518       3  &lt; 2.2e-16\n                 \nfit_quadratic    \nfit_linear    ***\nfit_nogrowth  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nRemember that this is just an example of how to compare nested models, and that you should only compare models whose fit indices are acceptable.\n\n\n\nIf the LRT or the \\(\\chi^2\\) difference test returned a non-significant result (\\(p &gt; .05\\)), then both Models 1 and 2 would be assumed to have no significant difference in model fit and thus, equally fit the data well. In this case, Model 1 (ie., the reduced model) which is a more parsimonious model compared to Model 2 should be selected as the best representation of model to data correspondence."
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#bilinearsplinepiecewisemultiphase-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#bilinearsplinepiecewisemultiphase-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Bilinear/Spline/Piecewise/Multiphase growth models",
    "text": "Bilinear/Spline/Piecewise/Multiphase growth models\nThe Quadratic growth curve model is specified by adding a second-order power of time to the Linear growth curve model, which means that there would be a high correlation between the power terms. This can be resolved by centering the intercept growth factor in the middle of the observation, but becomes more difficult when moving to higher-order polynomials. For this reason, it is recommended to examine the data if a Piecewise growth curve model could be an alternative solution. The most common type is the Bilinear growth curve model which joins two linear growth factors. It also goes by the name Spline growth model and Multiphase growth model. They can accommodate different linear or nonlinear growth functions by segmenting the period of observation with a knot point often called transition points when there are theoretical reasons to separate the observations into discrete phases - hence their name Multiphase growth model. For example, they can be used to model developmental changes that occur during pre-school, primary school and high school with transition points at when a child begins primary school and also at when s/he begins high school.\n\n\nModel 4_1\nModel 4_2\nModel 4_3\n\n\n\n\nCode# 004_Bilinear/Spline growth model\nbilinear &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s1 =~ 0*lone1 + 1*lone2 + 3*lone3 + 3*lone4 + 3*lone5\n           s2 =~ 0*lone1 + 0*lone2 + 0*lone3 + 1*lone4 + 3*lone5'\nfit_bilinear &lt;- growth(bilinear, data = data)\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_bilinear, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 67 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                40.781\n  Degrees of freedom                                 6\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.921\n  Tucker-Lewis Index (TLI)                       0.869\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -741.809\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1511.618\n  Bayesian (BIC)                              1564.418\n  Sample-size adjusted Bayesian (SABIC)       1520.012\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.134\n  90 Percent confidence interval - lower         0.097\n  90 Percent confidence interval - upper         0.175\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.991\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.074\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s1 =~                                               \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             3.000                           \n    lone5             3.000                           \n  s2 =~                                               \n    lone1             0.000                           \n    lone2             0.000                           \n    lone3             0.000                           \n    lone4             1.000                           \n    lone5             3.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s1               -0.015    0.005   -2.851    0.004\n    s2               -0.019    0.004   -5.012    0.000\n  s1 ~~                                               \n    s2                0.000    0.002    0.083    0.934\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i                 1.444    0.024   61.016    0.000\n    s1                0.007    0.008    0.807    0.420\n    s2               -0.059    0.008   -7.002    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.046    0.012    3.772    0.000\n   .lone2             0.114    0.011   10.134    0.000\n   .lone3             0.130    0.016    8.057    0.000\n   .lone4             0.106    0.011    9.719    0.000\n   .lone5             0.082    0.022    3.665    0.000\n    i                 0.140    0.017    8.385    0.000\n    s1                0.008    0.002    3.404    0.001\n    s2                0.002    0.004    0.571    0.568\n\n\n\n\n\nCode# 004_2_Bilinear/Spline growth model - 2\nbilinear_2 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s1 =~ -3*lone1 + -2*lone2 + 0*lone3 + 0*lone4 + 0*lone5\n           s2 =~ 0*lone1 + 0*lone2 + 0*lone3 + 1*lone4 + 3*lone5'\nfit_bilinear_2 &lt;- growth(bilinear_2, data = data)\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_bilinear_2, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 62 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                40.781\n  Degrees of freedom                                 6\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.921\n  Tucker-Lewis Index (TLI)                       0.869\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -741.809\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1511.618\n  Bayesian (BIC)                              1564.418\n  Sample-size adjusted Bayesian (SABIC)       1520.012\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.134\n  90 Percent confidence interval - lower         0.097\n  90 Percent confidence interval - upper         0.175\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.991\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.074\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s1 =~                                               \n    lone1            -3.000                           \n    lone2            -2.000                           \n    lone3             0.000                           \n    lone4             0.000                           \n    lone5             0.000                           \n  s2 =~                                               \n    lone1             0.000                           \n    lone2             0.000                           \n    lone3             0.000                           \n    lone4             1.000                           \n    lone5             3.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s1                0.010    0.005    2.009    0.045\n    s2               -0.018    0.006   -3.254    0.001\n  s1 ~~                                               \n    s2                0.000    0.002    0.083    0.934\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i                 1.465    0.025   57.734    0.000\n    s1                0.007    0.008    0.807    0.420\n    s2               -0.059    0.008   -7.002    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.046    0.012    3.772    0.000\n   .lone2             0.114    0.011   10.134    0.000\n   .lone3             0.130    0.016    8.057    0.000\n   .lone4             0.106    0.011    9.719    0.000\n   .lone5             0.082    0.022    3.665    0.000\n    i                 0.126    0.018    7.130    0.000\n    s1                0.008    0.002    3.404    0.001\n    s2                0.002    0.004    0.571    0.568\n\n\n\n\n\nCode# 004_3_Bilinear/Spline growth model - 3\nbilinear_3 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s1 =~ -3*lone1 + -3*lone2 + -3*lone3 + -2*lone4 + 0*lone5\n           s2 =~ -3*lone1 + -2*lone2 + 0*lone3 + 0*lone4 + 0*lone5'\nfit_bilinear_3 &lt;- growth(bilinear_3, data = data)\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_bilinear_3, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 68 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                40.781\n  Degrees of freedom                                 6\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.921\n  Tucker-Lewis Index (TLI)                       0.869\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -741.809\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1511.618\n  Bayesian (BIC)                              1564.418\n  Sample-size adjusted Bayesian (SABIC)       1520.012\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.134\n  90 Percent confidence interval - lower         0.097\n  90 Percent confidence interval - upper         0.175\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.991\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.074\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s1 =~                                               \n    lone1            -3.000                           \n    lone2            -3.000                           \n    lone3            -3.000                           \n    lone4            -2.000                           \n    lone5             0.000                           \n  s2 =~                                               \n    lone1            -3.000                           \n    lone2            -2.000                           \n    lone3             0.000                           \n    lone4             0.000                           \n    lone5             0.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s1               -0.012    0.008   -1.377    0.168\n    s2                0.011    0.003    3.342    0.001\n  s1 ~~                                               \n    s2                0.000    0.002    0.083    0.934\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i                 1.288    0.019   68.489    0.000\n    s1               -0.059    0.008   -7.002    0.000\n    s2                0.007    0.008    0.807    0.420\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.046    0.012    3.772    0.000\n   .lone2             0.114    0.011   10.134    0.000\n   .lone3             0.130    0.016    8.057    0.000\n   .lone4             0.106    0.011    9.719    0.000\n   .lone5             0.082    0.022    3.665    0.000\n    i                 0.036    0.022    1.637    0.102\n    s1                0.002    0.004    0.571    0.568\n    s2                0.008    0.002    3.404    0.001"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#growth-models-with-time--varying-and-invariant-predictors-and-distal-outcomes",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#growth-models-with-time--varying-and-invariant-predictors-and-distal-outcomes",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Growth models with time- varying and invariant predictors and distal outcomes",
    "text": "Growth models with time- varying and invariant predictors and distal outcomes\nDynamic predictors that change across time can be incorporated into the growth model to simultaneously estimate the overall rate of change and the change from the time-varying predictors. These dynamic, time-varying predictors account for within-person changes by altering the trajectory of growth in an individual.\nBetween-person differences in the within-person rate of change can be explained by the inclusion of time invariant predictors such as gender or experimental conditions.\nGrowth factors can also be hypothesized to predict distal outcomes that are measured after the growth process such as the rate of change in metacognitve therapy predicting recovery status in a 24-month follow up.\n\n\nModel 5\nModel 6\nModel 7\nModel 8\n\n\n\n\nCode# 005_Linear growth model with time-varying covariates \ntimevaryingcov &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n# Time-varying covariates\nlone1 ~ host1             #lone1 ~ eq*host1\nlone2 ~ host2             #lone2 ~ eq*host2\nlone3 ~ host3             #lone3 ~ eq*host3\nlone4 ~ host4             #lone4 ~ eq*host4\nlone5 ~ host5             #lone5 ~ eq*host5\n\n#Estimate the means of the TVC\nhost1 ~ 1\nhost2 ~ 1\nhost3 ~ 1\nhost4 ~ 1\nhost5 ~ 1\n\n#Estimate covariance between TVC\nhost1 ~~ host2 + host3 + host4 + host5\nhost2 ~~ host3 + host4 + host5\nhost3 ~~ host4 + host5\nhost4 ~~ host5'\n\nfit_timevaryingcov &lt;- growth(timevaryingcov, data = data)\nsummary(fit_timevaryingcov, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 113 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        35\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               103.191\n  Degrees of freedom                                30\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              2956.213\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.975\n  Tucker-Lewis Index (TLI)                       0.962\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -659.170\n  Loglikelihood unrestricted model (H1)       -607.575\n                                                      \n  Akaike (AIC)                                1388.340\n  Bayesian (BIC)                              1520.341\n  Sample-size adjusted Bayesian (SABIC)       1409.326\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.087\n  90 Percent confidence interval - lower         0.069\n  90 Percent confidence interval - upper         0.106\n  P-value H_0: RMSEA &lt;= 0.050                    0.001\n  P-value H_0: RMSEA &gt;= 0.080                    0.755\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.059\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lone1 ~                                             \n    host1             0.719    0.017   41.813    0.000\n  lone2 ~                                             \n    host2             0.722    0.014   52.466    0.000\n  lone3 ~                                             \n    host3             0.738    0.012   63.080    0.000\n  lone4 ~                                             \n    host4             0.735    0.015   48.645    0.000\n  lone5 ~                                             \n    host5             0.737    0.022   33.693    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  host1 ~~                                            \n    host2             0.161    0.018    8.703    0.000\n    host3             0.105    0.018    5.860    0.000\n    host4             0.053    0.013    4.153    0.000\n    host5             0.036    0.011    3.452    0.001\n  host2 ~~                                            \n    host3             0.158    0.021    7.358    0.000\n    host4             0.079    0.015    5.286    0.000\n    host5             0.052    0.012    4.247    0.000\n  host3 ~~                                            \n    host4             0.120    0.016    7.325    0.000\n    host5             0.069    0.013    5.280    0.000\n  host4 ~~                                            \n    host5             0.064    0.010    6.527    0.000\n  i ~~                                                \n    s                -0.003    0.001   -4.609    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    host1             1.432    0.028   51.297    0.000\n    host2             1.459    0.032   45.207    0.000\n    host3             1.535    0.034   45.422    0.000\n    host4             1.311    0.025   52.956    0.000\n    host5             1.294    0.021   62.524    0.000\n    i                 0.414    0.026   15.690    0.000\n    s                -0.010    0.007   -1.399    0.162\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.024    0.003    7.834    0.000\n   .lone2             0.025    0.003    9.540    0.000\n   .lone3             0.038    0.003   11.346    0.000\n   .lone4             0.031    0.003   10.917    0.000\n   .lone5             0.017    0.003    5.695    0.000\n    host1             0.250    0.020   12.669    0.000\n    host2             0.334    0.026   12.669    0.000\n    host3             0.367    0.029   12.669    0.000\n    host4             0.197    0.016   12.669    0.000\n    host5             0.138    0.011   12.669    0.000\n    i                 0.028    0.003    8.206    0.000\n    s                 0.001    0.000    4.757    0.000\n\n\n\n\n\nCode# 006_Linear growth model with time invariant covariates \ntimeinvar &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n\n# Time invariant covariates\ni ~ female\ns ~ female'\nfit_timeinvar &lt;- growth(timeinvar, data = data)\nsummary(fit_timeinvar, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 55 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n                                                  Used       Total\n  Number of observations                           320         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                86.716\n  Degrees of freedom                                13\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               475.777\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.840\n  Tucker-Lewis Index (TLI)                       0.815\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -741.159\n  Loglikelihood unrestricted model (H1)       -697.801\n                                                      \n  Akaike (AIC)                                1506.319\n  Bayesian (BIC)                              1551.538\n  Sample-size adjusted Bayesian (SABIC)       1513.476\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.133\n  90 Percent confidence interval - lower         0.107\n  90 Percent confidence interval - upper         0.160\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.090\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~                                                 \n    female           -0.132    0.047   -2.804    0.005\n  s ~                                                 \n    female            0.007    0.009    0.784    0.433\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .i ~~                                                \n   .s                -0.015    0.002   -6.079    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .i                 1.526    0.031   48.551    0.000\n   .s                -0.029    0.006   -4.999    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.062    0.010    6.025    0.000\n   .lone2             0.112    0.011   10.064    0.000\n   .lone3             0.171    0.015   11.628    0.000\n   .lone4             0.107    0.010   10.953    0.000\n   .lone5             0.051    0.010    5.322    0.000\n   .i                 0.134    0.015    9.164    0.000\n   .s                 0.003    0.001    5.522    0.000\n\n\n\n\n\nCode# 007_Linear growth model with time invariant and time-varying covariates \ntimeinvartimevar &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n                       s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n# Time-varying covariates held equal\nlone1 ~ eq*host1\nlone2 ~ eq*host2\nlone3 ~ eq*host3\nlone4 ~ eq*host4\nlone5 ~ eq*host5\n\n# Time invariant covariates\ni ~ female + pdu1 + ace1\ns ~ female + pdu1 + ace1\n    \n#Estimate the means of TVC and TIC\nhost1 ~ 1\nhost2 ~ 1\nhost3 ~ 1\nhost4 ~ 1\nhost5 ~ 1\nfemale ~ 1\npdu1 ~ 1\nace1 ~ 1\n\n#Estimate covariances between TIC with TVC\nace1 ~~ female + pdu1 + host1 + host2 + host3 + host4 + host5\nfemale ~~ pdu1 + host1 + host2 + host3 + host4 + host5\npdu1 ~~ host1 + host2 + host3 + host4 + host5\nhost1 ~~ host2 + host3 + host4 + host5\nhost2 ~~ host3 + host4 + host5\nhost3 ~~ host4 + host5\nhost4 ~~ host5\n\n#Fix covariances between TIC and growth factors to zero\ni ~~ 0*host1 \ni ~~ 0*host2 \ni ~~ 0*host3 \ni ~~ 0*host4\ni ~~ 0*host5\n\ns ~~ 0*host1 \ns ~~ 0*host2 \ns ~~ 0*host3 \ns ~~ 0*host4\ns ~~ 0*host5\n'\nfit_timeinvar_timevar &lt;- growth(timeinvartimevar, data = data)\nsummary(fit_timeinvar_timevar, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 117 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        65\n  Number of equality constraints                     4\n\n                                                  Used       Total\n  Number of observations                           320         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               102.364\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3080.206\n  Degrees of freedom                                78\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.980\n  Tucker-Lewis Index (TLI)                       0.964\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1389.597\n  Loglikelihood unrestricted model (H1)      -1338.415\n                                                      \n  Akaike (AIC)                                2901.193\n  Bayesian (BIC)                              3131.061\n  Sample-size adjusted Bayesian (SABIC)       2937.580\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.066\n  90 Percent confidence interval - lower         0.049\n  90 Percent confidence interval - upper         0.082\n  P-value H_0: RMSEA &lt;= 0.050                    0.056\n  P-value H_0: RMSEA &gt;= 0.080                    0.078\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.036\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lone1 ~                                             \n    host1     (eq)    0.726    0.011   66.961    0.000\n  lone2 ~                                             \n    host2     (eq)    0.726    0.011   66.961    0.000\n  lone3 ~                                             \n    host3     (eq)    0.726    0.011   66.961    0.000\n  lone4 ~                                             \n    host4     (eq)    0.726    0.011   66.961    0.000\n  lone5 ~                                             \n    host5     (eq)    0.726    0.011   66.961    0.000\n  i ~                                                 \n    female           -0.130    0.021   -6.166    0.000\n    pdu1              0.006    0.015    0.409    0.683\n    ace1              0.082    0.021    3.828    0.000\n  s ~                                                 \n    female            0.008    0.005    1.752    0.080\n    pdu1              0.001    0.003    0.320    0.749\n    ace1             -0.003    0.005   -0.713    0.476\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  female ~~                                           \n    ace1             -0.002    0.014   -0.168    0.866\n  pdu1 ~~                                             \n    ace1              0.074    0.021    3.536    0.000\n  host1 ~~                                            \n    ace1              0.035    0.014    2.480    0.013\n  host2 ~~                                            \n    ace1              0.053    0.016    3.249    0.001\n  host3 ~~                                            \n    ace1              0.049    0.017    2.865    0.004\n  host4 ~~                                            \n    ace1              0.029    0.012    2.391    0.017\n  host5 ~~                                            \n    ace1              0.047    0.011    4.394    0.000\n  female ~~                                           \n    pdu1              0.015    0.020    0.719    0.472\n  host1 ~~                                            \n    female            0.004    0.014    0.256    0.798\n  host2 ~~                                            \n    female           -0.025    0.016   -1.578    0.114\n  host3 ~~                                            \n    female            0.007    0.017    0.426    0.670\n  host4 ~~                                            \n    female            0.008    0.012    0.682    0.495\n  host5 ~~                                            \n    female           -0.007    0.010   -0.719    0.472\n  host1 ~~                                            \n    pdu1              0.108    0.021    5.033    0.000\n  host2 ~~                                            \n    pdu1              0.107    0.024    4.378    0.000\n  host3 ~~                                            \n    pdu1              0.093    0.025    3.661    0.000\n  host4 ~~                                            \n    pdu1              0.050    0.018    2.767    0.006\n  host5 ~~                                            \n    pdu1              0.027    0.015    1.817    0.069\n  host1 ~~                                            \n    host2             0.161    0.019    8.683    0.000\n    host3             0.105    0.018    5.837    0.000\n    host4             0.054    0.013    4.345    0.000\n    host5             0.037    0.010    3.567    0.000\n  host2 ~~                                            \n    host3             0.157    0.021    7.330    0.000\n    host4             0.082    0.015    5.544    0.000\n    host5             0.054    0.012    4.409    0.000\n  host3 ~~                                            \n    host4             0.124    0.016    7.607    0.000\n    host5             0.071    0.013    5.459    0.000\n  host4 ~~                                            \n    host5             0.059    0.009    6.220    0.000\n .i ~~                                                \n    host1             0.000                           \n    host2             0.000                           \n    host3             0.000                           \n    host4             0.000                           \n    host5             0.000                           \n .s ~~                                                \n    host1             0.000                           \n    host2             0.000                           \n    host3             0.000                           \n    host4             0.000                           \n    host5             0.000                           \n .i ~~                                                \n   .s                -0.002    0.001   -4.287    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    host1             1.433    0.028   51.188    0.000\n    host2             1.460    0.032   45.155    0.000\n    host3             1.537    0.034   45.385    0.000\n    host4             1.306    0.024   53.812    0.000\n    host5             1.291    0.021   62.945    0.000\n    female            0.444    0.028   15.978    0.000\n    pdu1              2.079    0.041   50.747    0.000\n    ace1              1.949    0.028   69.642    0.000\n   .i                 0.292    0.049    5.926    0.000\n   .s                -0.005    0.010   -0.489    0.625\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.024    0.003    8.113    0.000\n   .lone2             0.025    0.003    9.668    0.000\n   .lone3             0.038    0.003   11.402    0.000\n   .lone4             0.031    0.003   10.955    0.000\n   .lone5             0.017    0.003    5.726    0.000\n    host1             0.251    0.020   12.649    0.000\n    host2             0.335    0.026   12.649    0.000\n    host3             0.367    0.029   12.649    0.000\n    host4             0.188    0.015   12.649    0.000\n    host5             0.135    0.011   12.649    0.000\n    female            0.247    0.020   12.649    0.000\n    pdu1              0.537    0.042   12.649    0.000\n    ace1              0.251    0.020   12.649    0.000\n   .i                 0.022    0.003    7.396    0.000\n   .s                 0.001    0.000    4.673    0.000\n\n\n\n\n\nCode# 008_Linear growth model with growth factors predicting distal outcomes \ndistal &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n                       s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n\n# Regress distal outcome on growth factors\nsubs5 ~ i + s\n\n#Estimate the intercept of distal outcome (subs5)\nsubs5 ~ 1'\nfit_distal &lt;- growth(distal, data = data)\nsummary(fit_distal, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 62 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           290         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                74.672\n  Degrees of freedom                                13\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               438.031\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.854\n  Tucker-Lewis Index (TLI)                       0.832\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1240.424\n  Loglikelihood unrestricted model (H1)      -1203.087\n                                                      \n  Akaike (AIC)                                2508.847\n  Bayesian (BIC)                              2560.226\n  Sample-size adjusted Bayesian (SABIC)       2515.829\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.128\n  90 Percent confidence interval - lower         0.101\n  90 Percent confidence interval - upper         0.157\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.998\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.086\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  subs5 ~                                             \n    i                 0.896    0.398    2.251    0.024\n    s                 5.889    3.222    1.828    0.068\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s                -0.015    0.003   -5.793    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .subs5            -0.006    0.539   -0.011    0.991\n    i                 1.466    0.025   58.598    0.000\n    s                -0.023    0.004   -5.114    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.055    0.011    5.231    0.000\n   .lone2             0.118    0.012    9.727    0.000\n   .lone3             0.171    0.015   11.052    0.000\n   .lone4             0.122    0.012   10.569    0.000\n   .lone5             0.052    0.011    4.929    0.000\n   .subs5             2.365    0.200   11.825    0.000\n    i                 0.142    0.016    8.925    0.000\n    s                 0.003    0.001    5.308    0.000"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#multiple-group-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#multiple-group-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Multiple group growth models",
    "text": "Multiple group growth models\nThe T 006_Linear growth model with time invariant covariate does not tell us anything about variances and covariances among growth factors, residual variability, and the structure of the within-person changes. A Multiple-group growth model approach offers greater flexibility in explaining between-person differences in the within-person rate of change than the Growth model with time invariant covariate. For example, the Wald test of differences in growth parameters can be tested within the multiple-group approach to explain whether, on average, the experimental group experience greater overall decline than the control group - thus providing insights into how and why individuals differ in their rate of change and by how much difference.\nThe multiple-group approach can inform about differences in all the growth function parameters - including the growth factors’ means, co/variances and residual variances. Thus, providing information about the differences in the overall rate of change, the extent of variability in the initial status and rate of change as well differences in the extent of fluctuations around individuals own trajectories across the groups.\nTake for example, the feeling of loneliness among boys and girls. In addition to investigating significant differences in the predicted outcome at baseline or initial status (i.e., intercept) and rate of overall change (i.e., slope), we can also investigate differences in the amounts of variability at the between and within levels of the growth model and may find that boys show greater variability in the intercept and slope indicating that boys’ trajectories are more different from one another than girls’ trajectories. The structure of within-person changes may also vary such that boys may show slower decline than girls in the feeling of loneliness. We can thus conclude, boys and girls differ in their baseline, and the average growth trajectories of loneliness, the extent of between-person differences in those trajectories and the extent of variability around their individual trajectories.\nThe multigroup approach can tell us why and how groups of people significantly differ and by how much difference in their trajectories or development over time.\n\n\nModel 9_1\nModel 9_2\nModel 9_3\nModel 9_4\n\n\n\n\nCode# 009_1_Multigroup LGCM M1 Invariance model - M1\nmultigroupM1 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n#Growth factor means constrained equal\ni ~ c(int, int)*1\ns ~ c(slp, slp)*1\n\n#Growth factor variances held equal\ni ~~ c(vint, vint)*i\ns ~~ c(vslp, vslp)*s\n\n#Growth factor covariances held equal\ni ~~ c(cvf, cvf)*s\n\n#Residual variances of observed items held equal\nlone1 ~~ c(res, res)*lone1\nlone2 ~~ c(res, res)*lone2\nlone3 ~~ c(res, res)*lone3\nlone4 ~~ c(res, res)*lone4\nlone5 ~~ c(res, res)*lone5\n'\nfit_multigroupM1 &lt;- growth(multigroupM1, data = data, group = \"female\")\n\nWarning: lavaan-&gt;lav_data_full():  \n   group variable 'female' contains missing values\n\nCodesummary(fit_multigroupM1, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n  Number of equality constraints                    14\n\n  Number of observations per group:               Used       Total\n    0                                              178         222\n    1                                              142         193\n\nModel Test User Model:\n                                                      \n  Test statistic                               207.477\n  Degrees of freedom                                34\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    0                                           98.099\n    1                                          109.378\n\nModel Test Baseline Model:\n\n  Test statistic                               463.335\n  Degrees of freedom                                20\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.609\n  Tucker-Lewis Index (TLI)                       0.770\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -776.723\n  Loglikelihood unrestricted model (H1)       -672.984\n                                                      \n  Akaike (AIC)                                1565.445\n  Bayesian (BIC)                              1588.055\n  Sample-size adjusted Bayesian (SABIC)       1569.024\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.179\n  90 Percent confidence interval - lower         0.156\n  90 Percent confidence interval - upper         0.202\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.230\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [0]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s        (cvf)   -0.011    0.002   -4.425    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i        (int)    1.484    0.025   60.198    0.000\n    s        (slp)   -0.026    0.004   -5.932    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vint)    0.135    0.016    8.666    0.000\n    s       (vslp)    0.001    0.001    2.467    0.014\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\nGroup 2 [1]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s        (cvf)   -0.011    0.002   -4.425    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i        (int)    1.484    0.025   60.198    0.000\n    s        (slp)   -0.026    0.004   -5.932    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vint)    0.135    0.016    8.666    0.000\n    s       (vslp)    0.001    0.001    2.467    0.014\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\n\n\n\nCode# 009_2_Multigroup LGCM M2 Free factor means - M2\nmultigroupM2 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n#Growth factor means freely estimated\ni ~ c(intm, intf)*1\ns ~ c(slpm, slpf)*1\n\n#Growth factor variances held equal\ni ~~ c(vint, vint)*i\ns ~~ c(vslp, vslp)*s\n\n#Growth factor covariances held equal\ni ~~ c(cvf, cvf)*s\n\n#Residual variances of observed items held equal\nlone1 ~~ c(res, res)*lone1\nlone2 ~~ c(res, res)*lone2\nlone3 ~~ c(res, res)*lone3\nlone4 ~~ c(res, res)*lone4\nlone5 ~~ c(res, res)*lone5\n'\nfit_multigroupM2 &lt;- growth(multigroupM2, data = data, group = \"female\")\n\nWarning: lavaan-&gt;lav_data_full():  \n   group variable 'female' contains missing values\n\nCodesummary(fit_multigroupM2, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 34 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n  Number of equality constraints                    12\n\n  Number of observations per group:               Used       Total\n    0                                              178         222\n    1                                              142         193\n\nModel Test User Model:\n                                                      \n  Test statistic                               196.543\n  Degrees of freedom                                32\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    0                                           94.352\n    1                                          102.191\n\nModel Test Baseline Model:\n\n  Test statistic                               463.335\n  Degrees of freedom                                20\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.629\n  Tucker-Lewis Index (TLI)                       0.768\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -771.255\n  Loglikelihood unrestricted model (H1)       -672.984\n                                                      \n  Akaike (AIC)                                1558.511\n  Bayesian (BIC)                              1588.657\n  Sample-size adjusted Bayesian (SABIC)       1563.283\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.179\n  90 Percent confidence interval - lower         0.156\n  90 Percent confidence interval - upper         0.204\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.213\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [0]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s        (cvf)   -0.010    0.002   -4.331    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intm)    1.550    0.033   47.589    0.000\n    s       (slpm)   -0.031    0.006   -5.236    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vint)    0.130    0.015    8.547    0.000\n    s       (vslp)    0.001    0.001    2.425    0.015\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\nGroup 2 [1]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s        (cvf)   -0.010    0.002   -4.331    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intf)    1.401    0.036   38.400    0.000\n    s       (slpf)   -0.020    0.007   -3.062    0.002\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vint)    0.130    0.015    8.547    0.000\n    s       (vslp)    0.001    0.001    2.425    0.015\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\n\n\n\nCode# 009_3_Multigroup LGCM M3 Free factor means and co/variances - M3\nmultigroupM3 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n#Growth factor means freely estimated\ni ~ c(intm, intf)*1\ns ~ c(slpm, slpf)*1\n\n#Growth factor variances freely estimated\ni ~~ c(vinm, vinf)*i\ns ~~ c(vslm, vslf)*s\n\n#Growth factor covariances freely estimated\ni ~~ c(covm, covf)*s\n\n#Residual variances of observed items held equal\nlone1 ~~ c(res, res)*lone1\nlone2 ~~ c(res, res)*lone2\nlone3 ~~ c(res, res)*lone3\nlone4 ~~ c(res, res)*lone4\nlone5 ~~ c(res, res)*lone5\n'\nfit_multigroupM3 &lt;- growth(multigroupM3, data = data, group = \"female\")\n\nWarning: lavaan-&gt;lav_data_full():  \n   group variable 'female' contains missing values\n\nCodesummary(fit_multigroupM3, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 82 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n  Number of equality constraints                     9\n\n  Number of observations per group:               Used       Total\n    0                                              178         222\n    1                                              142         193\n\nModel Test User Model:\n                                                      \n  Test statistic                               186.447\n  Degrees of freedom                                29\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    0                                           90.667\n    1                                           95.780\n\nModel Test Baseline Model:\n\n  Test statistic                               463.335\n  Degrees of freedom                                20\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.645\n  Tucker-Lewis Index (TLI)                       0.755\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -766.208\n  Loglikelihood unrestricted model (H1)       -672.984\n                                                      \n  Akaike (AIC)                                1554.415\n  Bayesian (BIC)                              1595.867\n  Sample-size adjusted Bayesian (SABIC)       1560.977\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.184\n  90 Percent confidence interval - lower         0.159\n  90 Percent confidence interval - upper         0.210\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.177\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [0]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s       (covm)   -0.015    0.004   -4.140    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intm)    1.550    0.036   43.187    0.000\n    s       (slpm)   -0.031    0.006   -4.949    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vinm)    0.170    0.024    6.957    0.000\n    s       (vslm)    0.002    0.001    2.662    0.008\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\nGroup 2 [1]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s       (covf)   -0.004    0.003   -1.484    0.138\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intf)    1.401    0.031   44.901    0.000\n    s       (slpf)   -0.020    0.006   -3.321    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vinf)    0.079    0.017    4.753    0.000\n    s       (vslf)    0.000    0.001    0.569    0.569\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\n\n\n\nCode# 009_4_Multigroup LGCM M4 Free factor means and co/variances - M4\nmultigroupM4 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n#Growth factor means freely estimated\ni ~ c(intm, intf)*1\ns ~ c(slpm, slpf)*1\n\n#Growth factor variances freely estimated\ni ~~ c(vinm, vinf)*i\ns ~~ c(vslm, vslf)*s\n\n#Growth factor covariances freely estimated\ni ~~ c(covm, covf)*s\n\n#Residual variances of observed items freely estimated across groups but held equal within groups\nlone1 ~~ c(rsm, rsf)*lone1\nlone2 ~~ c(rsm, rsf)*lone2\nlone3 ~~ c(rsm, rsf)*lone3\nlone4 ~~ c(rsm, rsf)*lone4\nlone5 ~~ c(rsm, rsf)*lone5\n'\nfit_multigroupM4 &lt;- growth(multigroupM4, data = data, group = \"female\")\n\nWarning: lavaan-&gt;lav_data_full():  \n   group variable 'female' contains missing values\n\nCodesummary(fit_multigroupM4, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 49 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n  Number of equality constraints                     8\n\n  Number of observations per group:               Used       Total\n    0                                              178         222\n    1                                              142         193\n\nModel Test User Model:\n                                                      \n  Test statistic                               178.403\n  Degrees of freedom                                28\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    0                                           87.439\n    1                                           90.964\n\nModel Test Baseline Model:\n\n  Test statistic                               463.335\n  Degrees of freedom                                20\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.661\n  Tucker-Lewis Index (TLI)                       0.758\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -762.185\n  Loglikelihood unrestricted model (H1)       -672.984\n                                                      \n  Akaike (AIC)                                1548.371\n  Bayesian (BIC)                              1593.591\n  Sample-size adjusted Bayesian (SABIC)       1555.529\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.183\n  90 Percent confidence interval - lower         0.158\n  90 Percent confidence interval - upper         0.209\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.172\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [0]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s       (covm)   -0.014    0.004   -3.668    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intm)    1.550    0.036   43.187    0.000\n    s       (slpm)   -0.031    0.006   -4.949    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vinm)    0.163    0.025    6.632    0.000\n    s       (vslm)    0.001    0.001    1.842    0.065\n   .lone1    (rsm)    0.121    0.007   16.340    0.000\n   .lone2    (rsm)    0.121    0.007   16.340    0.000\n   .lone3    (rsm)    0.121    0.007   16.340    0.000\n   .lone4    (rsm)    0.121    0.007   16.340    0.000\n   .lone5    (rsm)    0.121    0.007   16.340    0.000\n\n\nGroup 2 [1]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s       (covf)   -0.006    0.003   -2.146    0.032\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intf)    1.401    0.031   44.901    0.000\n    s       (slpf)   -0.020    0.006   -3.321    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vinf)    0.087    0.017    5.217    0.000\n    s       (vslf)    0.001    0.001    1.565    0.118\n   .lone1    (rsf)    0.093    0.006   14.595    0.000\n   .lone2    (rsf)    0.093    0.006   14.595    0.000\n   .lone3    (rsf)    0.093    0.006   14.595    0.000\n   .lone4    (rsf)    0.093    0.006   14.595    0.000\n   .lone5    (rsf)    0.093    0.006   14.595    0.000"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#nested-model-comparisons-in-the-multigroup-lgcm",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#nested-model-comparisons-in-the-multigroup-lgcm",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Nested model comparisons in the Multigroup LGCM",
    "text": "Nested model comparisons in the Multigroup LGCM\nModels 9_1, 9_2, 9_3 and 9_4 can be compared since the first three are all nested in Model 9_4 (i.e., they are reduced or constrained forms of the full model in Model 9_4), and the first two are nested in Model 9_3 with Model 9_1 also nested in Model 9_2. The same approach for selecting the best-fitting model as in the comparisons of Models 1, 2, and 3 is employed here too.\nIf the LRT or the \\(\\chi^2\\) difference is significant (\\(p &lt; .05\\)), it means that the full model fits the data significant better than the reduced or constrained model.\nThe constraints in each of the models have implications for how the results are interpreted in the multigroup approach,. Following are the sequence of testing in the multigroup approach.\n\n\nM1: Constrain all parameters (growth factor means, growth factor variances and covariances, and residual variances) to be identical across groups\n\n\nM2: Freely estimate growth factor means across groups, while keeping constraints on the growth factor variances and covariance, and residual variances\n\n\nM3: Freely estimate growth factor means, growth factor variances and covariances, while keeping the constraints on the residual variances\n\n\nM4: Freely estimate growth factor means, growth factor variances and covariances, and residual variances across the groups\n\n\nIn the first model (Model 9_1 or M1), it is assumed that both groups have the same growth function and shape, along with the same magnitude of variation in the growth factors and within-person deviations from the growth function.\nThat is to say, both groups have equal initial (starting) level and rate of change in loneliness as well as equal inter-individual differences in the initial level and rate of change as well as equal within-person variability around individual trajectories (or in the time-specific deviations from the rate of change).\nIn the second model (Model 9_2 or M2), the growth factors means are freely estimated while keeping all the other constraints or assumptions. Thus, the second model suggests that the groups have unequal initial level and rate of change.\nIn the third mode (Model 9_3 or M3), inter-individual or between-person differences in the initial level, the rate of change, and the correlation between the initial level and rate of change are now also freely estimated - indicating that both groups have different initial level, rate of change and the correlation between them.\nFinally, Model 9_4 or M4, indicates that in addition to both groups having different initial level, rate of change and the correlation between them, within-person variability around individual trajectories are also different between both groups.\nHere the comparisons tests the following\n\n\nM1 vs. M2: Tests whether the both groups differ in their initial level and average trajectory or rate of change\n\n\nM2 vs. M3: Tests the extent of inter-individual or between-person differences in the initial level and rate of change in both groups\n\n\nM3 vs. M4: Tests the extent of within-person variability around individual trajectories\n\n\nIf all models fit equally well (i.e., no significant results from the LRT or \\(\\chi^2\\) difference is not significant (\\(p &gt; .05\\))) then choose the model with the smallest number of parameters, M1 – most parsimonious model as it is the most constrained/reduced model.\n\nCode#The `anova` function in `lavaan` computes the LRT for nested models.\ncompare_groups &lt;- anova(fit_multigroupM1, fit_multigroupM2, fit_multigroupM3, fit_multigroupM4)\ncompare_groups\n\n\nChi-Squared Difference Test\n\n                 Df    AIC    BIC  Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)\nfit_multigroupM4 28 1548.4 1593.6 178.40                                      \nfit_multigroupM3 29 1554.4 1595.9 186.45     8.0442 0.20983       1   0.004565\nfit_multigroupM2 32 1558.5 1588.7 196.54    10.0956 0.12158       3   0.017771\nfit_multigroupM1 34 1565.5 1588.1 207.48    10.9344 0.16709       2   0.004223\n                   \nfit_multigroupM4   \nfit_multigroupM3 **\nfit_multigroupM2 * \nfit_multigroupM1 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe LRT or the \\(\\chi^2\\) difference test returned significant results for all three tests, suggesting that the full model (Model 9_4 or M4) is best fitting model in this case.\nSubstantively, this means that both groups (males and females) differ in their average initial level and growth trajectories of loneliness, the extent of between-person differences in those trajectories and the extent of variability around their individual trajectories.\nUsing Model 9_4 or M4, we can test whether the differences are significant as follows"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#test-of-parameter-constraints",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#test-of-parameter-constraints",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Test of parameter constraints",
    "text": "Test of parameter constraints\nFirst we test whether the intercept growth factors in both groups are significantly different\n\nCodeconstint = 'intm - intf == 0'\nlavTestWald(fit_multigroupM4, constraints = constint)\n\n$stat\n[1] 9.911781\n\n$df\n[1] 1\n\n$p.value\n[1] 0.001642241\n\n$se\n[1] \"standard\"\n\n\nThen we also test whether the slope growth factors in both groups are significantly different\n\nCodeconstslp = 'slpm - slpf ==0'\nlavTestWald(fit_multigroupM4, constraints = constslp)\n\n$stat\n[1] 1.494709\n\n$df\n[1] 1\n\n$p.value\n[1] 0.2214873\n\n$se\n[1] \"standard\"\n\n\nTest significant difference between groups in the variability around intercept\n\nCodeconstint_var = 'vinm - vinf == 0'\nlavTestWald(fit_multigroupM4, constraints = constint_var)\n\n$stat\n[1] 6.502546\n\n$df\n[1] 1\n\n$p.value\n[1] 0.01077202\n\n$se\n[1] \"standard\"\n\n\nTest significant difference between groups in the variability around slope\n\nCodeconstslp_var = 'vslm - vslf == 0'\nlavTestWald(fit_multigroupM4, constraints = constslp_var)\n\n$stat\n[1] 0.14985\n\n$df\n[1] 1\n\n$p.value\n[1] 0.6986788\n\n$se\n[1] \"standard\"\n\n\nTest significant difference between groups in the variability around the relationship between intercept and slope\n\nCodeconstslp_cov_var = 'covm - covf == 0'\nlavTestWald(fit_multigroupM4, constraints = constslp_cov_var)\n\n$stat\n[1] 2.797878\n\n$df\n[1] 1\n\n$p.value\n[1] 0.09438918\n\n$se\n[1] \"standard\"\n\n\nTest significant difference between groups in the residual variability\n\nCodeconstslp_res_var = 'rsm - rsf == 0'\nlavTestWald(fit_multigroupM4, constraints = constslp_res_var)\n\n$stat\n[1] 8.154299\n\n$df\n[1] 1\n\n$p.value\n[1] 0.004295919\n\n$se\n[1] \"standard\""
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#modelling-co-development-and-multivariate-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#modelling-co-development-and-multivariate-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Modelling co-development and Multivariate growth models",
    "text": "Modelling co-development and Multivariate growth models\nModelling the co-development among different attributes such as the comorbidity of anxiety and depression is becoming more common. Multivariate growth models also called Parallel growth models can accommodate different growth functions among two or more attributes.\nCare must be taken and theoretical considerations must be prioritized when choosing between Multivariate growth curve models and the Growth curve models with time-varying covariates.\nThe two are related but answer different research questions.\n\n\nModel 10_1\nModel 10_2\nModel 10_3\n\n\n\n\nCode# 010_1_Parallel growth curve models - anxiety and depression symptoms\nparallel &lt;- ' ia =~ 1*anx1 + 1*anx2 + 1*anx3 + 1*anx4 + 1*anx5\n                sa =~ 0*anx1 + 1*anx2 + 3*anx3 + 4*anx4 + 6*anx5\n                id =~ 1*dep1 + 1*dep2 + 1*dep3 + 1*dep4 + 1*dep5\n                sd =~ 0*dep1 + 1*dep2 + 3*dep3 + 4*dep4 + 6*dep5\n#Growth factor corelations \nia ~~ id + sa\nsd ~~ id + sa\nia ~~ 0*sd \nid ~~ 0*sa\n'\nfit_parallel &lt;- growth(parallel, data = data)\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_parallel, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 88 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        22\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               820.887\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1912.994\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.584\n  Tucker-Lewis Index (TLI)                       0.564\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1711.078\n  Loglikelihood unrestricted model (H1)      -1300.634\n                                                      \n  Akaike (AIC)                                3466.156\n  Bayesian (BIC)                              3549.128\n  Sample-size adjusted Bayesian (SABIC)       3479.347\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.237\n  90 Percent confidence interval - lower         0.223\n  90 Percent confidence interval - upper         0.252\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.357\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia =~                                               \n    anx1              1.000                           \n    anx2              1.000                           \n    anx3              1.000                           \n    anx4              1.000                           \n    anx5              1.000                           \n  sa =~                                               \n    anx1              0.000                           \n    anx2              1.000                           \n    anx3              3.000                           \n    anx4              4.000                           \n    anx5              6.000                           \n  id =~                                               \n    dep1              1.000                           \n    dep2              1.000                           \n    dep3              1.000                           \n    dep4              1.000                           \n    dep5              1.000                           \n  sd =~                                               \n    dep1              0.000                           \n    dep2              1.000                           \n    dep3              3.000                           \n    dep4              4.000                           \n    dep5              6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia ~~                                               \n    id                0.125    0.012   10.436    0.000\n    sa                0.000    0.002    0.109    0.913\n  id ~~                                               \n    sd                0.005    0.002    2.216    0.027\n  sa ~~                                               \n    sd                0.004    0.000    9.146    0.000\n  ia ~~                                               \n    sd                0.000                           \n  sa ~~                                               \n    id                0.000                           \n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    ia                1.397    0.022   64.889    0.000\n    sa               -0.032    0.004   -7.842    0.000\n    id                1.545    0.027   56.861    0.000\n    sd               -0.014    0.005   -2.825    0.005\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.083    0.010    8.647    0.000\n   .anx2              0.122    0.011   11.095    0.000\n   .anx3              0.148    0.012   11.878    0.000\n   .anx4              0.103    0.009   11.541    0.000\n   .anx5              0.062    0.008    7.615    0.000\n   .dep1              0.103    0.012    8.309    0.000\n   .dep2              0.149    0.014   10.787    0.000\n   .dep3              0.241    0.020   11.889    0.000\n   .dep4              0.181    0.016   11.601    0.000\n   .dep5              0.156    0.017    9.292    0.000\n    ia                0.097    0.012    8.393    0.000\n    sa                0.002    0.000    3.997    0.000\n    id                0.171    0.019    8.956    0.000\n    sd                0.002    0.001    2.954    0.003\n\n\n\n\n\nCode# 010_2_Parallel growth curve models - anxiety and depression symptoms with autocorrelations\nparallelautocor &lt;- ' ia =~ 1*anx1 + 1*anx2 + 1*anx3 + 1*anx4 + 1*anx5\n                sa =~ 0*anx1 + 1*anx2 + 3*anx3 + 4*anx4 + 6*anx5\n                id =~ 1*dep1 + 1*dep2 + 1*dep3 + 1*dep4 + 1*dep5\n                sd =~ 0*dep1 + 1*dep2 + 3*dep3 + 4*dep4 + 6*dep5\n#Growth factor corelations \nia ~~ id + sa\nsd ~~ id + sa\nia ~~ 0*sd \nid ~~ 0*sa\n\n#Autocorrelations \nanx1 ~~ anx2\nanx2 ~~ anx3\nanx3 ~~ anx4\nanx4 ~~ anx5\n\ndep1 ~~ dep2\ndep2 ~~ dep3\ndep3 ~~ dep4\ndep4 ~~ dep5\n'\nfit_parallelautocor &lt;- growth(parallelautocor, data = data)\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   covariance matrix of latent variables is not positive definite ; use \n   lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_parallelautocor, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 97 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        30\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               797.045\n  Degrees of freedom                                35\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1912.994\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.592\n  Tucker-Lewis Index (TLI)                       0.475\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1699.157\n  Loglikelihood unrestricted model (H1)      -1300.634\n                                                      \n  Akaike (AIC)                                3458.314\n  Bayesian (BIC)                              3571.457\n  Sample-size adjusted Bayesian (SABIC)       3476.302\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.260\n  90 Percent confidence interval - lower         0.245\n  90 Percent confidence interval - upper         0.276\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.337\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia =~                                               \n    anx1              1.000                           \n    anx2              1.000                           \n    anx3              1.000                           \n    anx4              1.000                           \n    anx5              1.000                           \n  sa =~                                               \n    anx1              0.000                           \n    anx2              1.000                           \n    anx3              3.000                           \n    anx4              4.000                           \n    anx5              6.000                           \n  id =~                                               \n    dep1              1.000                           \n    dep2              1.000                           \n    dep3              1.000                           \n    dep4              1.000                           \n    dep5              1.000                           \n  sd =~                                               \n    dep1              0.000                           \n    dep2              1.000                           \n    dep3              3.000                           \n    dep4              4.000                           \n    dep5              6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia ~~                                               \n    id                0.120    0.012   10.344    0.000\n    sa                0.004    0.002    1.529    0.126\n  id ~~                                               \n    sd                0.007    0.004    1.748    0.080\n  sa ~~                                               \n    sd                0.004    0.000    9.109    0.000\n  ia ~~                                               \n    sd                0.000                           \n  sa ~~                                               \n    id                0.000                           \n .anx1 ~~                                             \n   .anx2              0.021    0.011    1.880    0.060\n .anx2 ~~                                             \n   .anx3              0.032    0.009    3.402    0.001\n .anx3 ~~                                             \n   .anx4             -0.000    0.008   -0.058    0.954\n .anx4 ~~                                             \n   .anx5             -0.012    0.009   -1.262    0.207\n .dep1 ~~                                             \n   .dep2              0.022    0.018    1.239    0.215\n .dep2 ~~                                             \n   .dep3              0.027    0.013    2.045    0.041\n .dep3 ~~                                             \n   .dep4              0.017    0.015    1.183    0.237\n .dep4 ~~                                             \n   .dep5             -0.039    0.016   -2.440    0.015\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    ia                1.394    0.021   65.511    0.000\n    sa               -0.032    0.004   -8.005    0.000\n    id                1.543    0.027   57.239    0.000\n    sd               -0.017    0.005   -3.386    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.102    0.015    6.870    0.000\n   .anx2              0.145    0.014   10.330    0.000\n   .anx3              0.162    0.014   11.832    0.000\n   .anx4              0.091    0.010    9.176    0.000\n   .anx5              0.049    0.013    3.626    0.000\n   .dep1              0.116    0.023    5.122    0.000\n   .dep2              0.173    0.020    8.867    0.000\n   .dep3              0.252    0.022   11.625    0.000\n   .dep4              0.161    0.018    9.108    0.000\n   .dep5              0.119    0.025    4.742    0.000\n    ia                0.073    0.015    4.804    0.000\n    sa                0.002    0.001    2.197    0.028\n    id                0.147    0.026    5.720    0.000\n    sd                0.003    0.001    2.232    0.026\n\n\n\n\n\nCode# 010_3_Parallel growth curve models - anxiety and depression symptoms with cross-domain correlations \nparallelcross &lt;- ' ia =~ 1*anx1 + 1*anx2 + 1*anx3 + 1*anx4 + 1*anx5\n                sa =~ 0*anx1 + 1*anx2 + 3*anx3 + 4*anx4 + 6*anx5\n                id =~ 1*dep1 + 1*dep2 + 1*dep3 + 1*dep4 + 1*dep5\n                sd =~ 0*dep1 + 1*dep2 + 3*dep3 + 4*dep4 + 6*dep5\n#Growth factor corelations \nia ~~ id + sa\nsd ~~ id + sa\nia ~~ 0*sd \nid ~~ 0*sa\n\n#Cross domain correlations\nanx1 ~~ dep1\nanx2 ~~ dep2\nanx3 ~~ dep3\nanx4 ~~ dep4\nanx5 ~~ dep5\n'\nfit_parallelcross &lt;- growth(parallelcross, data = data)\nsummary(fit_parallelcross, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 103 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        27\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               161.219\n  Degrees of freedom                                38\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1912.994\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.934\n  Tucker-Lewis Index (TLI)                       0.922\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1381.244\n  Loglikelihood unrestricted model (H1)      -1300.634\n                                                      \n  Akaike (AIC)                                2816.487\n  Bayesian (BIC)                              2918.316\n  Sample-size adjusted Bayesian (SABIC)       2832.676\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.101\n  90 Percent confidence interval - lower         0.085\n  90 Percent confidence interval - upper         0.117\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.983\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.122\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia =~                                               \n    anx1              1.000                           \n    anx2              1.000                           \n    anx3              1.000                           \n    anx4              1.000                           \n    anx5              1.000                           \n  sa =~                                               \n    anx1              0.000                           \n    anx2              1.000                           \n    anx3              3.000                           \n    anx4              4.000                           \n    anx5              6.000                           \n  id =~                                               \n    dep1              1.000                           \n    dep2              1.000                           \n    dep3              1.000                           \n    dep4              1.000                           \n    dep5              1.000                           \n  sd =~                                               \n    dep1              0.000                           \n    dep2              1.000                           \n    dep3              3.000                           \n    dep4              4.000                           \n    dep5              6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia ~~                                               \n    id                0.075    0.009    8.272    0.000\n    sa               -0.004    0.001   -2.790    0.005\n  id ~~                                               \n    sd               -0.002    0.002   -1.204    0.229\n  sa ~~                                               \n    sd                0.000    0.000    1.208    0.227\n  ia ~~                                               \n    sd                0.000                           \n  sa ~~                                               \n    id                0.000                           \n .anx1 ~~                                             \n   .dep1              0.082    0.011    7.655    0.000\n .anx2 ~~                                             \n   .dep2              0.105    0.012    8.565    0.000\n .anx3 ~~                                             \n   .dep3              0.130    0.015    8.939    0.000\n .anx4 ~~                                             \n   .dep4              0.103    0.011    8.982    0.000\n .anx5 ~~                                             \n   .dep5              0.056    0.011    4.900    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    ia                1.394    0.021   66.266    0.000\n    sa               -0.031    0.004   -7.868    0.000\n    id                1.548    0.026   59.272    0.000\n    sd               -0.013    0.005   -2.773    0.006\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.109    0.012    9.157    0.000\n   .anx2              0.137    0.013   10.704    0.000\n   .anx3              0.154    0.013   11.374    0.000\n   .anx4              0.106    0.010   10.746    0.000\n   .anx5              0.056    0.010    5.820    0.000\n   .dep1              0.134    0.015    8.954    0.000\n   .dep2              0.171    0.016   10.473    0.000\n   .dep3              0.241    0.021   11.262    0.000\n   .dep4              0.187    0.017   10.745    0.000\n   .dep5              0.158    0.020    7.910    0.000\n    ia                0.080    0.010    8.242    0.000\n    sa                0.001    0.000    3.065    0.002\n    id                0.138    0.016    8.787    0.000\n    sd                0.001    0.001    1.222    0.222"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#sequentially-contingent-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#sequentially-contingent-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Sequentially contingent growth models",
    "text": "Sequentially contingent growth models\nGrowth in one attribute can predict the growth that occur in another attribute later in the developmental process. The rate of change in language development during pre-school may predict the rate of change in language skills during primary school. Sequentially contingent growth models offer flexibility in modelling such relations in the developmental process that occur in different stages, but might be contingent on each other.\n\nModel 11\n\n\n\nCode# 011_ Sequentially contingent growth curve model anxiety t1-t5 predicting depression t6-t10\nsequential &lt;- ' ia =~ 1*anx1 + 1*anx2 + 1*anx3 + 1*anx4 + 1*anx5\n                sa =~ 0*anx1 + 1*anx2 + 3*anx3 + 4*anx4 + 6*anx5\n                id =~ 1*dep6 + 1*dep7 + 1*dep8 + 1*dep9 + 1*dep10\n                sd =~ 0*dep6 + 1*dep7 + 2*dep8 + 3*dep9 + 4*dep10\n#Growth factor corelations \nia ~~ sa\nid ~~ sd\nia ~~ 0*sd \nid ~~ 0*sa\n\n#Growth factor regressions of depression on anxiety symptoms\nid ~ ia\nsd ~ sa\n'\n#Rename multiple columns using rename()\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nCodedata &lt;- data %&gt;% \n  rename(\"dep6\" = \"dep1\",\n         \"dep7\" = \"dep2\",\n         \"dep8\" = \"dep3\",\n         \"dep9\" = \"dep4\",\n         \"dep10\" = \"dep5\")\n\nfit_sequential &lt;- growth(sequential, data = data)\n\nWarning: lavaan-&gt;lav_object_post_check():  \n   some estimated lv variances are negative\n\nCodesummary(fit_sequential, fit.measures = TRUE)\n\nlavaan 0.6-18 ended normally after 91 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        22\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               688.159\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1912.994\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.655\n  Tucker-Lewis Index (TLI)                       0.639\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1644.714\n  Loglikelihood unrestricted model (H1)      -1300.634\n                                                      \n  Akaike (AIC)                                3333.428\n  Bayesian (BIC)                              3416.399\n  Sample-size adjusted Bayesian (SABIC)       3346.619\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.216\n  90 Percent confidence interval - lower         0.202\n  90 Percent confidence interval - upper         0.231\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.123\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia =~                                               \n    anx1              1.000                           \n    anx2              1.000                           \n    anx3              1.000                           \n    anx4              1.000                           \n    anx5              1.000                           \n  sa =~                                               \n    anx1              0.000                           \n    anx2              1.000                           \n    anx3              3.000                           \n    anx4              4.000                           \n    anx5              6.000                           \n  id =~                                               \n    dep6              1.000                           \n    dep7              1.000                           \n    dep8              1.000                           \n    dep9              1.000                           \n    dep10             1.000                           \n  sd =~                                               \n    dep6              0.000                           \n    dep7              1.000                           \n    dep8              2.000                           \n    dep9              3.000                           \n    dep10             4.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  id ~                                                \n    ia                1.377    0.067   20.520    0.000\n  sd ~                                                \n    sa                2.253    0.186   12.082    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia ~~                                               \n    sa               -0.014    0.002   -7.039    0.000\n .id ~~                                               \n   .sd                0.020    0.004    5.271    0.000\n  ia ~~                                               \n   .sd                0.000                           \n  sa ~~                                               \n   .id                0.000                           \n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    ia                1.396    0.023   60.533    0.000\n    sa               -0.032    0.005   -7.065    0.000\n   .id               -0.371    0.096   -3.869    0.000\n   .sd                0.049    0.010    5.111    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.077    0.008    9.449    0.000\n   .anx2              0.122    0.011   11.411    0.000\n   .anx3              0.151    0.013   11.961    0.000\n   .anx4              0.103    0.009   11.598    0.000\n   .anx5              0.052    0.007    7.836    0.000\n   .dep6              0.115    0.013    8.699    0.000\n   .dep7              0.148    0.013   11.037    0.000\n   .dep8              0.241    0.020   11.845    0.000\n   .dep9              0.185    0.016   11.602    0.000\n   .dep10             0.141    0.015    9.496    0.000\n    ia                0.122    0.013    9.684    0.000\n    sa                0.003    0.000    7.331    0.000\n   .id               -0.029    0.013   -2.301    0.021\n   .sd               -0.011    0.002   -6.125    0.000\n\n\n\n\n\n\n\n\n\n\n\nFeel free to contact me at frederick.anyan@ntnu.no for advise or invitation to present workshops in your own institution."
  },
  {
    "objectID": "workshops/NTNU_2024_01_March_JASP/jasp_intro.html",
    "href": "workshops/NTNU_2024_01_March_JASP/jasp_intro.html",
    "title": "Introduction to JASP for Data Analysis",
    "section": "",
    "text": "This workshop will cover an introduction to the JASP statistical tool. This is a practical workshop that will introduce you to JASP and its uses for statistical analysis through hands-on experience. Datasets will be provided.\nJASP is free, open-source and widely available, user-friendly computer software program for analysing quantitative data. This is a beginner’s two-hour workshop, aiming to provide participants who have interest in learning or using JASP with the skills for navigating the JASP workspace, data management and transformation in JASP, setting and creating variables, and the quantitative skills for managing and analysing datasets in JASP.\nDownload Presentation"
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "Latent Growth Curve Models (LGCM) & Growth Mixture Models (GMM) - Two-day Workshop\n\n\n\n\n\n\n\nLatent Growth Curve Models\n\n\nGrowth Mixture Models\n\n\nLatent Class Growth Models\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2021\n\n\nFrederick Anyan\n\n\n\n\n\n\n  \n\n\n\n\nLatent Growth Curve Models (LGCM): Applications with R\n\n\n\n\n\n\n\nLatent Growth Curve Models\n\n\nDynamic Models\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\nFrederick Anyan\n\n\n\n\n\n\n  \n\n\n\n\nLatent Growth Curve Models (LGCM): Applications with Mplus\n\n\n\n\n\n\n\nLatent Growth Curve Models\n\n\nDynamic Models\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nFrederick Anyan\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to JASP for Data Analysis\n\n\n\n\n\n\n\nJASP\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2024\n\n\nFrederick Anyan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Quantitative Methodology II (PSY2117 & PSYK4317)\n\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPrevious teaching activities\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2015\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/before_tenured.html",
    "href": "teaching/before_tenured.html",
    "title": "Previous teaching activities",
    "section": "",
    "text": "I was involved in co/teaching various undergraduate courses prior to becoming an Associate Professor\nNorwegian University of Science and Technology\n\n\nPSY3810: Innovative health promotion strategies in everyday settings\n\n\nPSY2900: Research in developmental psychology\n\n\nPSYPRO4315: Developmental psychology II\n\n\nPSY3100: Quantitative research methods\n\n\nPSY1014: Social psychology\n\n\nPSYPRO4114: Social psychology (professional psychology students)\n\n\nAustralian National University\n\n\nPSYC2001: Social psychology\n\n\nAshesi University\n\n\nSOAN229: Social research methods\n\n\nBUSA132: Organizational Behaviour\n\n\nSt. Karol School Of Nursing\n\n\nNURS364: Nursing research methods"
  },
  {
    "objectID": "teaching/teaching_tenured.html",
    "href": "teaching/teaching_tenured.html",
    "title": "Quantitative Methodology II (PSY2117 & PSYK4317)",
    "section": "",
    "text": "Quantitative Methodology II"
  }
]