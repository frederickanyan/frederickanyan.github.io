[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Frederick Anyan, Ph.D",
    "section": "",
    "text": "Associate Professor of Quantitative Methods and co-leader of the Quantitative Methods Research Group (QMRG) at the Norwegian University of Science and Technology, NTNU\n\n\nPh.D in Behaviour and Health, NTNU & Australian National University (ANU)🇳🇴&🇦🇺\n\n\nMPhil. in Human Development, NTNU🇳🇴\n\n\nBA. in Psychology with Philosophy, University of Ghana (UG)🇬🇭"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "TeachingResearchMentoring\n\n\nMy teaching in undergraduate quantitative method course focuses on understanding and emphasizing statistical concepts and their applications. Occasionally, and depending on context and need, my teaching in advance and graduate-level quantitative method add computational and statistical details to understanding concepts and their applications.\n\n\nMy research focuses on the application and assessment of quantitative methods in the social and behavioural sciences. Specifically, I focus on combining innovative statistical methods and substantive interests into a single program of research that seeks to understand, improve and promote adaptive psychological functioning and resilience in the following areas:\n\n\nLongitudinal analyses of the mental health, vulnerability and protective factors among Norwegian Afghanistan veterans.\n\n\nInvestigating what factors contribute to the complex interplay between biological systems, psychological and social-environmental factors in perpetuating the feeling of loneliness and social isolation and the consequences for mental and physical health outcomes.\n\n\nInvestigating how individuals recruit multiple protective systems (biological, psychological, social-environmental, community, and ecological factors) to respond to adversity.\n\n\nInvestigating the central mechanisms (beliefs, awareness, strategies, and executive functioning) in the development and maintenance of psychological disorders and important targets in treatments inspired by the Metacognitive Control System Model\n\n\nMy expertise in applied analysis in panel and intensive longitudinal data, as well as structural equation modelling (SEM) and hierarchical linear modelling (HLM) enables my participation in research to uncover subtle patterns in complex data sets, teasing apart minute details to reveal crucial insights that could inform effective interventions.\n\n\nBeyond research, I am very approachable and a passionate mentor and educator, with a deep commitment to sharing my expertise, taking active role in training graduate students and postdoctoral fellows. With a diverse quantitative and substantive research program that influences both theory and practice, I strive not only to make meaningful contributions to the scientific community through teaching and research, but also, train the next generation of researchers. So, you are welcome to contact me."
  },
  {
    "objectID": "projects/forsvaret/index.html",
    "href": "projects/forsvaret/index.html",
    "title": "Longitudinal analyses of the Mental health, Vulnerability, and Protective factors among Norwegian Afghanistan Veterans",
    "section": "",
    "text": "Data from HUNT survey and the Armed Forces’ health registry will be combined to investigate relationships between deployment related risk factors and health, profiles of resilience among the general population and Norwegian Afghanistan veterans.\nAs both the Armed Forces’ health surveys and HUNT include large cohorts, there is a high probability that there is a subgroup included in both health surveys. If one identifies this subgroup and connects data from HUNT with the Armed Forces’ health surveys, this will provide a unique opportunity to find links between risk factors (lifestyle or environment) and the development of good or bad health (illness) after international deployments, and also to understand how resilience and constellations of specific robustness factors might differ in a civilian and veteran sample."
  },
  {
    "objectID": "projects/reslon/index.html",
    "href": "projects/reslon/index.html",
    "title": "Resilience to Loneliness for Mental and Physical Health outcomes(RESLON-MPH)",
    "section": "",
    "text": "Resilience to Loneliness for Mental and Physical Health outcomes(RESLON-MPH) investigates the complex interplay between biological systems, psychological and social-environmental factors in loneliness for mental and physical health outcomes. The RESLON-MPH project will use various research approaches combining intensive longitudinal data (e.g., experienced sampling methods), large-scale genetic studies (e.g., genome-wide association studies - GWAS), and intranasal oxytocin trials."
  },
  {
    "objectID": "publications/specificity.html",
    "href": "publications/specificity.html",
    "title": "Specificity in mediated pathways by anxiety symptoms linking adolescent stress profiles to depressive symptoms: Results of a moderated mediation approach",
    "section": "",
    "text": "Background We investigated the specificity in mediated pathways that separately link specific stress dimensions through anxiety to depressive symptoms and the protective utility of resilience. Thus, this study goes beyond lumping together potential mediating and moderating processes that can explain the relations between stress and (symptoms of) psychopathology and the buffering effect of resilience.\nMethods Ghanaian adolescents between 13 and 17 years (female = 285; male = 244) completed the Adolescent Stress Questionnaire (ASQ), Spielberger State Anxiety Inventory (STAI), Short Mood Feeling Questionnaire (SMFQ) and the Resilience Scale for Adolescents (READ). Independent samples t-test, multivariate analysis of covariance with follow-up tests and moderated mediation analyses were performed.\nResults Evidences were found for specificity in the associations between dimensions of adolescent stressors and depressive symptoms independent of transient anxiety. Transient anxiety partly accounted for the indirect effects of eight stress dimensions on depressive symptoms. Except stress of school attendance and school/leisure conflict, resilience moderated the indirect effects of specific stress dimensions on depressive symptoms. Results suggested differences in how Ghanaian adolescents view the various stress dimensions, and mediated pathways associated with anxiety and depressive symptoms.\nLimitations Use of cross-sectional data does not show causal process and temporal changes over time.\nConclusions Findings support and clarify the specificity in the interrelations and mediated pathways among dimensions of adolescent stress, transient anxiety, and depressive symptoms. Conditional process analyses shows that resilience does not only buffer direct, but also indirect psychological adversities. Interventions for good mental health may focus on low resilience subgroups in specific stress dimensions while minimizing transient anxiety.\nRead more\nDownload"
  },
  {
    "objectID": "publications/upright_rationale.html",
    "href": "publications/upright_rationale.html",
    "title": "UPRIGHT, a resilience-based intervention to promote mental well-being in schools: study rationale and methodology for a European randomized controlled trial",
    "section": "",
    "text": "Background Adolescence is crucial period for laying the foundations for healthy development and mental well-being. The increasing prevalence of mental disorders amongst adolescents makes promotion of mental well-being and prevention interventions at schools important. UPRIGHT (Universal Preventive Resilience Intervention Globally implemented in schools to improve and promote mental Health for Teenagers) is designed as a whole school approach (school community, students and families) to promote a culture of mental well-being and prevent mental disorders by enhancing resilience capacities. The present article aims at describing the rationale, conceptual framework, as well as methodology of implementation and evaluation of the UPRIGHT intervention.\nMethods UPRIGHT project is a research and innovation project funded by the European Union’s Horizon 2020 Research and Innovation programme under grant agreement No. 754919 (Duration: 48 months). The theoretical framework has been developed by an innovative and multidisciplinary approach using a co-creation process inside the UPRIGHT Consortium (involving seven institutions from Spain, Italy, Poland, Norway, Denmark, and Iceland). Resulted is the UPRIGHT programme with 18 skills related to 4 components: Mindfulness, Coping, Efficacy and Social and Emotional Learning.\nAmong the five Pan-European regions, 34 schools have been currently involved (17 control; 17 intervention) and around 6000 adolescents and their families are foreseen to participate along a 3-year period of evaluation. Effectiveness of the intervention will be evaluated as a randomized controlled trial including quantitative and qualitative analysis in the five Pan-European regions representative of the cultural and socioeconomic diversity. The cost-effectiveness assessment will be performed by simulation modelling methods.\nDiscussion We expect a short- to medium-term improvement of mental well-being in adolescents by enhancing resilience capacities. The study may provide robust evidence on intrapersonal, familiar and social environmental resilience factors promoting positive mental well-being.\nRead more\nDownload"
  },
  {
    "objectID": "publications/rsaAustralia.html",
    "href": "publications/rsaAustralia.html",
    "title": "Measuring Resilience Across Australia and Norway: Validation and Psychometric Properties of the English Version of the Resilience Scale for Adults",
    "section": "",
    "text": "Resilience has become increasingly important in clinical and health psychology, but only few scales have received good psychometric ratings for assessing various outcomes of resilience. The Resilience Scale for Adults (RSA) is one of the best psychometrically rated scales and has been validated among Norwegian samples. The purpose of this study was to explore the construct validity of the RSA in an English-speaking Australian sample and test measurement invariance between the Australian sample and a Norwegian sample. An Australian sample (N = 781) completed the RSA, Sense of Coherence Scale (SOC-13), Patient Health Questionnaire (PHQ-9), and Generalized Anxiety Disorder Questionnaire (GAD-7). A second sample of Norwegians (N = 320) was included in the analyses of invariance of the RSA across cultures. There were expected negative correlations between RSA and PHQ-9, and between RSA and GAD-7, but positive correlations between RSA and SOC-13. The results indicated that the six-factor measurement model of the RSA is the same in the Australian and Norwegian samples, and respondents from the two cultures understood and interpreted the items in a comparable fashion. Support was found for the cross-cultural validity of the RSA in an English-speaking Australian sample and as a valid and reliable self-report measure of protective factors.\nRead more\nDownload"
  },
  {
    "objectID": "publications/cocreation.html",
    "href": "publications/cocreation.html",
    "title": "Co-creation and regional adaptation of a resilience-based universal whole-school program in five European regions",
    "section": "",
    "text": "The co-creation of educational services that promote youth resilience and mental health is still scarce. UPRIGHT (Universal Preventive Resilience Intervention Globally implemented in schools to improve and promote mental Health for Teenagers) is a research and intervention program in the Basque Country (Spain), Trentino (Italy), Low Silesia (Poland), Denmark and Reykjavik (Iceland). UPRIGHT implemented a co-creation research process whose results, outcomes and policy implications are presented here. The co-creation had a mixed-methods participatory research design with nine specific objectives linked to paired strategies of inquiry for adolescents, families, teachers and school staff. The overarching objective was to generate a valid and feasible regional adaptation strategy for UPRIGHT intervention model. Participants answered surveys (n = 794) or attended 16 group sessions (n = 217). The results integrate quantitative and qualitative information to propose a regional adaptation strategy that prioritizes resilience skills, adolescents’ concerns, and preferred methods for implementation across countries and in each school community. In conclusion, a whole-school resilience program must innovate, include and connect different actors, services and communities, and must incorporate new technologies and activities outside the classroom. A participatory co-creation process is an indispensable step to co-design locally relevant resilience interventions with the involvement of the whole-school community.\nRead more\nDownload"
  },
  {
    "objectID": "publications/SRSdev.html",
    "href": "publications/SRSdev.html",
    "title": "Development and validation of the theory-driven School Resilience Scale for Adults: Preliminary results",
    "section": "",
    "text": "Resilience is the ability of an individual or community to adapt to life challenges or adversities while maintaining mental health and well-being. In the multi-systemic resilience paradigm, human development and resilience is embedded in adaptive systems and in their interactions. Although the relationship between school systems and adolescents’ mental wellbeing is established, there is no agreement on how to recognize and evaluate the most relevant aspects of the school community, acting at collective level, to boost positive socio-emotional and educational outcomes in children and adolescents. This study presents the development and preliminary validation of a new and theory-driven construct and instrument, the School Resilience Scale for Adults (SRS). School Resilience comprises five interrelated constructs (i.e. Positive relationships, Belonging, Inclusion, Participation, and Mental health awareness) connected theoretically to wellbeing and resilience in children and adolescents. The scale development was theory-driven, and the instrument was tested in four European counties in the frame of the UPRIGHT project (Universal Preventive Resilience Intervention Globally implemented in schools to improve and promote mental Health for Teenagers). Overall, 340 adults participated, 129 teachers and school staff, and 211 relatives of teenagers. The sample was randomly split for two studies: (1) an Exploratory Factor analysis (ESEM), and (2) Confirmatory Factor (CFA) analysis. In the exploratory analysis, Chi-Square difference test and model fit indices point towards the five-factor solution over a three-factor solution. The confirmatory study indicated that a five-factor model (RMSEA = 0.038, CFI = 0.96, TLI = 0.95, SRMR = 0.045) was slightly better than a second-order model (RMSEA = 0.046, CFI = 0.94, TLI = 0.93, SRMR = 0.05). Convergent and discriminant validities were partially demonstrated. Alpha and omega reliability coefficients verified the measurement model of the scale. The results confirmed that a multidimensional construct of School Resilience, defined as a collective resilience factor, embedded in the school staff, family members, and adolescents’ interrelated systems can be characterized and measured. Further studies must determine its role in the promotion of adolescents’ resilience, mental wellbeing, educational outcomes, and in their positive adaptation in challenging contexts.\nRead more\nDownload"
  },
  {
    "objectID": "publications/stresshome.html",
    "href": "publications/stresshome.html",
    "title": "Stress of home life and gender role socializations, family cohesion, and symptoms of anxiety and depression",
    "section": "",
    "text": "This cross-sectional study investigated the relation of sociocultural prescriptions of gender role socializations to differences in stress at home and to anxiety and depressive symptoms for adolescent girls and boys, with family cohesion as a mediator. A total of 244 boys and 285 girls aged 13–17 years recruited from Accra, Ghana completed the Short Mood Feeling Questionnaire, Spielberger State Anxiety Inventory, Stress of Home Life and Family Cohesion self-report scales in April 2015. In each sample, two mediation analyses were conducted using Structural Equation Modelling. Exposure to stress at home that was perceived to result from sociocultural prescriptions of gender role norms largely accounted for anxiety and depressive symptoms among girls, whereas this relation was non-significant among boys. Significant indirect relations through low family cohesion to anxiety symptoms were observed for girls and boys but not to depressive symptoms for boys. These findings suggest that differences in gender role socializations at home may account for individual differences in associations between exposure to stress at home and anxiety and depressive symptoms as well as explain the differential indirect relations through low family cohesion. Improving family cohesion while reducing stress at home may contribute to reducing stress and thus anxiety and depressive symptoms.\nRead more\nDownload"
  },
  {
    "objectID": "publications/powershifts.html",
    "href": "publications/powershifts.html",
    "title": "The influence of power shifts in data collection and analysis stages : A focus on qualitative research interview",
    "section": "",
    "text": "This paper analyzes the power relation between the interviewer and the interviewee in the qualitative research interview methodology. The paper sets out to grapple with the extent to which the dynamisms in power shifts influence data collection and analysis in the interview methodology. The exploration of power shifts in the qualitative research interview facilitates comprehensive understanding of the nuances of the data by providing more information about the interviewee and the interviewer. This enhances a deeper discerning into the research process, and the topics discussed. This paper also elaborates on how interviewees as well as interviewers display their countermeasures to each other in the course of the interview situation and presents a greater understanding of the power dynamics that exist between the interviewer and interviewee. Power asymmetry seems to be an exasperating circumstance in the interview methodology as pointed out by the discussions in this article. This article also discusses practical recommendations for minimizing the power dynamics during data analysis in the qualitative research interview.\nRead more\nDownload"
  },
  {
    "objectID": "publications/coping.html",
    "href": "publications/coping.html",
    "title": "The coping mechanism and strategies of hypertension patients in Ghana: The role of religious faith, beleifs and practices",
    "section": "",
    "text": "This qualitative study explored the role of religious faith, belief and practice systems in the coping mechanisms and strategies of essential hypertension patients in Accra, Ghana. Six participants were recruited for participation, of which five were Christians and one was a Muslim. Interviews were conducted and interpretative phenomenological analysis was used to analyze the data. Results showed that participants used their religious faith, beliefs and practices as coping resources. Participants used a deferring-collaborative style of religious coping, which seemed to have provided them with an avoidance strategy that protected the participants from conscious confrontation with their illness. Religious faith and beliefs also afforded the participants a sense of coherence that enabled the participants to manage their stress, reflect on their external and internal resources to promote effective coping and adaptive functioning in a health promoting manner. Implications of a deferring-collaborative style of religious coping and religious re-appraisal are discussed.\nRead more\nDownload"
  },
  {
    "objectID": "publications/anx_sym_med.html",
    "href": "publications/anx_sym_med.html",
    "title": "Anxiety symptoms mediate the relationship between exposure to stressful negative life events and depressive symptoms: A conditional process modelling of the protective effects of resilience",
    "section": "",
    "text": "Background Resilience has provided a useful framework that elucidates the effects of protective factors to overcome psychological adversities but studies that address the potential contingencies of resilience to protect against direct and indirect negative effects are lacking. These obvious gaps have also resulted in oversimplification of complex processes that can be clarified by moderated mediation associations. This study examines a conditional process modelling of the protective effects of resilience against indirect effects.\nMethod Two separate samples were recruited in a cross-sectional survey from Australia and Norway to complete the Patient Health Questionnaire −9, Generalized Anxiety Disorder, Stressful Negative Life Events Questionnaire and the Resilience Scale for Adults. The final sample sizes were 206 (females = 114; males = 91; other = 1) and 210 (females = 155; males = 55) for Australia and Norway respectively. Moderated mediation analyses were conducted across the samples.\nResults Anxiety symptoms mediated the relationship between exposure to stressful negative life events and depressive symptoms in both samples. Conditional indirect effects of exposure to stressful negative life events on depressive symptoms mediated by anxiety symptoms showed that high subgroup of resilience was associated with less effect of exposure to stressful negative life events through anxiety symptoms on depressive symptoms than the low subgroup of resilience.\nLimitations As a cross-sectional survey, the present study does not answer questions about causal processes despite the use of a conditional process modelling.\nConclusions These findings support that, resilience protective resources can protect against both direct and indirect – through other channels – psychological adversities.\nRead more\nDownload"
  },
  {
    "objectID": "publications/adolescents.html",
    "href": "publications/adolescents.html",
    "title": "Adolescent stress and symptoms of anxiety and depression: Resilience explains and differentiates the relationships",
    "section": "",
    "text": "Background Some adolescents exhibit resilience even in the face of high levels of stress exposure. Despite this relationship, studies that investigate explanations for how resilience interacts with risk to produce particular outcomes and why this is so are lacking. The effect of resilience across the relationship between stress and symptoms of anxiety and stress and symptoms of depression was tested to provide explanations for how resilience interacts with stress and symptoms of anxiety, and depression.\nMethod In a cross-sectional survey, 533 Ghanaian adolescents aged 13–17 years (M=15.25, SD=1.52), comprising 290 girls and 237 boys completed the Resilience Scale for Adolescents, Adolescent Stress Questionnaire, Spielberger State Anxiety Inventory, and Short Mood Feeling Questionnaire. Mediation and moderation analyses were conducted.\nResults The results indicated that resilience partially mediated the relationship between stress, and symptoms of anxiety, and depression. Effects of stress were negatively associated with resilience, and positively associated with symptoms of anxiety and depression. In a differential moderator effect, resilience moderated the relationship between stress and symptoms of depression but not stress and symptoms of anxiety.\nLimitations Although the findings in this study are novel, they do not answer questions about protective mechanisms or processes.\nConclusions Evidence that resilience did not have the same effect across stress, and symptoms of anxiety and depression may support resilience as a dynamic process model. Access to different levels of resilience shows that enhancing resilience while minimizing stress may improve psychiatric health in adolescents’ general population.\nRead more\nDownload"
  },
  {
    "objectID": "publications/READGerman.html",
    "href": "publications/READGerman.html",
    "title": "Psychometric properties of the Resilience Scale for Adolescents (READ) and Measurement Invariance Across Two Different German-Speaking Samples",
    "section": "",
    "text": "The Resilience Scale for Adolescents (READ) is a highly rated scale for measuring protective factors of resilience. Even though the READ has been validated in several different cultural samples, no studies have validated the READ across samples in German from Switzerland and Germany. The purpose of this study was to explore the construct validity of the German READ version in two samples from two different countries and to test the measurement invariance between those two samples. A German sample (n = 321, M = 12.74, SD = 0.77) and a German-speaking Swiss sample (n = 349, M = 12.67, SD = 0.69) of seventh graders completed the READ, Hopkins Symptom Checklist (HSCL-25), Rosenberg Self-Esteem Scale (RSE), General Self-Efficacy Scale, and Satisfaction with Life Scale (SWL). The expected negative correlations between READ and HSCL-25 and the positive correlations between RSE, self-efficacy, and SWL were supported. Furthermore, the results of the measurement invariance demonstrated that the originally proposed five-dimensional structure is equal in the German and Swiss samples, and it can be assumed that the same construct was assessed by excluding one item. The five-factor, 27-item solution is a valid and reliable self-report measure of protective factors between two German-speaking samples.\nRead more\nDownload"
  },
  {
    "objectID": "publications/ResCovid.html",
    "href": "publications/ResCovid.html",
    "title": "Resilience Moderates Negative Outcome from Stress during the COVID-19 Pandemic: A Moderated-Mediation Approach",
    "section": "",
    "text": "Resilience refers to an individual’s healthy coping abilities when encountering adverse life events. The COVID-19 pandemic represents a situation with a high amount of stress exposure, which in turn may be associated with negative emotional outcome like depressive symptoms. The current study investigated if resilience moderated the effect of stress on symptoms of depression and if anxiety symptoms mediated this association. An adult sample of community controls completed the Perceived stress scale 14 (PSS-14), the Resilience scale for adults (RSA), the Patient health questionnaire 9 (PHQ-9) and the Generalized anxiety disorder 7 (GAD-7). Independent samples t-test, correlation analyses and moderated mediation analyses were conducted. The results showed that resilience moderated the relations between stress and anxiety symptoms (β = −0.131, p &lt; 0.001) as well as between stress and depressive symptoms (β = −0.068, p &lt; 0.05). In support of a moderated mediation model, resilience moderated the indirect effect of stress on depressive symptom, as confirmed by the index of moderated mediation (IMM = −0.036, p &lt; 0.001; [95% BCa: −0.055, −0.020]). The high resilience subgroup was less affected than the low resilience subgroup by the effect of stress exposure symptoms of depression, mediated by anxiety. The study shows that stress exposure is associated with symptoms of depression, and anxiety mediates this association. Level of resilience differentiates the direct and indirect effect of stress on depression. Knowledge about the effect of stress in response to a pandemic is important for developing treatment and prevention strategies for stress, depression and health-related anxiety.\nRead more\nDownload"
  },
  {
    "objectID": "publications/temporalreciprocal.html",
    "href": "publications/temporalreciprocal.html",
    "title": "Temporal and Reciprocal Relations Between Worry and Rumination Among Subgroups of Metacognitive Beliefs",
    "section": "",
    "text": "Metacognitive theory provides strong foundation for hypothesizing relations between worry and rumination among subgroups of metacognitive beliefs. However, empirical exploration of prospective and reciprocal relations between worry and rumination are lacking. This study investigated the stability and relations between worry and rumination to better understand how they influence each other over time, and how different levels of metacognitive beliefs affect relations between (i) initial and future worry, and initial and future rumination, and (ii) the cross-lag relations between worry and rumination. Overall, 482 (Females = 63%) participants (Mean age = 26 years) participated in a two-wave data collection and completed the Metacognition Questionnaire (MCQ-30), the Ruminative Response Scale and the Penn State Worry Questionnaire (PSWQ). A multigroup two-wave autoregressive cross-lagged model was estimated. Multigroup autoregression analyses revealed that independent of participants being in the high or low metacognition group, initial levels of worry predicted future levels of worry, as was the case for rumination. Multigroup cross-lagged analyses revealed that initial levels of worry did not predict future levels of rumination in both high and low levels of metacognitions. However, initial rumination predicted future levels of worry in the high metacognitions group, which was not the case for the low metacognitions group. Thus, high levels of metacognitions do not only strengthen the relation between both present and future worry, present and future rumination, but also present rumination with future worry. This finding may imply that those with rumination related conditions at present are more likely in the future to show both rumination and worry related conditions. Conversely, those with worry related conditions show future worry related conditions. These findings may have implications for a clinical sample regarding the high complexity of rumination conditions that may proceed with multifinality causal pathways especially for individuals with high levels of metacognitions. This complexity may be a possible explanation for the limited success in other traditional treatment of rumination related conditions and the relatively high relapse rates for such conditions in clinical samples.\nRead more\nDownload"
  },
  {
    "objectID": "publications/prospectivelonel.html",
    "href": "publications/prospectivelonel.html",
    "title": "Prospective relations between loneliness in different relationships, metacognitive beliefs, worry and common mental health problems",
    "section": "",
    "text": "Background This study investigated prospective relations between loneliness in family, romantic and social relationships and common mental health problems measured as symptoms of anxiety and depression. How these relations are mediated by metacognitive beliefs and worry in a serial mediation model in a full SEM was also tested.\nMaterials and methods Data were collected at two time points, separated by three months among students at the Norwegian University of Science and Technology. In total, 241 (Females = 65%) students completing both waves of data collection were included for analyses.\nResults Loneliness in family relationships was only concurrently associated with worry whereas loneliness in social and romantic relationships showed concurrent and prospective relations. Overall, the results highlighted that for loneliness in social and romantic relationships, their prospective relations with anxiety and depressive symptoms depended on how an individual responded with metacognitive beliefs or worry or both. However, social loneliness might be an exception since it also had a direct effect on levels of depressive symptoms.\nConclusions To prevent or reduce loneliness and common mental health problems, evidence provided show that interventions may incorporate components that target self-focused negative thinking in the form of worry or beliefs about the contents of negative thinking in the form of metacognitive beliefs, underlying loneliness and mental health problems.\nRead more\nDownload"
  },
  {
    "objectID": "publications/interpersonalstress.html",
    "href": "publications/interpersonalstress.html",
    "title": "Interpersonal stress, anxiety and depressive symptoms: Results from a moderated mediation analysis with resilience",
    "section": "",
    "text": "Introduction and objectives Interpersonal stress factors contribute to common mental health problems measured as anxiety and depression. Recently, it is emerging that anxiety precedes depression but not the reverse, and markedly increase in response to stress giving way to depression. As such, anxiety itself could be a predictive risk factor, and mediate the associations between stress and depression. While resilience protects against exposure to stress and common mental health problems, it is unclear to what extent different resilience factors are differentially involved in protection against anxiety and depressive symptoms. This study explored complex theoretical associations between interpersonal stress, anxiety and depressive symptoms and resilience factors.\nMaterials and methods Participants (N = 210 adults) completed the Resilience Scale for Adults (RSA), Patient Health Questionnaire (PHQ-9), Generalized Anxiety Disorder Questionnaire (GAD-7) and the Stressful Life Events Questionnaire (SLE) in a cross-sectional survey. Hierarchical linear regressions and moderated-mediation analyses were performed using PROCESS macro.\nResults Interpersonal stress explained more variance in depressive than anxiety symptoms. Support was found for the mediating effect of anxiety symptoms in the relationship between interpersonal stress and depressive symptoms. Resilience factors are differentially involved in protection against anxiety and depressive symptoms.\nConclusion Exposure to interpersonal stress is not only directly associated with depressive symptoms but also indirectly through high scores on anxiety symptoms. Uneven functioning and differential impact of resilience factors can help us understand the mixed successes in implementing resilience-based interventions for positive mental health and judiciously allocate scarce and finite resources for intervention.\nRead more\nDownload"
  },
  {
    "objectID": "publications/changephysical.html",
    "href": "publications/changephysical.html",
    "title": "Change in Physical Activity During the Coronavirus Disease 2019 Lockdown in Norway: The Buffering Effect of Resilience on Mental Health",
    "section": "",
    "text": "Imposition of lockdown restrictions during the coronavirus disease 2019 (COVID-19) pandemic was sudden and unprecedented and dramatically changed the life of many people, as they were confined to their homes with reduced movement and access to fitness training facilities. Studies have reported significant associations between physical inactivity, sedentary behavior, and common mental health problems. This study investigated relations between participants’ reports of change in physical activity (PA; i.e., Reduced PA, Unchanged PA, or Increased PA) and levels of anxiety and depression symptoms during the COVID-19 pandemic lockdown in Norway in the time period from March 12, 2020 to June 15, 2020. The relations between age and gender and levels of anxiety and depression symptoms as well as how different levels of resilience influenced the relation between changes in PA and levels of anxiety and depression symptoms were also investigated. A cross-sectional survey design was used. Participants (N = 1,314; females = 31%) were members of an endurance sports organization aged between 18 and 81 years (M = 49 years; SD = 11.50 years). Participants completed the Resilience Scale for Adults and the Hospital Anxiety and Depression Scale and reported their changes in PA after lockdown restrictions were implemented on March 12, 2020. Regression analysis, independent samples t-test, and two-way multivariate analysis of variance were conducted. Reduced PA was associated with a higher risk of anxiety and depression symptoms. Younger participants in Reduced PA and Unchanged PA subgroups scored significantly higher on levels of anxiety symptoms and significantly higher on depression symptoms in Unchanged PA subgroup. Females in Unchanged PA and Increased PA subgroups scored significantly higher on levels of anxiety symptoms, whereas no gender differences were found for depression symptoms. The main and interaction effects of change in PA and resilience were significantly associated with depression symptoms. For anxiety symptoms, only the main effect of resilience, but not PA, and the interaction effect were significant. Results further showed that resilience was an important factor that influenced the levels of change in PA. High levels of resilience were associated with lower anxiety and depression symptoms in Reduced, Unchanged, and Increased PA subgroups during the COVID-19 lockdown. Promoting PA while boosting resilience factors such as confidence in own ability and drawing on the social support of even reduced social networks or connections while under lockdown can protect against common mental health problems.\nRead more\nDownload"
  },
  {
    "objectID": "publications/housingfirst.html",
    "href": "publications/housingfirst.html",
    "title": "Housing first, connection second: the impact of professional helping relationships on the trajectories of housing stability for people facing severe and multiple disadvantage",
    "section": "",
    "text": "Background Despite the accumulating evidence on the role of professional helping relationships for highly disadvantaged populations, methodological shortcomings have made it difficult to establish a robust relationships-outcomes link. This study sought to establish the impact of professional helping relationships on the trajectories over 24 months of housing stability for 2141 people facing severe and multiple disadvantage using data from the Housing First controlled trial in Canada.\nMethod The study used a mixed method design. Latent growth curve and growth mixture models assessed the impact of working alliance across the sample as a whole and within subgroups with different patterns of housing stability. Thematic analysis explored the factors that may affect the quality of working alliances within different subgroups.\nResults Three distinct trajectories of housing stability emerged (i.e., Class 1: “sharp rise, sustained, and decline housing”; Class 2: “hardly any time housed”; Class 3: “high rise, sustained, and decline housing”) with professional helping relationships having different effects in each. The analysis revealed structural and individual circumstances that may explain differences among the classes.\nConclusions The findings underscore the role of professional helping relationships, as distinct from services, in major interventions for highly disadvantaged populations, and draws new attention to the temporal patterns of responses to both the quality of relationship and targeted interventions.\nRead more\nDownload"
  },
  {
    "objectID": "publications/sickleave.html",
    "href": "publications/sickleave.html",
    "title": "Sick leave and return to work for patients with anxiety and depression: A longitudinal study of trajectories before, during and after work-focused treatment",
    "section": "",
    "text": "Objectives Sick leave due to anxiety and depression is a heterogeneous process constituting a pressing public health issue. This longitudinal study aimed to identify sick leave trajectories among patients before, during and after work-focused treatment, in all 29.5 months. We then aimed to determine the background and clinical characteristics of these trajectory groups.\nMethods Background and clinical data were collected by patient self-report (N=619) in an observational study in a specialised mental healthcare clinic. Sick leave was recorded from national registry data. A latent growth mixture model identified trajectories. Multinomial logistic regression determined differences in background characteristics while a one-way analysis of variance (ANOVA) identified clinical differences.\nResults We identified three trajectories: The ‘Resilient’ group (47.7%) had low sick leave throughout the period. The two other groups (‘Recovery’, 31.8% and ‘High risk’, 20.5%) had similar pretreatment trajectories: lower sick leave one year prior which increased to high sick leave at the start of treatment. After treatment, the ‘Recovery’ group made an almost full return to work while the ‘High risk’ group remained at high sick leave. The two groups with high sick leave had more women and higher age compared with the ‘Resilient’ group. All groups had similar clinical scores at the start of treatment, but the ‘High risk’ groups had residual depressive symptoms at the end of treatment. Effect sizes for anxiety and depression were moderate or large for all groups, (Cohen’s d=0.74–1.81), and 87.2% of the total sample were fully working one year after treatment.\nConclusion We found three subgroups with distinctly different trajectories. Female gender and higher age were associated with high sick leave at the start of treatment, while residual depressive symptoms at the end of treatment predicted continued sick leave. The study points to the possibility of improving patient outcomes in the future by stratifying and tailoring treatment to patient characteristics.\nRead here\nDownload"
  },
  {
    "objectID": "publications/metacognition_cognition.html",
    "href": "publications/metacognition_cognition.html",
    "title": "Metacognition, Cognition and Social Anxiety: A Test of Temporal and Reciprocal Relationships",
    "section": "",
    "text": "Cognitive models of social anxiety give prominence to dysfunctional schemas about the social self as the key underlying factors in maladaptive self-processing strategies and social anxiety symptoms. In contrast, the metacognitive model argues that beliefs about cognition represent a central belief domain underlying psychopathology and cognitive schemas as products of a thinking style regulated by metacognition. The present study therefore evaluated the temporal and reciprocal relations between metacognitive beliefs, social self-beliefs, and social anxiety symptoms to shed light on possible causal relationships among them. Eight hundred and sixty-eight individuals gathered at convenience participated in a four-wave online survey with each measurement wave 6 weeks apart. Using autoregressive cross-lagged panel models, we found significant temporal and reciprocal relations between metacognition, social self-beliefs (schemas), and social anxiety. Whilst social self-beliefs prospectively predicted social anxiety this relationship was reciprocal. Metacognitive beliefs prospectively predicted both social interaction anxiety and social self-beliefs, but this was not reciprocal. The results are consistent with metacognitive beliefs causing social anxiety and social self-beliefs and imply that negative social self-beliefs might be a product of metacognition. The clinical implications are that metacognitive beliefs should be the central target in treatments of social anxiety.\nRead more\nDownload"
  },
  {
    "objectID": "publications/relevanceofwell.html",
    "href": "publications/relevanceofwell.html",
    "title": "Relevance of well-being, resilience, and health-related quality of life to mental health profiles of European adolescents: results from a cross-sectional analysis of the school-based multinational UPRIGHT project",
    "section": "",
    "text": "Purpose The existing evidence suggests that a complete evaluation of mental health should incorporate both psychopathology and mental well-being indicators. However, few studies categorize European adolescents into subgroups based on such complete mental health data. This study used the data on mental well-being and symptoms of mental and behavioral disorders to explore the mental health profiles of adolescents in Europe.\nMethods Data collected from adolescents (N = 3767; mean age 12.4 [SD = 0.9]) from five European countries supplied the information on their mental well-being (personal resilience, school resilience, quality of life, and mental well-being) and mental and behavioral disorder symptoms (anxiety, depression, stress, bullying, cyber-bullying, and use of tobacco, alcohol, or cannabis). Multiple correspondence analysis and cluster analysis were combined to classify the youths into mental health profiles.\nResults Adolescents were categorized into three mental health profiles. The “poor mental health” profile (6%) was characterized by low levels of well-being and moderate symptoms of mental disorders. The “good mental health” profile group (26%) showed high well-being and few symptoms of mental disorders, and the “intermediate mental health” profile (68%) was characterized by average well-being and mild-to-moderate symptoms of mental disorders. Groups with higher levels of well-being and fewer symptoms of mental disorders showed lower rates of behavioral problems. Mental well-being indicators strongly contributed to this classification.\nConclusion Adolescents with the “intermediate” or “poor” mental health profiles may benefit from interventions to improve mental health. Implications for school-based interventions are discussed.\nRead more\nDownload"
  },
  {
    "objectID": "publications/READ_UPRIGHT.html",
    "href": "publications/READ_UPRIGHT.html",
    "title": "Measuring Resilience Across Participating Regions in the UPRIGHT EU Horizon 2020 Project: Factor Structure and Psychometric Properties of the Resilience Scale for Adolescents",
    "section": "",
    "text": "Resilience is the process and outcome of healthy adaptation despite significant adversity. Proliferation of research on the resilience construct has led to scientific concerns about the operationalization and measurement of resilience for assessment science and practice. Various studies that have investigated the psychometric properties and construct validity of the Resilience Scale for Adolescents (READ) have yielded inconsistent findings, which could partly be due to variations in the methodological approaches. This study investigated the factor structure and construct validity of the READ in four European regions participating in the Universal Preventive Resilience Intervention Globally Implemented in Schools to Improve and Promote Mental Health for Teenagers (UPRIGHT) project. Participants included adolescents aged 10–15 years from Spain (n = 391, females = 51%), Iceland (n = 379, females = 55%), Italy (n = 460, females = 55%), and Poland (n = 316, females = 51%). The five-factor model of the READ was similar across gender and participating regions. Construct validity of the READ was supported. After establishing construct separability, incremental validity was supported (except for the social competence subscale). The READ is a valid and reliable measure of protective factors involved in resilience and demonstrates promise for cross-cultural applicability. Recommendations for measuring resilience and validating the READ in future investigations are provided.\nRead more\nDownload"
  },
  {
    "objectID": "publications/lonelinessNN.html",
    "href": "publications/lonelinessNN.html",
    "title": "Loneliness in social relationships: Mapping the nomological network of loneliness with key conceptual domains and theoretical constructs",
    "section": "",
    "text": "To expand evidence for the nature and related mechanisms underlying loneliness measured by Social and Emotional Loneliness Scale for Adults (SELSA-S), several hypotheses were developed and tested to map the nomological network of loneliness. Tests included examining the structure of the multidimensional experiences of loneliness, concurrent and prospective relations between loneliness, sociodemographic variables, worry, rumination, metacognition, symptoms of anxiety and depression. This study also sought to determine how resilience is involved in the protection against loneliness and depressive symptoms. Four hundred and eighty-two students with a mean age of 25.84 years (SD = 5.74) participated (N = 482; 59% females). Structural and temporal stability analyses supported the multidimensional experiences of loneliness, including family, romantic and social loneliness. Psychological network analysis identified especially strong connections (i.e., edges) between indicators belonging to loneliness in family and social relationships. At the general level, older participants and those who were single reported more loneliness. Loneliness was concurrently and prospectively associated with worry, rumination and metacognitions and predicted vulnerabilities in levels of anxiety and depressive symptoms. At follow-up, the effect of loneliness on depressive symptoms was lower when scoring high on resilience. Interventions for loneliness may address improving family relationships and metacognitive processes underlying loneliness, which may in turn improve mental health. Interpersonal and intrapersonal protective factors involved in resilience may compensate for deficits in social relationships thereby buffering negative effects of loneliness on common mental health problems.\nRead more\nDownload"
  },
  {
    "objectID": "publications/networkMCQ.html",
    "href": "publications/networkMCQ.html",
    "title": "The network structure of dysfunctional metacognition: Analysis of the MCQ-30",
    "section": "",
    "text": "The Metacognitive Control System (MCS) model gives central importance to maladaptive metacognition in psychological vulnerability and disorder. The metacognitions questionnaire 30 (MCQ-30) is widely used to assess such metacognitions and to establish their effects. Previous studies consistently demonstrate that the MCQ-30 consists of five latent factors, with some factors showing wide-ranging positive associations with symptoms and some demonstrating more specific symptom links. Questions remain concerning relationships between MCQ-items (or domains) and the most central of these outside of the latent-factor model. In the present study we set out to explore the internal structure of the MCQ-30 using network analysis and estimated two graphical Gaussian models, one with items- and one with domains, in an unselected sample (N = 1080). The robustness and stability of the networks, as well as the node predictability were assessed. Among our observations was that the items of the MCQ-30 appeared to cluster in meaningful substructures, corresponding to metacognitive theory. Furthermore, “need for control” was the most centrally placed domain, suggesting it plays an important role in the network and that its activation has a strong influence on other nodes. The theoretical and clinical implications of the current findings are discussed in light of the metacognitive model of psychological disorder.\nRead more\nDownload"
  },
  {
    "objectID": "publications/resiliencepatterns.html",
    "href": "publications/resiliencepatterns.html",
    "title": "Resilience patterns of Swiss adolescents before and during the COVID-19 pandemic: a latent transition analysis",
    "section": "",
    "text": "This study investigated resilience patterns and predictors of these patterns (i.e. gender and migration background) among Swiss early adolescents in times of COVID-19. A total of 317 pupils participated at two time points. We conducted two separate latent class analyses and a latent transition analysis using mental health issues and protective factors as indicators. The results revealed three groups: resilient (high mental health issues, high protective factors), nonresilient (high mental health issues, low protective factors), and untroubled (low mental health issues, high protective factors). The resilient group was the most stable (91% stability), whereas the untroubled was the least stable (69% stability). Boys were more likely to be part of the untroubled group than the other groups at the second time point. Gender at the first time point and migration background at both time points were nonsignificant as predictors. Findings highlight the importance of group-specific research, health promotion, and interventions.\nRead more\nDownload"
  },
  {
    "objectID": "publications/resilienceprofiles.html",
    "href": "publications/resilienceprofiles.html",
    "title": "Resilience profiles across context: A latent profile analysis in a German, Greek, and Swiss sample of adolescents",
    "section": "",
    "text": "The present study investigated resilience profiles (based on levels of symptoms of anxiety and depression and five dimensions of protective factors) of 1,160 students from Germany (n = 346, 46.0% females, Mage = 12.77, SDage = 0.78), Greece (n = 439, 54.5% females, Mage = 12.68, SDage = 0.69), and Switzerland (n = 375, 44.5% females, Mage = 12.29, SDage = 0.88) using latent profile analyses. We also checked for measurement invariance and investigated the influence of gender and migration on class membership. A three-profile-solution was found for Switzerland (nonresilient 22.1%, moderately resilient 42.9%, untroubled 34.9%), and a four-profile-solution was the best fitting model for Germany (nonresilient 15.7%, moderately resilient 44.2%, untroubled 27.3%, resilient 12.7%) and Greece (nonresilient 21.0%, moderately resilient 30.8%, untroubled 24.9%, resilient 23.3%). Measurement invariance did not hold across the three countries. Profile differences regarding class membership predictions were detected for Germany and Greece, but none for Switzerland. Results implicate that resilience profiles are highly contextually sensitive, and resilience research findings should not be generalized considering the particularity of contexts, people, and outcomes.\nRead more\nDownload"
  },
  {
    "objectID": "publications/workability.html",
    "href": "publications/workability.html",
    "title": "Testing the longitudinal effect of metacognitive beliefs on the trajectory of work ability",
    "section": "",
    "text": "There is increasing need to identify factors that contribute to poor work ability with an aim to prevent work related problems such as sick leave and disability pension. In the Metacognitive Control System model, dysfunctional metacognitive beliefs are seen as an underlying factor in psychological vulnerability beyond disorder, and recent studies have reported that metacognitions are associated with work ability and work status. In the present study, we set out to test if there is a prospective relationship between dysfunctional metacognitions and self-assessed work ability. Individuals in working age (M = 37.19; SD = 10.31) participated in a four-timepoint self-report survey (N = 528; 75% females) separated by six weeks between each timepoint. Baseline gender differences and differences between participants by job status were conducted using t-test and one-way ANOVA, respectively. Latent growth curve with covariates assessed the impact of dysfunctional metacognitions on work ability across the four timepoints. Males reported higher work ability. Participants in fulltime job also reported higher work ability followed by those in part-time job, jobseekers, sick leave up to 12 months, and sick leave &gt; 12 months, respectively. Dysfunctional metacognitions predicted work ability over time when controlling for gender, age, physical health status, and three common categories of emotional distress symptoms. This finding suggest that dysfunctional metacognitions are a prospective predictor of work ability beyond health status and implies that these beliefs should be targeted with a view to increasing work ability and thus potentially reduce risk for sick leave and other work-related problems.\nRead more\nDownload"
  },
  {
    "objectID": "publications/changeininterpersonal.html",
    "href": "publications/changeininterpersonal.html",
    "title": "Change in interpersonal problems and metacognitive beliefs as predictors of improvement in patients with generalized anxiety disorder",
    "section": "",
    "text": "Introduction Generalized anxiety disorder (GAD) is characterized by persistent worry and anxiety, often with a chronic course. We tested the role of two suggested underlying factors in GAD, interpersonal problems and negative metacognitive beliefs, as predictors of trait-worry and trait-anxiety.\nMethods The sample consisted of 56 patients with a primary diagnosis of GAD from a randomized controlled trial. We first estimated the proportion of variance lying between the higher level of the data structure to account for potential therapists’ effects. Two hierarchical regression analyses were conducted testing change in interpersonal problems and negative metacognitive beliefs as predictors of change in trait-worry and trait-anxiety following treatment. Change in depression and anxiety symptoms was controlled.\nResults Change in negative metacognitive beliefs was the strongest predictor of improvement of both trait-worry and trait-anxiety. Change in interpersonal problems was not a unique predictor of change in trait-worry but did make a significant and unique contribution to trait-anxiety.\nConclusions Negative metacognitive beliefs may be important targets to improve trait-worry and trait-anxiety in GAD. Interpersonal problems may be relevant for trait-anxiety but could also be a surface marker of higher order vulnerability factors. Implications for treatment are discussed.\nRead more\nDownload"
  },
  {
    "objectID": "publications/RSAsicklisted.html",
    "href": "publications/RSAsicklisted.html",
    "title": "Measuring Resilience in Long-term Sick-listed Individuals: Validation of the Resilience Scale for Adults",
    "section": "",
    "text": "Return to work from long-term sick leave is influenced by personal and social factors, which can be measured by resilience, a construct that describe healthy adaptation against adversity. This study aimed to validate the validity and psychometric properties of the resilience scale for adults in a sample of long-term sick-listed individuals, and to investigate measurement invariance when compared with a university student sample. Confirmatory factor analysis was used on a sick-listed sample (n = 687) to identify the scale?s factor structure, and comparison with a university student sample (n = 241) was utilized to determine measurement invariance. Results show that a slightly modified factor structure, in accordance with previous research, achieved acceptable fit in the sick-listed sample, while comparisons with the student sample supported measurement invariance. This means that the study to a large degree support the factor structure of the resilience scale for adults in long-term sick-listed. Furthermore, the results indicate that the scale is similarly understood among long-term sick-listed as in a previously validated student sample. Thus, the resilience scale for adults can be a valid and reliable measure of protective factors in the long-term sickness absence and return to work context, and the subscale and total score can be interpreted similarly in long-term sick-listed as in other populations.\nRead more\nDownload"
  },
  {
    "objectID": "publications/MetacognitionCASAnx.html",
    "href": "publications/MetacognitionCASAnx.html",
    "title": "Prospective Relations Between Dysfunctional Metacognitive Beliefs, Metacognitive Strategies, and Anxiety: Results From a Four-Wave Longitudinal Mediation Model",
    "section": "",
    "text": "The metacognitive model of psychological disorders suggests that emotional disorders are related to maladaptive metacognitive strategies corresponding to underlying dysfunctional metacognitive beliefs. There is substantial empirical evidence supporting a role of metacognition in psychopathology, but fewer studies have evaluated the metacognitive model using longitudinal data and taken into consideration its differentiation between components and how they are hypothesized to be related to each other. Thus, more specific model evaluation is important as it relates to identifying mechanisms of disorder with a potential to provide clinical advances. In the present study, 868 participants took part in a 4-wave survey and reported on metacognitive beliefs and strategies and anxiety symptoms. Two longitudinal mediation models (forward and reversed causation) were run to test temporal precedence and bidirectional relations. The results indicated that metacognitive beliefs significantly predicted metacognitive strategies, which further predicted anxiety symptoms and mediated the indirect effect in the relationship between metacognitive beliefs and anxiety over time. The relationship between metacognitive beliefs and anxiety symptoms over time were bidirectional, but this relationship was not accounted for by metacognitive strategies. These findings largely support central predictions set forward by the metacognitive model and indicate that metacognitions play a preceding and maintaining role in anxiety.\nRead more\nDownload"
  },
  {
    "objectID": "publications/NetworkMCQCASSymp.html",
    "href": "publications/NetworkMCQCASSymp.html",
    "title": "The network structure of dysfunctional metacognitions, CAS strategies, and symptoms",
    "section": "",
    "text": "In the metacognitive model of psychological disorders, metacognitive strategies and corresponding underlying metacognitive beliefs intensify and maintain emotional distress symptoms. In the current study, our three objectives were to evaluate and replicate the network structure of dysfunctional metacognitions as assessed with the MCQ-30, to examine its stability when adding relevant covariates in the form of metacognitive strategies (worry and rumination) and symptoms (anxiety and depression), and to evaluate how different sets of dysfunctional metacognitions are more or less strongly linked differently to metacognitive strategies and symptoms. A cross-sectional university sample with a mean age of 26 years (N = 440; Males = 156, Females = 283) completed the Metacognitions Questionnaire–30, Penn State Worry Questionnaire, Ruminative Response Scale, and Hopkins Symptom Checklist. Data were analysed using psychological network analysis in R-studio statistical software. The network structure of dysfunctional metacognitions replicated well with item clusters that correspond to clinically meaningful substructures in the metacognitive model. Negative metacognitive beliefs and beliefs about uncontrollability might have more functional significance in the mutual connections between dysfunctional meta-domains as well as the connections with metacognitive strategies and symptoms. For worry and anxiety, negative beliefs about uncontrollability and corresponding danger of worry were more prominently connected in the network structure. For rumination, cognitive self-consciousness was more prominent, whereas for depression, need for control was more prominently connected. Support was found for mutual interdependence between different sets of dysfunctional metacognitive beliefs, that metacognitive beliefs are linked to but separate from metacognitive strategies, and that these may function together in affecting emotional distress symptoms.\nRead more\nDownload"
  },
  {
    "objectID": "publications/Incidencemental.html",
    "href": "publications/Incidencemental.html",
    "title": "Incidence of mental disorders in the general population aged 1–30 years disaggregated by gender and socioeconomic status",
    "section": "",
    "text": "Purpose The objective of this study was to estimate the incidence and age of onset of mental disorders diagnosed by gender and socioeconomic status (SES) in children, adolescents, and young adults up to 30 years of age in the whole population of the Basque Country (Spain).\nMethods All mental health diagnoses documented in Basque Health Service records from 1 January 2003 to 31 December 2018, were classified into eight clusters: anxiety, attention deficit hyperactivity disorder (ADHD), conduct disorders, depression, psychosis/personality disorders, substance use, eating disorders, and self-harm. We calculated incidence and cumulative incidence for each cluster, disaggregated by gender, and socioeconomic status (SES). Poisson regression analyses were performed.\nResults Overall, 9,486,853 person-years of observation were available for the 609,281 individuals included. ADHD and conduct disorders were diagnosed in the first decade, anxiety and depression disorders in the second and third decades, and psychosis/personality and substance use in the third. The cumulative incidence at 18 years of age for any type of disorder was 15.5%. The group with low SES had a statistically significantly higher incidence of all eight clusters. The incidence of ADHD, conduct disorders, depression, psychosis/personality disorders, and substance use was higher in males and that of anxiety, eating disorders and self-harm was higher in females.\nConclusions The incidence of mental disorders is high among children, adolescents, and young adults in the Basque Country underlining the need for preventive interventions. Marked differences by gender and SES highlight mental health inequalities, especially for depression and psychosis in low SES males..\nRead more\nDownload"
  },
  {
    "objectID": "quantposts/null hypothesis testing/index.html",
    "href": "quantposts/null hypothesis testing/index.html",
    "title": "Null Hypothesis Testing",
    "section": "",
    "text": "Researchers start their research by creating a null hypothesis, which is the assumption that there is no relationship between the variables being tested. They then collect data and use statistical tests to determine if the data is consistent with the null hypothesis, or if there is enough evidence to reject the null hypothesis.\nA researcher may select a sample of 750 students from the population of all NTNU students to investigate the relationship between attending lectures and exam anxiety. Ideally, the researcher wants to make conclusions about the population of all NTNU students using sample statistics which is computed based on the sample of 750 students. A sample statistic is a numerical summary from the sample data. Here, the mean of exam anxiety for the 750 students or the correlation between attending lectures and exam anxiety for the 750 students is a sample statistic. Its corresponding numeric value for all NTNU students is called a parameter (or population parameter). Although the researcher works with a sample of 750 students, the ultimate interest is in the population of all NTNU students. But the parameter value is unknown unless the researcher can gather all NTNU students.\nIndeed, a hypothesis is stated in reference to the population (e.g., there is no difference in height between the population of males and females), but sample data is used to test the hypothesis, which is how inferences about the population are drawn from the sample data.\nIt is almost impossible or could be very expensive and time consuming to test the entire population.\nSo, what does the researcher do?\nThe researcher uses sample statistics as estimates for the corresponding population parameters. But this has some problems due to sampling error or random variability. This is because whenever the researcher samples different groups of 750 students, the researcher may observe a mean of 4.50 for exam anxiety in Group 1 and 5.20 in Group 2 and yet still 3.75 in Group 3. This random variability in a sample statistic such as the mean of exam anxiety from sample to sample is called sampling error.\nSo, what does this mean for the researcher´s conclusions?\nIf the researcher makes conclusions based on the sample of 750 students, it will not be guaranteed that the conclusion will be observed in the population of all NTNU students due to sampling error. It could be that the mean of exam anxiety is not even close to any of the sample means and it could also be that the relationship between attending lectures and exam anxiety observed in the sample of 750 students, will not exist and that there will be no relationship between attending lectures and exam anxiety at all in the population. This would mean that the observed relationship between attending lectures and exam anxiety in the sample of 750 students is just due to sampling error or occurred by chance. This problem can be reduced or mitigated by power analysis and sample size calculations prior as part of the research design and prior to data calculation.\nNull hypothesis significance testing is a statistical technique used to determine if the results of a study occurred by chance, or if they are a true effect in the population. The general idea underpinning null hypothesis significance testing is based on the observed relationship in the sample data, which is that:\n\n\nThe observed effect or relationship in the sample data reflects sampling error or very likely occurred by chance. Thus, no true effect or relationship exists in the population.\n\n\nThe observed effect or relationship in the sample data reflects a true effect or relationship in the population. Thus, it is very unlikely to have occurred by chance.\n\n\nLet’s say that a researcher starts with a null hypothesis that there is no relationship between attending lectures and exam anxiety, and collects data from 750 students of NTNU. The researcher must choose a level of significance (such as 0.05) that represents the proportion of times (that, if the null hypothesis is true), a researcher will mistakenly reject the null hypothesis, or put simply, the probability of rejecting the null hypothesis in the long run (i.e., over several random samples from the population) if the null hypothesis is actually true.\nIf the null hypothesis is true (that, there is no relationship between attending lectures and exam anxiety), and a researcher mistakenly rejects it (therefore says that, there is a relationship between attending lectures and exam anxiety), this is called making a Type-1 error, and the probability of a researcher making this type of erroneous conclusion is set at 0.05 (as the alpha level). Thus, the level of significance or alpha can also be understood as the probability of making a Type-1 error, supposing the null hypothesis is true. This is because the level of significance or alpha is the threshold below which the decision to reject the null hypothesis is made. Consequently, supposing that the null hypothesis is true, the probability of rejecting the null hypothesis, thereby making a Type-1 error is the significance level or alpha that was chosen for the hypothesis test. Here, the researcher mistakenly concludes that there is something (or there is an effect or relationship) when there is nothing (no effect or no relationship). There is another error that can be made in hypothesis testing.\nLet’s briefly summarize the two types of errors in significance testing:\nSuppose the null hypothesis is true:\n\n\nA Type-1 error occurs when the null hypothesis is rejected.\n\n\nSuppose the null hypothesis is false:\n\n\nA Type-2 error occurs when the null hypothesis is not rejected.\n\n\nGoing back to our example, if the p-value is less than the level of significance or alpha, the researcher concludes that there is evidence to reject the null hypothesis. For example, if a correlation test shows a very low p-value, say p &lt; 0.05, this means that it is extremely or very unlikely that the results of the correlation test occurred by chance if the null hypothesis was true. The p-value is the probability of observing the sample data or one that is more extreme, if the null hypothesis was true.\nWhen the p-value, or the probability of observing the results given the null hypothesis, is less than the significance level or alpha, the researcher rejects the null hypothesis, and concludes that there is a significant relationship or effect between the variables being tested - that is, the relationship in the sample data reflects true effect or relationship in the population. For example, there is a significant relationship between attending lectures and exam anxiety in NTNU students.\nRejecting the null hypothesis doesn’t necessarily ‘prove’ that the alternative hypothesis is true. It simply means that based on the available evidence - that is, based on the sample data, it is more likely that there is a relationship between attending lectures and exam anxiety than that there isn’t. The decision to reject the null hypothesis is based on several factors, including the significance level or alpha, which specifies the maximum probability of falsely rejecting the null hypothesis if it is actually true in the population."
  },
  {
    "objectID": "quantposts/rejecting the null hypothesis/index.html",
    "href": "quantposts/rejecting the null hypothesis/index.html",
    "title": "Rejecting the Null Hypothesis",
    "section": "",
    "text": "Rejecting the null hypothesis is useful for drawing inferences in the sample as it allows the researcher to conclude about whether or not there is a statistically significant effect, difference or relationship between variables in the population.\nResearchers start their research by creating a null hypothesis, which is typically the assumption that there is no significant effect, difference or relationship between the variables in the population. Researchers then collect data from a sample of the population and use statistical tests to determine whether the sample data provides enough evidence to reject the null hypothesis in favor of an alternative hypothesis, which typically states that there is a significant effect, difference or relationship between the variables in the population.\nIf a researcher rejects the null hypothesis in favor of the alternative hypothesis, this means that the researcher can conclude that there is a statistically significant effect, difference or relationship between the variables in the population from which the sample was drawn. Making inferences to the population, even if the researcher only has data from a sample of that population, is because the researcher has determined that the observed results are unlikely to have occurred by chance, and so the results are representative of the population as a whole. See here"
  },
  {
    "objectID": "quantposts/rejecting the null hypothesis/index.html#example",
    "href": "quantposts/rejecting the null hypothesis/index.html#example",
    "title": "Rejecting the Null Hypothesis",
    "section": "Example",
    "text": "Example\n\nLet’s say that a researcher starts with a null hypothesis that there is no relationship between attending lectures and exam anxiety, and collects data from 750 students of NTNU. If a correlation test shows a very low p-value, say p &lt; 0.05, this means that it is very unlikely that the results of the correlation test could have occurred by chance if the null hypothesis was true. Since the p-value, or the probability of observing the results or one that is more extreme given the null hypothesis, is less than the significance level o alpha, researchers reject the null hypothesis for the the alternative hypothesis, which states that there is a significant relationship or effect between the variables being tested - that is, the observed relationship in the sample data reflects true effect or relationship in the population.\n\nIn our example, by rejecting the null hypothesis, the researcher concludes that attending lectures has an effect on exam anxiety, and that this is very unlikely to have occurred by chance if the null hypothesis was true. In this way, the relationship between attending lectures and exam anxiety in the sample of 750 students reflects a true effect in the population of all NTNU students from which the sample of 750 students was drawn."
  },
  {
    "objectID": "quantposts/chi_square/chi_sqaure.html",
    "href": "quantposts/chi_square/chi_sqaure.html",
    "title": "Association Between Two Categorical Variables",
    "section": "",
    "text": "We can analyse the association between two categorical variables in different ways (e.g., using stacked bar graphs or pie charts). The most common way is to use contingency tables with rows and columns displaying categories of each variable. The count or frequency of each pair of categories are given in a cell.\nWe will see how to analyse the association between two categorical variables using different functions in different packages in RStudio. The CrossTbale() function seems to be very popular as is the chisq.test() function. Another function is the ggbarstats() in the ‘ggstatsplot’ package. This package produces beautiful plots and charts that are publication-ready with good quality. By plotting your pie chart or stacked bar graph, the ggpiestats() and the ggbarstats() function also compute the Chi-squared test statistic, with very useful information in addition, including a Bayesian effect size.\nTo test the null hypothesis, we can use the CrossTable() function in the ‘gmodels’ package. Note that the CrossTable() can take both raw data and contingency table."
  },
  {
    "objectID": "quantposts/chi_square/chi_sqaure.html#crosstable-function",
    "href": "quantposts/chi_square/chi_sqaure.html#crosstable-function",
    "title": "Association Between Two Categorical Variables",
    "section": "CrossTable() function",
    "text": "CrossTable() function\nLet’s see how the CrossTable() function works\n\nCodedata &lt;- read.csv(\"/Volumes/anyan-1/frederickanyan.github.io/quantpost_data/happinesGSS12_long.csv\")# Read the data for the analysis \n\n\nLet’s see how a cross tabulation of the data looks\n\nCodelibrary(gmodels) #Load the packgae to access the CrossTable() function\nCrossTable(data$Income, data$Happy) #Get a cross tabulation of variables with cell counts/contingency table\n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  1733 \n\n \n             | data$Happy \n data$Income |       not |    pretty |      very | Row Total | \n-------------|-----------|-----------|-----------|-----------|\n     above   |        29 |       178 |       135 |       342 | \n             |     4.356 |     1.413 |     8.709 |           | \n             |     0.085 |     0.520 |     0.395 |     0.197 | \n             |     0.134 |     0.181 |     0.254 |           | \n             |     0.017 |     0.103 |     0.078 |           | \n-------------|-----------|-----------|-----------|-----------|\n     average |        83 |       494 |       277 |       854 | \n             |     5.163 |     0.135 |     0.898 |           | \n             |     0.097 |     0.578 |     0.324 |     0.493 | \n             |     0.384 |     0.501 |     0.522 |           | \n             |     0.048 |     0.285 |     0.160 |           | \n-------------|-----------|-----------|-----------|-----------|\n     below   |       104 |       314 |       119 |       537 | \n             |    20.530 |     0.235 |    12.604 |           | \n             |     0.194 |     0.585 |     0.222 |     0.310 | \n             |     0.481 |     0.318 |     0.224 |           | \n             |     0.060 |     0.181 |     0.069 |           | \n-------------|-----------|-----------|-----------|-----------|\nColumn Total |       216 |       986 |       531 |      1733 | \n             |     0.125 |     0.569 |     0.306 |           | \n-------------|-----------|-----------|-----------|-----------|\n\n \n\n\nFrequencies are displayed in each cell. The frequencies or cell counts in each cell can be converted to percentages (N/Row Total). Within each category of income, the percentage for the three categories of happiness is displayed. Thus, of the 342 people who reported their family income as above average, 135 reported themselves as very happy (39.5%). By contrast, 119 (22.2%) of the 537 people who reported below average family income, reported they were very happy.\nYou can reduce information in each cell by running the code below\n\nCodeCrossTable(data$Income, data$Happy, prop.t=FALSE, prop.r=FALSE, prop.c=FALSE) #To hide proportions in the rows and columns\n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n| Chi-square contribution |\n|-------------------------|\n\n \nTotal Observations in Table:  1733 \n\n \n             | data$Happy \n data$Income |       not |    pretty |      very | Row Total | \n-------------|-----------|-----------|-----------|-----------|\n     above   |        29 |       178 |       135 |       342 | \n             |     4.356 |     1.413 |     8.709 |           | \n-------------|-----------|-----------|-----------|-----------|\n     average |        83 |       494 |       277 |       854 | \n             |     5.163 |     0.135 |     0.898 |           | \n-------------|-----------|-----------|-----------|-----------|\n     below   |       104 |       314 |       119 |       537 | \n             |    20.530 |     0.235 |    12.604 |           | \n-------------|-----------|-----------|-----------|-----------|\nColumn Total |       216 |       986 |       531 |      1733 | \n-------------|-----------|-----------|-----------|-----------|"
  },
  {
    "objectID": "quantposts/chi_square/chi_sqaure.html#conditional-and-marginal-proportions",
    "href": "quantposts/chi_square/chi_sqaure.html#conditional-and-marginal-proportions",
    "title": "Association Between Two Categorical Variables",
    "section": "Conditional and marginal proportions",
    "text": "Conditional and marginal proportions\nConditional percentages show the distribution of proportions in one variable, conditional on the other variable - hence, also called conditional distributions. For example, the conditional distribution of happiness for those who reported average income are 9.7%, 57.8%, and 32.4%. They can also be interpreted as conditional probabilities. Given that an individual reported average family income, the probability of not being happy, or pretty happy, or very happy is 9.7, 57.8, and 32.4, respectively.\nMarginal proportions refer to the values in the margins of the contingency table. The marginal proportion of people who reported not happy, pretty happy, or very happy is 0.125(12.5%), 0.569(56.9%) and 0.306(30.6%), respectively.\nTo perform a Chi-squared test with the CrossTable() function, we can add some arguments to the previous code.\n\nCodeCrossTable(data$Income, data$Happy, \n           #fisher = TRUE, #To get fisher's exact test \n           chisq = TRUE, #To get pearson chi-square statistic\n           expected = TRUE, #To get the expected cell counts (which should be &gt; 5 in each cell)\n           ) \n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  1733 \n\n \n             | data$Happy \n data$Income |       not |    pretty |      very | Row Total | \n-------------|-----------|-----------|-----------|-----------|\n     above   |        29 |       178 |       135 |       342 | \n             |    42.627 |   194.583 |   104.791 |           | \n             |     4.356 |     1.413 |     8.709 |           | \n             |     0.085 |     0.520 |     0.395 |     0.197 | \n             |     0.134 |     0.181 |     0.254 |           | \n             |     0.017 |     0.103 |     0.078 |           | \n-------------|-----------|-----------|-----------|-----------|\n     average |        83 |       494 |       277 |       854 | \n             |   106.442 |   485.888 |   261.670 |           | \n             |     5.163 |     0.135 |     0.898 |           | \n             |     0.097 |     0.578 |     0.324 |     0.493 | \n             |     0.384 |     0.501 |     0.522 |           | \n             |     0.048 |     0.285 |     0.160 |           | \n-------------|-----------|-----------|-----------|-----------|\n     below   |       104 |       314 |       119 |       537 | \n             |    66.931 |   305.529 |   164.540 |           | \n             |    20.530 |     0.235 |    12.604 |           | \n             |     0.194 |     0.585 |     0.222 |     0.310 | \n             |     0.481 |     0.318 |     0.224 |           | \n             |     0.060 |     0.181 |     0.069 |           | \n-------------|-----------|-----------|-----------|-----------|\nColumn Total |       216 |       986 |       531 |      1733 | \n             |     0.125 |     0.569 |     0.306 |           | \n-------------|-----------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  54.04308     d.f. =  4     p =  5.154502e-11 \n\n\n \n\n\nFollowing is the Chi-squared statistic and corresponding p-value for the test of independence under the null hypothesis that, income and happiness are independent (no association). Since the p-value is very small (&lt; .05), we can reject the null hypothesis. Thus, there is an association between family income and happiness.\nIn other words, the observed association between family income and happiness in the sample data reflects a true association in the population, and it is very unlikely to have occurred by chance if the null hypothesis was true. Find out the problem with this conclusion here"
  },
  {
    "objectID": "quantposts/chi_square/chi_sqaure.html#chisq.test-function",
    "href": "quantposts/chi_square/chi_sqaure.html#chisq.test-function",
    "title": "Association Between Two Categorical Variables",
    "section": "chisq.test() function",
    "text": "chisq.test() function\nWe can also use a different function to perform the Chi-squared test. Here, we use the chisq.test() function in the ‘stats’ package, which also contains many other functions.\n\nCodechi.test &lt;- chisq.test(data$Income, data$Happy)#Create and object called chi.test and assign the result of the chisq.test function() into this object\nchi.test #Call the object to see its contents\n\n\n    Pearson's Chi-squared test\n\ndata:  data$Income and data$Happy\nX-squared = 54.043, df = 4, p-value = 5.155e-11\n\n\n\nCodechi.test$expected #To get expected cell counts. \n\n           data$Happy\ndata$Income       not   pretty     very\n    above    42.62666 194.5828 104.7905\n    average 106.44201 485.8881 261.6699\n    below    66.93133 305.5291 164.5395"
  },
  {
    "objectID": "quantposts/chi_square/chi_sqaure.html#using-standardized-residuals-to-reveal-patterns-of-associations",
    "href": "quantposts/chi_square/chi_sqaure.html#using-standardized-residuals-to-reveal-patterns-of-associations",
    "title": "Association Between Two Categorical Variables",
    "section": "Using standardized residuals to reveal patterns of associations",
    "text": "Using standardized residuals to reveal patterns of associations\nThe residuals show the difference between the observed counts and what the model predicts (the expected counts/frequencies) in a particular cell computed under the null hypothesis. The standardized residual is similar to the z-score and indicates the number of standard deviations that an observed count falls from its expected count. If the value of the standardized residual lies outside of +/-1.96, then it is significant at p &lt; .05; if it lies outside +/-2.58, then it is significant at p &lt;. 01 and when outside +/-3.29, then it is significant at p &lt; .001.\n\nCodechi.test$stdres #Assuming there is a significant result, the standardized residuals can help us to understand the patterns of association\n\n           data$Happy\ndata$Income        not     pretty       very\n    above   -2.4899518 -2.0210658  3.9551662\n    average -3.4099626  0.7870470  1.5977872\n    below    5.8295149  0.8885336 -5.1313795\n\n\nFor example, if we take the first cell - (i.e., people who reported above average family income, and not happy). We can say that, the observed count is 2.49 standard deviations below (because of the negative sign, -2.49) the expected count for this particular cell. The substantive interpretation is that, for people with above average family income, many fewer were not happy than what the model predicted or, in other words, what the assumption of independence between income and happiness would predict.\nWe can interpret positive standardized residuals first, followed by negative standardized residuals.\n\n\nFor standardized residuals 5.83 and 3.96, the observed count is much higher than the expected count (more than 3 standard deviations higher). For people who reported below average family income, many more were not happy. For people who reported above average family income, many more were very happy.\n\n\nFor standardized residuals -3.41, -2.02 and -5.13, the observed count is much lower than the expected count. For people who reported average family income, much fewer were not happy. For people who reported below average family income, much fewer were very happy.\n\n\nOverall, the association between income and happiness seems to be driven by average to above average family income, and much more so, by above average family income.\n\n\nThe Chi-squared test does not tell us where in the cell counts or frequencies the difference from independence lies, that is why the standardized residuals are useful for interpretation and understanding the patterns of association between the variables."
  },
  {
    "objectID": "quantposts/chi_square/chi_sqaure.html#ggpiestats-and-ggbarstats-function",
    "href": "quantposts/chi_square/chi_sqaure.html#ggpiestats-and-ggbarstats-function",
    "title": "Association Between Two Categorical Variables",
    "section": "ggpiestats() and ggbarstats() function",
    "text": "ggpiestats() and ggbarstats() function\nWe can also use the ‘ggstatsplot’ package for this exercise. This package “creates graphics with details from statistical tests included in the plots themselves. It provides an easier syntax to generate information-rich plots for statistical analysis of continuous (violin plots, scatterplots, histograms, dot plots, dot-and-whisker plots) or categorical (pie and bar charts) data”. See here\n\nCodelibrary(ggstatsplot) #Load the package to access the functions\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\n\nBy plotting a pie chart, we also get the results for the Chi-squared test\n\nCodeggpiestats(data = data,\n           x = Income,\n          y = Happy,\n          label = \"both\")\n\n\n\n\nWe can also perform and visualize the Chi-squared test of independence using the ggbarstats() function when we call the function to plot a stacked bar graph.\n\nCodeggbarstats(data = data, #The first argument is the data\n           x = Income,   #The variable to use as the rows in the contingency table\n          y = Happy,     #The variable to use as the columns in the contingency table.\n          label = \"both\") #You can use \"percentage\" or \"count\"\n\n\n\n\nAs can be seen, the proportion of people who reported below average family income reduced with increasing happiness whereas the proportion of people who reported above average family income increases with increasing happiness. This support the previous conclusion that, the association between income and happiness seems to be driven by above average family income.\nThis function automatically outputs the Cramer’s V with its 95% Confidence Interval next to the p-value. The effect size of .12 is a relatively weak association. It also provides a corresponding Bayesian effect size, which is much more useful. There is also a Bayes factor, which tests both the null and alternative hypothesis at the same time. The designation of ‘01’ returns a Bayes Factor in favor of the null hypothesis whereas ‘10’ returns a Bayes Factor in favor of the alternative hypothesis. The Bayes factor shows that the null hypothesis does not do well compared to the alternative hypothesis. This is evidence in favor of the alternative hypothesis that, there is an association between family income and happiness.\nFinally, this function shows the proportion test for family income (below average, average and above average) in each category of happiness (not happy, pretty happy, and very happy) under the null hypothesis that the sample proportions are not equal. They show whether the proportions inside each category of happiness differ. Since the p-values are all very small, we can conclude that the sample proportions of family income within each category of happiness differs. This type of Chi-squared test is referred to as the Chi-squared goodness-of-fit statistic, used to test hypothesis involving a single categorical variable from a single sample."
  },
  {
    "objectID": "quantposts/upset/upset.html",
    "href": "quantposts/upset/upset.html",
    "title": "Visualizing Sets",
    "section": "",
    "text": "Variables or columns are known as sets in upset visualization. Upset plots can be used to visualize the size and the pairwise combinations or intersections of sets and their aggregates. This facilitates easy-to-understand communication of the size and proportion of set memberships."
  },
  {
    "objectID": "quantposts/upset/upset.html#example",
    "href": "quantposts/upset/upset.html#example",
    "title": "Visualizing Sets",
    "section": "Example",
    "text": "Example\n\nLet’s say you want the size or proportion of your sample who meet cut-off for some disorders as well as co-morbidity across disorders. Upset plots can visualize the proportion of the sample who meet criteria for panic, separation anxiety disorder and selective mutism, or other kinds of combinations of sorts. For example, the proportion of people who meet panic disorder, but not separation anxiety disorder and PTSD, or the proportion who meet criteria for PTSD, but not depression and social anxiety disorders, and several other combinations.\n\nData with multiple variables or their combinations is often displayed in a Venn diagram. In some cases the Euler diagram is used. Both have limitations with increasing number of variables or sets. Upset plots can be used to visualize the size of different variables or sets, frequencies of their overlaps or intersections and their aggregates - for communicating set memberships.\nIn this tutorial post, we will see how to use the upset() function in the ‘UpSetR’ package to visualize intersecting sets.\nLoad data\n\nCodedata &lt;- read.csv(\"/Volumes/anyan-1/frederickanyan.github.io/quantpost_data/dataupset.csv\")#\n\n\n#head(data) #first few rows\n\n\nFollowing are symptoms in the data\n\n\nSeparation anxiety disorder - separation.\n\n\nSelective mutism - mutism.\n\n\nSpecific phobia - phobia.\n\n\nSocial anxiety disorder - social.\n\n\nPanic disorder - panic.\n\n\nGeneralized anxiety disorder - anxiety.\n\n\nDepression - depression.\n\n\nPost-traumatic stress disorder - ptsd.\n\n\nLet’s change the variable names to the symptom names\n\nCodenames(data) &lt;- c(\"separation\", \"mutism\", \"phobia\", \"social\", \"panic\", \"anxiety\", \"depression\", \"ptsd\")\n\n\nFor this tutorial, median split was used to categorize participants into two groups namely ‘clinical’ and ‘non-clinical’ - with binary coding as 1 and 0. You can use established cut-off scores for your own data, not the median split."
  },
  {
    "objectID": "quantposts/upset/upset.html#upsetr-package",
    "href": "quantposts/upset/upset.html#upsetr-package",
    "title": "Visualizing Sets",
    "section": "UpSetR package",
    "text": "UpSetR package\n\nCodelibrary(UpSetR) #Load the UpSetR package to access the upset () function\n\n\nNow visualize the data using the upset() function.\n\nCodeupset(data,                      #Name of data file \n      nsets = 8,                #To see all 8 sets in the upset plot\n      matrix.color = \"red\", \n      sets.bar.color = \"blue\", \n      order.by = \"freq\",         #You can order sets by frequencies \n      set_size.show = TRUE) \n\n\n\n\nThe blue bar chart shows the total size of the sets (i.e., set size).\nThe red filled-in circles corresponds to intersections or overlaps showing which set is part of an intersection or which disorder overlaps with which other disorder(s). For example, panic and mutism form an intersection or overlap, and so does panic and phobia. Additionally, panic, mutism, phobia and separation also form an intersection. And so on…\nThe black bar chart shows the occurrence or frequencies for each intersection (i.e., intersection size).\nRead more about upset plots"
  },
  {
    "objectID": "quantposts/practical prelims/practical.html",
    "href": "quantposts/practical prelims/practical.html",
    "title": "Preliminaries for Longitudinal Analysis",
    "section": "",
    "text": "Some practical preliminary steps are useful for performing longitudinal data analyses. Some preliminary steps might even already show whether the data will support your hypothesized growth function or to fit a different growth function. Here, I go through some of the practical preliminaries required for performing longitudinal data analyses when using wide data set or long data set. I will use the loneliness data set including 442 observations recorded across five time points.\nLoad packages\n\nCodesuppressPackageStartupMessages({\nlibrary(psych)  #For practical preliminaries: univariate and bivariate descriptive stats\nlibrary(tidyr) #For reshaping data\nlibrary(lcsm)   #For plotting longitudinal trajectories in a wide data set\nlibrary(ggplot2) #For plotting longitudinal trajectories in long data set\n})\n\n\n\n\nWIDE DATASET\nLONG DATASET\n\n\n\n\nCode## Read data \ndata &lt;- read.csv(\"/Volumes/anyan-1/frederickanyan.github.io/quantpost_data/data.csv\")\n#Create new data set with only your main outcome variables\nlonely &lt;- data[, c(\"personid\", \"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\")]\n\n\n1. Examine univariate and bivariate statistics\n\nCode#Examine descriptive statistics.\ndescribe(lonely[, 2:6])#univariate descriptives\n\n      vars   n mean   sd median trimmed  mad min  max range skew kurtosis   se\nlone1    1 398 1.46 0.46   1.32    1.38 0.34   1 3.75  2.75 1.81     3.95 0.02\nlone2    2 395 1.47 0.52   1.31    1.38 0.31   1 5.00  4.00 2.22     7.22 0.03\nlone3    3 390 1.53 0.52   1.36    1.44 0.37   1 3.78  2.78 1.52     2.27 0.03\nlone4    4 413 1.35 0.47   1.22    1.25 0.25   1 4.92  3.92 3.05    12.75 0.02\nlone5    5 409 1.32 0.39   1.20    1.24 0.25   1 3.43  2.43 2.45     7.22 0.02\n\n\nFirst thing to notice from the descriptive statistics is the number and pattern of missing data. It can also be noticed that, the means and standard deviations show a simple pattern with increases in the feeling of loneliness from T1 through to T3, and begins to decline afterwards though to T5 coupled with increases in variation and then a decline after T3.\nIt can be noticed already from the means that a linear growth function might not accurately characterize the trajectory in the data.\n2. Describe covariance and correlation matrices\n\nCode#bivariate descriptives\ncov(lonely[, 2:6], use='pairwise.complete.obs') #covariance matrix\n\n           lone1      lone2      lone3      lone4      lone5\nlone1 0.21451070 0.14910019 0.09978644 0.08198277 0.05209327\nlone2 0.14910019 0.27059267 0.13796998 0.10077467 0.06904941\nlone3 0.09978644 0.13796998 0.27223396 0.10690494 0.08475463\nlone4 0.08198277 0.10077467 0.10690494 0.21720685 0.07542655\nlone5 0.05209327 0.06904941 0.08475463 0.07542655 0.15471723\n\n\nThe feasibility of estimating a growth model can also be already determined by examining the covariance matrix. If the covariances between two adjacent time points (T1 and T2; T2 and T3; T3 and T4; T4 and T5) are higher than non-adjacent time points, this could likely indicate non-negative slope variance. For example, in our covariance matrix the observed covariances between two adjacent time points are 0.15, 0.14, 0.11 and 0.08. These covariances are sometimes higher but also smaller than non-adjacent time points and thus, does not easily determine that there would be no negative slope variance.\n\nCodecor(lonely[, 2:6], use='pairwise.complete.obs') #correlation matrix\n\n          lone1     lone2     lone3     lone4     lone5\nlone1 1.0000000 0.6153198 0.4666493 0.3902312 0.3027420\nlone2 0.6153198 1.0000000 0.5184437 0.4142563 0.3557064\nlone3 0.4666493 0.5184437 1.0000000 0.4944602 0.4240808\nlone4 0.3902312 0.4142563 0.4944602 1.0000000 0.4342628\nlone5 0.3027420 0.3557064 0.4240808 0.4342628 1.0000000\n\n\nThe correlations over time provide unique information for longitudinal analysis. Here, most of the correlations show modest associations, indicating that the level of stability of individual differences across time is modest to high.\n3. Supplement main analysis with bivariate scatter plots and correlations\n\nCode#bivariate scatter plots below the diagonal, histograms on the diagonal, and the Pearson correlation above the diagonal.\npairs.panels(lonely[, 2:6], lm = TRUE) #lm = TRUE to fit a regression line\n\n\n\n\nBivariate scatter plots and correlations along with histograms can be supplemented to the main analysis.\n4. Examine longitudinal plots\n\nCodeplot_trajectories(data = lonely,\n                  id_var = \"personid\", \n                  var_list = c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\"),\n                  xlab = \"Year\", ylab = \"Loneliness\",\n                  connect_missing = FALSE,   #Want to plot only complete observations\n                  random_sample_frac = 0.05, #You can select more or less than 5% of the data by adjusting this\n                  title_n = TRUE)\n\nWarning: Removed 9 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 10 rows containing missing values (`geom_point()`).\n\n\n\n\n\nMake longitudinal plots to show participant’s scores of loneliness indexed on the y-axis and time of observation on the x-axis. Here, you can make one longitudinal plot that visualizes the overall trajectory for all participants and one that visualizes the trajectory for a subset of the participants.\n5. Examine separate individual longitudinal plots\n\nCodeplot_trajectories(data = lonely,\n                  id_var = \"personid\", \n                  var_list = c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\"),\n                  xlab = \"Year\", ylab = \"Loneliness\",\n                  connect_missing = FALSE,   #Want to plot only complete observations\n                  random_sample_frac = 0.025, #You can select more or less than 5% of the data by adjusting this\n                  title_n = TRUE) +\n facet_wrap(~personid)\n\nWarning: Removed 5 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 5 rows containing missing values (`geom_point()`).\n\n\n\n\n\nMy personal choice has been to show separate individual longitudinal plots, but you can decide to show whichever one works for you.\n\n\n\n\nCode## Reshape from wide to long using tidyr\nlonelylong &lt;- lonely %&gt;%\n              pivot_longer(cols = 2:6,\n                           names_to = \"year\",\n                           values_to = \"lone\")\n\n\n1. Examine univariate and bivariate statistics\n\nCode#Examine descriptive statistics using the wide data set.\ndescribe(lonely[, 2:6]) #univariate descriptives\n\n      vars   n mean   sd median trimmed  mad min  max range skew kurtosis   se\nlone1    1 398 1.46 0.46   1.32    1.38 0.34   1 3.75  2.75 1.81     3.95 0.02\nlone2    2 395 1.47 0.52   1.31    1.38 0.31   1 5.00  4.00 2.22     7.22 0.03\nlone3    3 390 1.53 0.52   1.36    1.44 0.37   1 3.78  2.78 1.52     2.27 0.03\nlone4    4 413 1.35 0.47   1.22    1.25 0.25   1 4.92  3.92 3.05    12.75 0.02\nlone5    5 409 1.32 0.39   1.20    1.24 0.25   1 3.43  2.43 2.45     7.22 0.02\n\n\nFirst thing to notice from the descriptive statistics is the number and pattern of missing data. It can also be noticed that, the means and standard deviations show a simple pattern with increases in the feeling of loneliness from T1 through to T3, and begins to decline afterwards though to T5 coupled with increases in variation and then a decline after T3.\nIt can be noticed already from the means that a linear growth function might not accurately characterize the trajectory in the data.\n2. Describe covariance and correlation matrices\n\nCode#bivariate descriptives\ncov(lonely[, 2:6], use='pairwise.complete.obs') #covariance matrix\n\n           lone1      lone2      lone3      lone4      lone5\nlone1 0.21451070 0.14910019 0.09978644 0.08198277 0.05209327\nlone2 0.14910019 0.27059267 0.13796998 0.10077467 0.06904941\nlone3 0.09978644 0.13796998 0.27223396 0.10690494 0.08475463\nlone4 0.08198277 0.10077467 0.10690494 0.21720685 0.07542655\nlone5 0.05209327 0.06904941 0.08475463 0.07542655 0.15471723\n\n\nThe feasibility of estimating a growth model can also be already determined by examining the covariance matrix. If the covariances between two adjacent time points (T1 and T2; T2 and T3; T3 and T4; T4 and T5) are higher than non-adjacent time points, this could likely indicate non-negative slope variance. For example, in our covariance matrix the observed covariances between two adjacent time points are 0.15, 0.14, 0.11 and 0.08. These covariances are sometimes higher but also smaller than non-adjacent time points and thus, does not easily determine that there would be no negative slope variance.\n\nCodecor(lonely[, 2:6], use='pairwise.complete.obs') #correlation matrix\n\n          lone1     lone2     lone3     lone4     lone5\nlone1 1.0000000 0.6153198 0.4666493 0.3902312 0.3027420\nlone2 0.6153198 1.0000000 0.5184437 0.4142563 0.3557064\nlone3 0.4666493 0.5184437 1.0000000 0.4944602 0.4240808\nlone4 0.3902312 0.4142563 0.4944602 1.0000000 0.4342628\nlone5 0.3027420 0.3557064 0.4240808 0.4342628 1.0000000\n\n\nThe correlations over time provide unique information for longitudinal analysis. Here, most of the correlations show modest associations, indicating that the level of stability of individual differences across time is modest to high.\n3. Supplement main analysis with bivariate scatter plots and correlations\n\nCode#bivariate scatter plots below the diagonal, histograms on the diagonal, and the Pearson correlation above the diagonal.\npairs.panels(lonely[, 2:6], lm = TRUE) #lm = TRUE to fits regression line\n\n\n\n\nBivariate scatter plots and correlations along with histograms can be supplemented to the main analysis.\n4. Examine longitudinal plots\n\nCode#Longitudinal plots with the long data set\nggplot(data = lonelylong[which(lonelylong$personid &lt; 26),], #Select the first 25 participants to show\n       aes(x = year, y = lone, group = personid)) +\n       geom_line() +\n       #geom_smooth(method = lm, se = FALSE, size = 1) +\n       xlab(\"Time of observation\") +\n       ylab(\"Loneliness\")\n\nWarning: Removed 17 rows containing missing values (`geom_line()`).\n\n\n\n\n\nMake longitudinal plots to show participant’s scores of loneliness indexed on the y-axis and time of observation on the x-axis. Here, you can make one longitudinal plot that visualizes the overall trajectory for all participants and one that visualizes the trajectory for a subset of the participants.\n5. Include separate individual trajectories\n\nCode#Longitudinal plots with the long data set\nggplot(data = lonelylong[which(lonelylong$personid &lt; 6),], #Select only five participants \n       aes(x = year, y = lone, group = personid)) +\n       geom_line() +     \n       #geom_smooth(method = lm, se = FALSE, size = 1) +\n       xlab(\"Time of observation\") +\n       ylab(\"Loneliness\")+\nfacet_wrap(~personid)\n\nWarning: Removed 1 row containing missing values (`geom_line()`).\n\n\n\n\n\nMy personal choice has been to show separate individual longitudinal plots, but you can decide to show whichever one works for you."
  },
  {
    "objectID": "quantposts/two occasion/two.html",
    "href": "quantposts/two occasion/two.html",
    "title": "Analyses of Two Occasion Data",
    "section": "",
    "text": "This tutorial compares different models of change when presented with data collected at two time points - which could be pre-test and post test data or some other form of observational data.\n1. Difference Score Model of Change\nThe Raw Change Model also called the Difference Score Model is probably the most obvious and common. A researcher computes change between two time points by subtracting T1 scores from T2 scores (T2 - T1). Resulting from this subtraction whether greater or lesser is the change that has occurred between two time points. The Difference Score Model examine between-person differences in the change that has occurred within individuals from T1 to T2. Common in this model of change is to use the computed (resulting) change or difference (D), that is, T2 - T1 = D, as an outcome in subsequent analysis - which is why it is often called the Difference Score Model\nThis approach is, however, heavily criticized and has a rather bad reputation even until today, and started with Cronbach & Furby, 1970\n\n\n“Raw change” or “raw gain” scores formed by subtracting pretest scores from posttest scores lead to fallacious conclusions, primarily because such scores are systematically related to any random error of measurement. Although the unsuitability of such scores has long been discussed, they are still employed, even by some otherwise sophisticated investigators. Cronbach & Furby, 1970, p. 68\n\n\nThe Difference Score Model is badly reputed mainly for the following:\n\n\nHigh correlation between T1 scores and the computed D scores. With very high T1 scores, the D tends to be highly negatively correlated.\n\n\nMeasurement error contained in T1 and T2 scores become attenuated in the computed D scores, greatly limiting the reliability of the computed D scores.\n\n\nSome authors have suggested ways to mitigate the problems of the Difference Score Model including, to account for the confounding effects of T1 when using the computed D scores in subsequent analysis. See Rogosa & Willett, 1983; Gottman & Rushe, 1993\n2. Autoregressive Model of Change\nThe Autoregressive Model of Change focuses on the end state by using T2 as the DV and T1 as the predictor. This model responds to questions about individual differences in change by regressing T2 on T1, and does not answer questions about intraindividual change same as for many panel models. The regression coefficient resulting from regressing a variable at later time point on itself at an earlier time point is called the autoregressive effect. In this case, the regression of T2 on T1 is the autoregressive effect, which describes the stability of individual differences from T1 to T2.\n\n\nA larger coefficient means that individual differences have not changed much from T1 to T2 - higher stability.\n\n\nA smaller autoregressive coefficient means that there has been a larger change in individual differences from T1 to T2 - lower stability.\n\n\nThe Autoregressive Model of Change has had some appeal since the 70s and obviously since the criticisms of the Difference Score Model by Cronbach & Furby, 1970, p. 68. The appealing feature of the The Autoregressive Model of Change stems from the fact that when T2 is regressed on T1 (autoregressive effect), the remaining variance or the residual variance in T2 can be predicted by other variables in which case, this becomes the prediction of the stable portion of variable T, say our variable is T measured at T1 and T2. This is what cross-lagged effects are most useful for, as for example, T2 can be regressed on both T1 and X1, which means X1 will predict T2 when controlling for prior levels of T at T1. So, X1 effectively predicts the stable portion or the residual variance of T (at T2) - which is why this mode is sometimes called residual change model.\nIn the Autoregressive Cross-lagged Panel Models, controlling for prior levels of a variable while predicting the residual variance by another variable allows a researcher to rule out the possibility that a cross-lagged effect is confounded by the fact that the predictor (X) and outcome (T) are both correlated at T1. That is, the reason X1 predicts T2 is because X and T are correlated at T1 - this cannot hold when controlling for the prior levels of T. Most Autoregressive Model of Change and the Autoregressive Cross-lagged Panel Models have appeared in both observed or latent variable modeling.\n3. Latent Difference Score Model of Change\nThe Latent Difference Score also called the Latent Change Score Model is seen by some methodologists as a framework on its own for modelling change with the capability for testing within-person change hypotheses and between-person differences in within-person change. Like the Autoregressive Models of Change, this Latent Change Score Model can accommodate bivariate information in which two variables are modeled concurrently with cross-lagged effects. The Latent Change Score Model starts by decomposing an observed variable into a latent true score and a latent residual score. This model incorporates the autoregressive effect into the latent true score such that the true score at T2 is a function of the latent true score at T1, plus the amount of change that has occurred between T1 and T2. The Latent Change Score Model extends over four successive models of change namely, no change, constant change, proportional change and dual change. The dual change combines both constant and proportional change components. In my opinion, the Latent Change Score Model is useful when bivariate information is incorporated thereby responding to questions about the nature and sequence of subsequent changes in x versus y. In other words, which variable between x and y is a leading indicator of subsequent changes in the other variable?\nResearchers must think very carefully of their theories of change when selecting between the different existing models. The Latent Change Score Model while offering greater flexibility in modelling within-person changes and between-person differences in within-person change, emphasizes time-dependent associations when bivariate or multivariate information is incorporated, and this must be carefully considered to benefit from this modelling framework.\nLoad packages\n\nCodesuppressPackageStartupMessages({\nlibrary(lcsm)   #For analyzing the latent change score model\nlibrary(ggplot2) #For visualization \n})\n\n\nRead data\n\nCodedata &lt;- read.csv(\"/Volumes/anyan-1/frederickanyan.github.io/quantpost_data/data.csv\")\ndata &lt;- data[, c(\"personid\", \"lone3\", \"lone5\")] #Create new data set with only your main outcome variables\nnames(data) &lt;- c(\"id\", \"loneT1\", \"loneT2\") #Rename variables to represent T1 and T2\n\n\n\n\nDifference Score Model\nAutoregressive Model\nLatent Change Score Model\n\n\n\nDetermine the difference score (T2-T1 = D)\n\nCodedata$lonediff &lt;- data$loneT2-data$loneT1 #You can attach the new variable lonediff to the data with $\n\n\nNow regress D on T1\n\nCodediffM &lt;- lm(formula = lonediff ~ 1 + loneT1,\n             data = data,\n             na.action = na.exclude)\nsummary(diffM)\n\n\nCall:\nlm(formula = lonediff ~ 1 + loneT1, data = data, na.action = na.exclude)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75462 -0.17873 -0.07593  0.08014  2.10763 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.83528    0.05658   14.76   &lt;2e-16 ***\nloneT1      -0.68587    0.03502  -19.59   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3489 on 367 degrees of freedom\n  (73 observations deleted due to missingness)\nMultiple R-squared:  0.5111,    Adjusted R-squared:  0.5098 \nF-statistic: 383.7 on 1 and 367 DF,  p-value: &lt; 2.2e-16\n\n\nThe Intercept (0.83) is the expected value of the change in loneliness for an individual with a score of 0 = at T1. The slope of loneT1 indicates the expected negative difference in within-person change (-0.68) for a unit change in loneliness at T1.\n\nCodeggplot(data = data, aes(x = loneT1, y = lonediff)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", formula = y ~ 1 + x, \n              se = TRUE, fullrange = TRUE, color = \"blue\", linewidth = 1.5) +\n  xlab(\"Loneliness T1\") + \n  ylab(\"Difference in Loneliness T2 and T1\") +\n  ggtitle(\"The Difference score Model\")\n\nWarning: Removed 73 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 73 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThe plot above represents the slope better.\n\n\nRegress T2 on T1\n\nCodearM &lt;- lm(formula = loneT2 ~ 1 + loneT1,\n            data = data,\n            na.action = na.exclude)\nsummary(arM)\n\n\nCall:\nlm(formula = loneT2 ~ 1 + loneT1, data = data, na.action = na.exclude)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75462 -0.17873 -0.07593  0.08014  2.10763 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.83528    0.05658  14.762   &lt;2e-16 ***\nloneT1       0.31413    0.03502   8.971   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3489 on 367 degrees of freedom\n  (73 observations deleted due to missingness)\nMultiple R-squared:  0.1798,    Adjusted R-squared:  0.1776 \nF-statistic: 80.48 on 1 and 367 DF,  p-value: &lt; 2.2e-16\n\n\nThe Intercept (0.83) is the expected value of loneliness at T2 for an individual with a score of 0 = at T1. The slope of loneT1 (0.31) indicates the stability of between-person differences from T1 to T2. The autoregressive coefficient show that individual differences in loneliness is moderately stable between the two time points as the autoregressive coefficient is about moderate size.\nRemember T1 and T2 were originally (lone3 at T3) and (lone5 at T5), which means that the distance between time points is longer than it would be for adjacent time points (lone3 at T3 and lone4 at T4 versus lone4 at T4 and lone5 at T5). The longer time that elapses between measurement occasions, the higher it is that the autoregressive effect dissipates and thereby resulting in less stability of individual differences from one occasion to the next. Therefore, the time lag between time points is very crucial in panel models since this may have implications for when hypothesized autoregressive or cross-lagged effects may disappear.\nAlternatively, we expect a positive difference of (0.31) in loneliness at T2 for a every unit change in loneliness at T1\n\nCodeggplot(data = data, aes(x = loneT1, y = loneT2)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", formula= y ~ 1 + x, \n              se = TRUE, fullrange = TRUE, color=\"blue\", linewidth = 1.5) +\n  xlab(\"Loneliness T1\") + \n  ylab(\"Loneliness T2\") +\n  ggtitle(\"The Autoregressive Model of Chang\")\n\nWarning: Removed 73 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 73 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThe plot represents the expected positive difference in loneliness at T2 for a every unit change in loneliness at T1\n\n\nTBC"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Longitudinal analyses of the Mental health, Vulnerability, and Protective factors among Norwegian Afghanistan Veterans\n\n\n\n\n\n\n\nveterans\n\n\nresilience\n\n\nmental health\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2023\n\n\nFrederick Anyan\n\n\n\n\n\n\n  \n\n\n\n\nResilience to Loneliness for Mental and Physical Health outcomes(RESLON-MPH)\n\n\n\n\n\n\n\nresilience\n\n\nloneliness\n\n\nsocial isolation\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2022\n\n\nFrederick Anyan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "The network structure of dysfunctional metacognitions, CAS strategies, and symptoms\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2023\n\n\n\n\n\n\n  \n\n\n\n\nMeasuring Resilience in Long-term Sick-listed Individuals: Validation of the Resilience Scale for Adults\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2023\n\n\n\n\n\n\n  \n\n\n\n\nProspective Relations Between Dysfunctional Metacognitive Beliefs, Metacognitive Strategies, and Anxiety: Results From a Four-Wave Longitudinal Mediation Model\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nFeb 17, 2023\n\n\n\n\n\n\n  \n\n\n\n\nChange in interpersonal problems and metacognitive beliefs as predictors of improvement in patients with generalized anxiety disorder\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\n\n\n\n\n  \n\n\n\n\nIncidence of mental disorders in the general population aged 1–30 years disaggregated by gender and socioeconomic status\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nTesting the longitudinal effect of metacognitive beliefs on the trajectory of work ability\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2022\n\n\n\n\n\n\n  \n\n\n\n\nThe network structure of dysfunctional metacognition: Analysis of the MCQ-30\n\n\n\n\n\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nResilience patterns of Swiss adolescents before and during the COVID-19 pandemic: a latent transition analysis\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2022\n\n\n\n\n\n\n  \n\n\n\n\nMetacognition, Cognition and Social Anxiety: A Test of Temporal and Reciprocal Relationships\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nResilience profiles across context: A latent profile analysis in a German, Greek, and Swiss sample of adolescents\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2022\n\n\n\n\n\n\n  \n\n\n\n\nSick leave and return to work for patients with anxiety and depression: A longitudinal study of trajectories before, during and after work-focused treatment\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2021\n\n\n\n\n\n\n  \n\n\n\n\nRelevance of well-being, resilience, and health-related quality of life to mental health profiles of European adolescents: results from a cross-sectional analysis of the school-based multinational UPRIGHT project\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLoneliness in social relationships: Mapping the nomological network of loneliness with key conceptual domains and theoretical constructs\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\nLoneliness\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2021\n\n\n\n\n\n\n  \n\n\n\n\nMeasuring Resilience Across Participating Regions in the UPRIGHT EU Horizon 2020 Project: Factor Structure and Psychometric Properties of the Resilience Scale for Adolescents\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nFeb 17, 2021\n\n\n\n\n\n\n  \n\n\n\n\nHousing first, connection second: the impact of professional helping relationships on the trajectories of housing stability for people facing severe and multiple disadvantage\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nWorking Alliance\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2021\n\n\n\n\n\n\n  \n\n\n\n\nPsychometric properties of the Resilience Scale for Adolescents (READ) and Measurement Invariance Across Two Different German-Speaking Samples\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2020\n\n\n\n\n\n\n  \n\n\n\n\nChange in Physical Activity During the Coronavirus Disease 2019 Lockdown in Norway: The Buffering Effect of Resilience on Mental Health\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nDec 15, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDevelopment and validation of the theory-driven School Resilience Scale for Adults: Preliminary results\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nInterpersonal stress, anxiety and depressive symptoms: Results from a moderated mediation analysis with resilience\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nCo-creation and regional adaptation of a resilience-based universal whole-school program in five European regions\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTemporal and Reciprocal Relations Between Worry and Rumination Among Subgroups of Metacognitive Beliefs\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2020\n\n\n\n\n\n\n  \n\n\n\n\nProspective relations between loneliness in different relationships, metacognitive beliefs, worry and common mental health problems\n\n\n\n\n\n\n\nMental Health\n\n\nMetacognitive Theory\n\n\nCognitive Theory\n\n\nLoneliness\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2020\n\n\n\n\n\n\n  \n\n\n\n\nResilience Moderates Negative Outcome from Stress during the COVID-19 Pandemic: A Moderated-Mediation Approach\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2020\n\n\n\n\n\n\n  \n\n\n\n\nUPRIGHT, a resilience-based intervention to promote mental well-being in schools: study rationale and methodology for a European randomized controlled trial\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMeasuring Resilience Across Australia and Norway: Validation and Psychometric Properties of the English Version of the Resilience Scale for Adults\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2019\n\n\n\n\n\n\n  \n\n\n\n\nSpecificity in mediated pathways by anxiety symptoms linking adolescent stress profiles to depressive symptoms: Results of a moderated mediation approach\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nThe coping mechanism and strategies of hypertension patients in Ghana: The role of religious faith, beleifs and practices\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nQualitative Interview Research\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2017\n\n\n\n\n\n\n  \n\n\n\n\nAnxiety symptoms mediate the relationship between exposure to stressful negative life events and depressive symptoms: A conditional process modelling of the protective effects of resilience\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2017\n\n\n\n\n\n\n  \n\n\n\n\nStress of home life and gender role socializations, family cohesion, and symptoms of anxiety and depression\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2017\n\n\n\n\n\n\n  \n\n\n\n\nAdolescent stress and symptoms of anxiety and depression: Resilience explains and differentiates the relationships\n\n\n\n\n\n\n\nMental Health\n\n\nResilience Theory\n\n\nVulnerability-Stress Theory\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2016\n\n\n\n\n\n\n  \n\n\n\n\nThe influence of power shifts in data collection and analysis stages : A focus on qualitative research interview\n\n\n\n\n\n\n\nQualitative Interview Research\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2013\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "quantposts.html",
    "href": "quantposts.html",
    "title": "Quant Posts",
    "section": "",
    "text": "Analyses of Two Occasion Data\n\n\n\nChange\n\n\nDifference Score\n\n\nAutoregressive\n\n\n\n\n\n\n\nFrederick Anyan\n\n\nSep 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPreliminaries for Longitudinal Analysis\n\n\n\n\n\n\nFrederick Anyan\n\n\nSep 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Sets\n\n\n\nSets\n\n\nVenn diagram\n\n\n\n\n\n\n\nFrederick Anyan\n\n\nJun 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssociation Between Two Categorical Variables\n\n\n\nCategorical variables\n\n\n\n\n\n\n\nFrederick Anyan\n\n\nJun 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRejecting the Null Hypothesis\n\n\n\nNull hypothesis\n\n\nSample statistics\n\n\nPopulation parameters\n\n\n\n\n\n\n\nFrederick Anyan\n\n\nMay 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNull Hypothesis Testing\n\n\n\nNull hypothesis\n\n\nSample statistics\n\n\nPopulation parameters\n\n\n\n\n\n\n\nFrederick Anyan\n\n\nMay 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshops/NTNU_2021_19_20_May/NTNU2021May.html",
    "href": "workshops/NTNU_2021_19_20_May/NTNU2021May.html",
    "title": "Latent Growth Curve Models (LGCM) & Growth Mixture Models (GMM) - Two-day Workshop",
    "section": "",
    "text": "Research questions examining within-person changes or joint within-person changes and between-person differences in the stability and change in individuals’ attributes over time make longitudinal data incredibly useful. Longitudinal data offers many possibilities to describe differences in how and when people change and explain why. Methodological limitations in calculating difference score, taking residualized scores, correlation among repeated measures, and other limitations mean that appropriate growth models must be estimated.\nStructural Equation Modelling (SEM) is a family of related analysis techniques – correlations, regression analyses and factor analyses, using both observed and unobserved (latent) variables to offer a flexible framework for analysing longitudinal data (and cross-sectional data too). Analysing growth models in the SEM framework provide a highly convenient and statistically rigorous framework for applied research in the social, behavioural, and educational sciences.\nThis course is a data analysis course, not a statistics course and will cover basic and advanced longitudinal SEM model using Mplus in a very easy and efficient implementation. Additionally, to make the course more ‘theory- and practice-based’ than ‘equations-based’, the models that will be estimated will be guided by the overarching objectives of longitudinal research described in the seminal work of Baltes and Nasselroade (1979).\nDownload"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "",
    "text": "Different analysis techniques allow researchers to examine change in outcome variable(s) across time, including regression methods, mean comparisons and repeated measures ANOVA - although with some limitations. A common practice in developmental research is to assess growth trajectory to understand developmental change - how and when it happens, interindividual differences in how and when it happens, as well as why it happens. Structural Equation Modelling (SEM) is a family of related analysis techniques – correlations, regression analyses and factor analyses, using both observed and unobserved (latent) variables to offer a flexible framework for analyzing developmental change in a highly convenient and statistically rigorous framework for applied research in the social, behavioral, and educational sciences.\nThis workshop will cover basic and advanced longitudinal SEM models using Mplus in a very easy and efficient implementation. To make the workshop more ‘theory- and practice-based’ than ‘equations-based’, the models that will be estimated will be guided by the overarching objectives of longitudinal research (see Baltes & Nesselroade, 1979; McArdle, 2012).\nFollowing are models shown in the tab groups"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#no-growthlinear-and-quadratic-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#no-growthlinear-and-quadratic-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "No growth/Linear and Quadratic growth models",
    "text": "No growth/Linear and Quadratic growth models\nBasic growth models are described here, including the No growth model or the Intercept only model - which is a logical starting point for growth modelling. We want to reject the no growth modelling as it predicts no overall rate of change across time. The next model is the Linear growth curve model which predicts a linear rate of change across time. The Quadratic growth curve model is a non-linear growth curve model that predicts an overall accelerartion or deceleration in the rate of change when controlling for the linear change across time. Although the Quadratic growth curve model can be a useful alternative when the Linear growth curve model fits poorly or there is some degree of nonlinearity in the observed data, it can present much interpretation difficulty. The Latent basis growth curve model allows the data to define the growth function - discussed in the workshop.\n\nModel 1Model 2Model 3\n\n\nTITLE:  001_No_change_No_growth_Intercept_only_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON; \n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\nESTIMATOR = ML;\n\nMODEL:\n  I|lone1@1 lone2@1 lone3@1 lone4@1 lone5@1;!Fix the loading for the intercept growth factor to 1\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  002_Linear_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\nESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6; !Include a slope growth factor and fix to the time scores of observation\n\nOUTPUT:\n  SAMPSTAT;\n\nPLOT:\n  TYPE = PLOT3;\n  SERIES = lone1 - lone5(S); !You can add a plot of the slope growth function \n\n\nTITLE:  003_Quadratic_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S Q|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6; !Include the quadratic growth function, \n                                                 !but don't include a second-order power term as Mplus will automatically do this for you\n\nOUTPUT:\n  SAMPSTAT;\n\nPLOT:\n  TYPE = PLOT3;\n  SERIES = lone1 - lone5(S);"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#bilinearsplinepiecewisemultiphase-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#bilinearsplinepiecewisemultiphase-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Bilinear/Spline/Piecewise/Multiphase growth models",
    "text": "Bilinear/Spline/Piecewise/Multiphase growth models\nThe Quadratic growth curve model is specified by adding a second-order power of time to the Linear growth curve model, which means that there would be a high correlation between the power terms. This can be resolved by centering the intercept growth factor in the middle of the observation, but becomes more difficult when moving to higher-order polynomials. For this reason, it is recommended to examine the data if a Piecewise growth curve model could be an alternative solution. The most common type is the Bilinear growth curve model which joins two linear growth factors. It also goes by the name Spline growth model and Multiphase growth model. They can accommodate different linear or nonlinear growth functions by segmenting the period of observation with a knot point often called transition points when there are theoretical reasons to separate the observations into discrete phases - hence their name Multiphase growth model. For example, they can be used to model developmental changes that occur during pre-school, primary school and high school with transition points at when a child begins primary school and also at when s/he begins high school.\n\nModel 4Model 5Model 6\n\n\nTITLE:  004_Bilinear_spline_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S1|lone1@0 lone2@1 lone3@3 lone4@3 lone5@3;!Slope 1\n  I S2|lone1@0 lone2@0 lone3@0 lone4@1 lone5@3;!Slope 2\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  002_Bilinear_spline_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S1|lone1@-3 lone2@-2 lone3@0 lone4@0 lone5@0;!Slope 1\n  I S2|lone1@0 lone2@0 lone3@0 lone4@1 lone5@3;!Slope 2\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  002_Bilinear_spline_growht_curve_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S1|lone1@-3 lone2@-3 lone3@-3 lone4@-2 lone5@0;!Slope 1\n  I S2|lone1@-3 lone2@-2 lone3@0 lone4@0 lone5@0;!Slope 2\n\nOUTPUT:\n  SAMPSTAT STAND;"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#growth-models-with-time--varying-and-invariant-predictors-and-distal-outcomes",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#growth-models-with-time--varying-and-invariant-predictors-and-distal-outcomes",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Growth models with time- varying and invariant predictors and distal outcomes",
    "text": "Growth models with time- varying and invariant predictors and distal outcomes\nDynamic predictors that change across time can be incorporated into the growth model to simultaneously estimate the overall rate of change and the change from the time-varying predictors. These dynamic, time-varying predictors account for within-person changes by altering the trajectory of growth in an individual. Between-person differences in the within-person rate of change can be explained by the inclusion of time invariant predictors such as gender or experimental conditions. Growth factors can be hypothesized to predict distal outcomes that are measured after the growth process such as the rate of change in metacognitve therapy predicting recovery status in a 24-month follow up.\n\nModel 7Model 8Model 9Model 10\n\n\nTITLE:  005_Linear_growht_curve_model_with_time_varying_covariate\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5\n  host1 host2 host3 host4 host5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;!Growth for loneliness\n\n!Regress loneliness on time-varying covariate\n  lone1 ON host1;!By adding labels to the parameter estimates\n  lone2 ON host2;!you can test whether TVC effects are constant over time\n  lone3 ON host3;\n  lone4 ON host4;\n  lone5 ON host5;\n\n  !However, if you already assume constant effect of TVC over time\n  !and do not want to test, you can use this model specification\n  !lone1 ON host1(a);!By adding the same label (a) to the parameter estimates\n  !lone2 ON host2(a);!you constrain the effects to be constant across time\n  !lone3 ON host3(a);\n  !lone4 ON host4(a);\n  !lone5 ON host5(a);\n\n!Fix TVC covariance with intercept and slope to zero\n  I S WITH host1-host5@0;\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  006_Linear_growht_curve_model_with_time_invariant_covariates\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5 female;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  I S ON female; !Regress growth factors on the time-invariant covariate\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  007_Linear_growht_curve_model_with_time-invariant and time-varying covariates\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5\n  host1 host2 host3 host4 host5\n  female pdu1 ace1;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  I S ON female pdu1 ace1;!Regress growth factors on time-invariant covariates\n\n  lone1 ON host1(a);!Regress loneliness on TVC\n  lone2 ON host2(a);!Constrain TVC effect to be equal across time\n  lone3 ON host3(a);\n  lone4 ON host4(a);\n  lone5 ON host5(a);\n\n  I S WITH host1-host5@0; !Fix TVC covariance with intercept and slope to zero\n\n  female pdu1 ace1 WITH host1-host5; !Estimate the covaraince between covariates\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  008_Linear_growht_curve_model_with_growth_factors_predicting_distal_outcome\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5 subs5;\n  \nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n    \n  subs5 ON I S; !Regress distal outcome on growth factors and time-invariant predictors\n    \n  !subs5 ON I S female pdu1 ace1;\n\n  !Regress growth factors on time-invariant covariates\n  !I S ON female pdu1 ace1;\n\n  !female pdu1 ace1;\n  ![female pdu1 ace1];\n  !female pdu1 ace1 WITH female pdu1 ace1;\n\nOUTPUT:\n  SAMPSTAT;"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#multiple-group-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#multiple-group-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Multiple group growth models",
    "text": "Multiple group growth models\nA Multiple-group growth model approach offers greater flexibility in explaining between-person differences in the within-person rate of change than the Growth model with time invariant covariate. For example, the Wald test of differences in growth parameters can be tested within the multiple-group approach to explain whether, on average, the experimental group experience greater overall decline than the control group - thus providing insights into how and why individuals differ in their rate of change and by how much difference. The multiple-group approach can inform about differences in all the growth functions’ parameters - including the growth factors means, co/variances and residual variances.\n\nModel 11Model 12Model 13Model 14\n\n\nTITLE:  009_Multigroup_LGCM_M1_Invariance_model\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nGROUPING = FEMALE (0 = MALES 1 = FEMALES);\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  !Estimate means of growth factors and label them\n  [I](INT);\n  [S](SLP);\n\n  !Estimate variances of growth factors\n  I(INT_V);\n  S(SLP_V);\n\n  !Estimate covariance of growth factors\n  I WITH S(IS_COV);\n\n  !Estimate residual variance and constrain them equal\n  lone1-lone5(RES);\n\n  !Sequentially testing models means that specific parameters are of interest\n  !For those parameters, we will begin by constraining them to be equal (identical) across both groups\n  !Those parameters are (MEANS OF GROWTH FACTORS, COVARIANCES AND RESIDUAL VARIANCES)\n  !In subsequent models, we will freely estimate those parameters\n\nMODEL MALES:\n  !Growth factor means for males\n  [I](INT);!The INT label will make the males' intercept growth factor identical to the\n  [S](SLP);!The labelling for all the parameters will make them idenitcal for males and\n\n  !Growth factor variances for males\n  I(INT_V);\n  S(SLP_V);\n\n  !Growth factor covariance for males\n  I WITH S(IS_COV);\n\n  !Residual variances for males\n  lone1-lone5(RES);\n\nMODEL FEMALES:\n  !Gorwth factor means for females\n  [I](INT);!The INT label will make the females' intercept growth factor identical to th\n  [S](SLP);\n\n  !Growth factor variances for females\n  I(INT_V);\n  S(SLP_V);\n\n  !Growth factor covariance for females\n  I WITH S(IS_COV);\n\n  !Residual variances for females\n  lone1-lone5(RES);\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  009_Multigroup_LGCM_M2_Growth_factor_means\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nGROUPING = FEMALE (0 = MALES 1 = FEMALES);\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  [I](INT);\n  [S](SLP);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\nMODEL MALES:\n  [I](INT_M); !Free growth factor means by using different labels or completely removing\n  [S](SLP_M);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\nMODEL FEMALES:\n  [I](INT_F);!Different labels are used to freely estimate the growth factor means\n  [S](SLP_F);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\n!MODEL TEST:\n  !INT_M = INT_F;\n  !0 = INT_M-INT_F;\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  009_Multigroup_LGCM_M3_Growth_factor_means_and covariances\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nGROUPING = FEMALE (0 = MALES 1 = FEMALES);\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  [I](INT);\n  [S](SLP);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\nMODEL MALES:\n  [I S];!First: Growth factor means are freely estimated\n  I S;!Second: Growth factor variances are freely estimated\n\n  I WITH S;!Second: Growth factor covariances are freely estimated\n\n  lone1-lone5(RES);\n\nMODEL FEMALES:\n  [I S];!First: Growth factor means are freely estimated\n  I S;!Second: Growth factor variances are freely estimated\n\n  I WITH S;!Second: Growth factor covariances are freely estimated\n\n  lone1-lone5(RES);\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  009_Multigroup_LGCM_M4_Growth_factor_means_and covariances_with_residual_variances\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  lone1 lone2 lone3 lone4 lone5;\n\nGROUPING = FEMALE (0 = MALES 1 = FEMALES);\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n\nMODEL:\n  I S|lone1@0 lone2@1 lone3@3 lone4@4 lone5@6;\n\n  [I](INT);\n  [S](SLP);\n\n  I(INT_V);\n  S(SLP_V);\n\n  I WITH S(IS_COV);\n\n  lone1-lone5(RES);\n\nMODEL MALES:\n  [I S](INT_M SLP_M);!First: Growth factor means are freely estimated\n  I S;!Second: Growth factor variances are freely estimated\n\n  I WITH S;!Second: Growth factor covariances are freely estimated\n\n  lone1-lone5;!Third, residual variances freely estimated\n\nMODEL FEMALES:\n  [I S](INT_F SLP_F);!First: Growth factor means are freely estimated\n  I S;!Second: Growth factor variances are freely estimated\n\nI WITH S;!Second: Growth factor covariances are freely estimated\n\n  lone1-lone5;!Third: residual variances freely estimated\n\n!MODEL TEST:\n!  0 = INT_M - INT_F;\n\nOUTPUT:\n  SAMPSTAT;"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#modelling-co-development-and-multivariate-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#modelling-co-development-and-multivariate-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Modelling co-development and Multivariate growth models",
    "text": "Modelling co-development and Multivariate growth models\nModelling the co-development among different attributes such as the comorbidity of anxiety and depression is becoming more common. Multivariate growth models also called Parallel growth models can accommodate different growth functions among two or more attributes. Care must be taken and theoretical considerations must be prioritized when choosing between Multivariate growth curve models and the Growth curve models with time-varying covariates. The two are related but answer different research questions.\n\nModel 15Model 16Model 17\n\n\nTITLE:  010_Parallel_growth_curve_model_anxiety_and_depressive symptoms\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n  MODEL = NOCOV;!Suppress Mplus default correlations between the growth factors\n  !That way, you have control over what variables you want to correlate or\n  \nMODEL:\n  I_ANX S_ANX|anx1@0 anx2@1 anx3@3 anx4@4 anx5@6;!anxiety symptoms growth\n  I_DEP S_DEP|dep1@0 dep2@1 dep3@3 dep4@4 dep5@6;!depressive symptoms\n\n  !Correlate the growth factors\n  I_ANX WITH S_ANX;\n  I_DEP WITH S_DEP;\n\n  I_ANX WITH I_DEP;\n  S_ANX WITH S_DEP;\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  010_Parallel_growth_curve_model_anxiety_and_depressive symptoms_autocorrelations\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n  MODEL = NOCOV;!Suppress Mplus default correlations between the growth factors\n  !That way, you have control over what variables you want to correlate or\n  \nMODEL:\n  I_ANX S_ANX|anx1@0 anx2@1 anx3@3 anx4@4 anx5@6;!anxiety symptoms growth\n  I_DEP S_DEP|dep1@0 dep2@1 dep3@3 dep4@4 dep5@6;!depressive symptoms\n\n  !Correlate the growth factors\n  I_ANX WITH S_ANX;\n  I_DEP WITH S_DEP;\n\n  I_ANX WITH I_DEP;\n  S_ANX WITH S_DEP;\n\n  !Within subdomain autocorrelations\n  anx1 anx2 anx3 anx4 PWITH anx2 anx3 anx4 anx5; !PWITH means pair with\n  dep1 dep2 dep3 dep4 PWITH dep2 dep3 dep4 dep5;\n\nOUTPUT:\n  SAMPSTAT;\n\n\nTITLE:  010_Parallel_growth_curve_model_anxiety_and_depressive symptoms_cross_domain_corre\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  anx1 anx2 anx3 anx4 anx5\n  dep1 dep2 dep3 dep4 dep5;\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n  MODEL = NOCOV;!Suppress Mplus default correlations between the growth factors\n  !That way, you have control over what variables you want to correlate or\n  \nMODEL:\n  I_ANX S_ANX|anx1@0 anx2@1 anx3@3 anx4@4 anx5@6;!anxiety symptoms growth\n  I_DEP S_DEP|dep1@0 dep2@1 dep3@3 dep4@4 dep5@6;!depressive symptoms\n\n  !Correlate the growth factors\n  I_ANX WITH S_ANX;\n  I_DEP WITH S_DEP;\n\n  I_ANX WITH I_DEP;\n  S_ANX WITH S_DEP;\n\n  !Cross subdomain correlations\n  anx1 anx2 anx3 anx4 anx5 PWITH dep1 dep2 dep3 dep4 dep5;\n\n\nOUTPUT:\n  SAMPSTAT;"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#sequentially-contingent-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_Mplus/LGCM_Mplus.html#sequentially-contingent-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with Mplus",
    "section": "Sequentially contingent growth models",
    "text": "Sequentially contingent growth models\nGrowth in one attribute can predict the growth that occur in another attribute later in the developmental process. The rate of change in language development during pre-school may predict the rate of change in language skills during primary school. Sequentially contingent growth models offer flexibility in modelling such relations in the developmental process that occur in different stages, but might be contingent on each other.\n\nModel 18\n\n\nTITLE:  011_Sequentially_contingent_growth_curve_model_anxiety_T1_T5_predicting_depression\n\nDATA:\nFILE IS data.dat;\nLISTWISE = ON;\n\nVARIABLE:\nNAMES ARE\n  id female pdu1 ace1 worry1\n  lone1 lone2 lone3 lone4 lone5\n  anx1 anx2 anx3 anx4 anx5\n  dep6 dep7 dep8 dep9 dep10!Time of observations modified for pedagogical reasons\n  host1 host2 host3 host4 host5\n  percon5 percon5b subs5 subs5b sleep5 sleep5b;\n\nUSEVARIABLES ARE\n  anx1 anx2 anx3 anx4 anx5\n  dep6 dep7 dep8 dep9 dep10;!Time of observations modified for pedagogical reasons\n\nMISSING ARE ALL (-999);\n\nANALYSIS:\n  ESTIMATOR = ML;\n  MODEL = NOCOV;!Suppress Mplus default correlations between the growth factors\n                    !That way, you have control over what variables you want to correlate or\nMODEL:\n  I_ANX S_ANX|anx1@0 anx2@1 anx3@3 anx4@4 anx5@6;!anxiety symptoms growth\n  I_DEP S_DEP|dep6@0 dep7@1 dep8@2 dep9@3 dep10@4;!Equidistant time scores for depressiv\n\n  !Correlate the growth factors\n  I_ANX WITH S_ANX;\n  I_DEP WITH S_DEP;\n\n  !Add sequqntially contingent growth factors\n  I_DEP S_DEP PON I_ANX S_ANX; !Pair ON\n\nOUTPUT:\n  SAMPSTAT;\n\n\n\n\n\n\n\n\n\nFeel free to contact me at frederick.anyan@ntnu.no for advise or invitation to present workshops in your own institution."
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "",
    "text": "Different analysis techniques allow researchers to examine change in outcome variable(s) across time, including regression methods, mean comparisons and repeated measures ANOVA - although with some limitations. A common practice in developmental research is to assess growth trajectory to understand developmental change - how and when it happens, interindividual differences in how and when it happens, as well as why it happens. Structural Equation Modelling (SEM) is a family of related analysis techniques – correlations, regression analyses and factor analyses, using both observed and unobserved (latent) variables to offer a flexible framework for analyzing developmental change in a highly convenient and statistically rigorous framework for applied research in the social, behavioral, and educational sciences.\nThis workshop will cover basic and advanced longitudinal SEM models using R in a very easy and efficient implementation. To make the workshop more ‘theory- and practice-based’ than ‘equations-based’, the models that will be estimated in this workshop will be guided by the overarching objectives of longitudinal research (see Baltes & Nesselroade, 1979; McArdle, 2012).\nReferences\nFollowing are models shown in the tab groups\nTab group 1\nTab group 2\nTab group 3\nTab group 4\nTab group 5\nTab group 6\nIf you are not interested in the practical preliminaries, you can jump to the No growth/Linear and Quadratic growth models by clicking on the options on your right"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#practical-preliminaries",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#practical-preliminaries",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Practical preliminaries",
    "text": "Practical preliminaries\nLoad packages\n\nCodesuppressPackageStartupMessages({\n#library(haven) #To read dataset into R. \nlibrary(psych)  #For practical preliminaries: univariate and bivariate descriptive stats\nlibrary(lcsm)   #For plotting longitudinal trajectories from wide data set\nlibrary(lavaan) #For calling sem/cfa/growth functions. We will use the growth() function in the lavaan pacakage, which also has other functions. [See here](https://lavaan.ugent.be)\nlibrary(ggplot2)\n})\n\n\nRead data\n\nCodedata &lt;- read.csv(\"/Volumes/anyan-1/frederickanyan.github.io/quantpost_data/data.csv\")\n#Create new data set with only your main outcome variables\nlonely &lt;- data[, c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\")]\n#To plot longitudinal trajectories, create a new data set of only your outcome variables with id included\nlonelytrajectory &lt;- data[, c(\"personid\", \"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\")]\n\n\n\n\nExamine univariate and bivariate statistics\nLongitudinal plots\n\n\n\n\nCode#Examine descriptive statistics.\ndescribe(lonely) #univariate descriptives \n\n      vars   n mean   sd median trimmed  mad min  max range skew kurtosis   se\nlone1    1 398 1.46 0.46   1.32    1.38 0.34   1 3.75  2.75 1.81     3.95 0.02\nlone2    2 395 1.47 0.52   1.31    1.38 0.31   1 5.00  4.00 2.22     7.22 0.03\nlone3    3 390 1.53 0.52   1.36    1.44 0.37   1 3.78  2.78 1.52     2.27 0.03\nlone4    4 413 1.35 0.47   1.22    1.25 0.25   1 4.92  3.92 3.05    12.75 0.02\nlone5    5 409 1.32 0.39   1.20    1.24 0.25   1 3.43  2.43 2.45     7.22 0.02\n\nCode#bivariate descriptives\ncov(lonely, use='pairwise.complete.obs') #covariance matrix\n\n           lone1      lone2      lone3      lone4      lone5\nlone1 0.21451070 0.14910019 0.09978644 0.08198277 0.05209327\nlone2 0.14910019 0.27059267 0.13796998 0.10077467 0.06904941\nlone3 0.09978644 0.13796998 0.27223396 0.10690494 0.08475463\nlone4 0.08198277 0.10077467 0.10690494 0.21720685 0.07542655\nlone5 0.05209327 0.06904941 0.08475463 0.07542655 0.15471723\n\nCodecor(lonely, use='pairwise.complete.obs') #correlation matrix\n\n          lone1     lone2     lone3     lone4     lone5\nlone1 1.0000000 0.6153198 0.4666493 0.3902312 0.3027420\nlone2 0.6153198 1.0000000 0.5184437 0.4142563 0.3557064\nlone3 0.4666493 0.5184437 1.0000000 0.4944602 0.4240808\nlone4 0.3902312 0.4142563 0.4944602 1.0000000 0.4342628\nlone5 0.3027420 0.3557064 0.4240808 0.4342628 1.0000000\n\nCode#bivariate scatter plots below the diagonal, histograms on the diagonal, and the Pearson correlation above the diagonal.\npairs.panels(lonely, lm = TRUE) #lm = TRUE to fit a regression line if needed\n\n\n\n\nExplanatory test or how to intepret and use results from preactical preliminaries can be found here\n\n\n\nCodeplot_trajectories(data = lonelytrajectory,\n                  id_var = \"personid\", \n                  var_list = c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\"),\n                  xlab = \"Year\", ylab = \"Loneliness\",\n                  connect_missing = FALSE,   #Want to plot only complete observations\n                  random_sample_frac = 0.05, #You can select more or less than 5% of the data by adjusting this\n                  title_n = TRUE)\n\nWarning: Removed 9 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 10 rows containing missing values (`geom_point()`).\n\n\n\n\n\nYou can plot separate individual trajectories\n\nCodeplot_trajectories(data = lonelytrajectory,\n                  id_var = \"personid\", \n                  var_list = c(\"lone1\", \"lone2\", \"lone3\", \"lone4\", \"lone5\"),\n                  xlab = \"Year\", ylab = \"Loneliness\",\n                  connect_missing = FALSE,   #Want to plot only complete observations\n                  random_sample_frac = 0.025, #You can select more or less than 5% of the data by adjusting this\n                  title_n = TRUE) +\n facet_wrap(~personid)\n\nWarning: Removed 5 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 5 rows containing missing values (`geom_point()`).\n\n\n\n\n\nExplanatory test or how to intepret and use results from preactical preliminaries can be found here"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#no-growthlinear-and-quadratic-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#no-growthlinear-and-quadratic-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "No growth/Linear and Quadratic growth models",
    "text": "No growth/Linear and Quadratic growth models\nBasic growth models are described here, including the No growth model or the Intercept only model - which is a logical starting point for growth modelling. We want to reject the no growth modelling as it predicts no overall rate of change across time. The next model is the Linear growth curve model which predicts a linear rate of change across time. The Quadratic growth curve model is a non-linear growth curve model that predicts an overall accelerartion or deceleration in the rate of change when controlling for the linear change across time. Although the Quadratic growth curve model can be a useful alternative when the Linear growth curve model fits poorly or there is some degree of nonlinearity in the observed data, it can present much interpretation difficulty. The Latent basis growth curve model allows the data to define the growth function - discussed in the workshop.\n\n\nModel 1\nModel 2\nModel 3\n\n\n\n\nCode# 001_No growth curve model\nnogrowth &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5'\nfit_nogrowth &lt;- growth(nogrowth, data = data)\nsummary(fit_nogrowth, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 37 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         7\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               186.433\n  Degrees of freedom                                13\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.607\n  Tucker-Lewis Index (TLI)                       0.698\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -814.634\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1643.269\n  Bayesian (BIC)                              1669.669\n  Sample-size adjusted Bayesian (SABIC)       1647.466\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.204\n  90 Percent confidence interval - lower         0.179\n  90 Percent confidence interval - upper         0.230\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.172\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n    i                 1.398    0.018   79.816    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.109    0.010   10.537    0.000\n   .lone2             0.142    0.013   11.035    0.000\n   .lone3             0.167    0.015   11.279    0.000\n   .lone4             0.112    0.011   10.587    0.000\n   .lone5             0.092    0.009   10.119    0.000\n    i                 0.075    0.008    9.531    0.000\n\n\n\n\n\nCode# 002_Linear growth curve model\nlinear &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5'\nfit_linear &lt;- growth(linear, data = data)\nsummary(fit_linear, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 49 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                75.244\n  Degrees of freedom                                10\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.852\n  Tucker-Lewis Index (TLI)                       0.852\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -759.040\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1538.080\n  Bayesian (BIC)                              1575.795\n  Sample-size adjusted Bayesian (SABIC)       1544.076\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.143\n  90 Percent confidence interval - lower         0.113\n  90 Percent confidence interval - upper         0.174\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.097\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s                -0.015    0.002   -6.246    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n    i                 1.466    0.024   62.031    0.000\n    s                -0.025    0.004   -5.784    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.059    0.010    5.761    0.000\n   .lone2             0.114    0.011   10.114    0.000\n   .lone3             0.172    0.015   11.659    0.000\n   .lone4             0.114    0.010   11.066    0.000\n   .lone5             0.047    0.010    4.929    0.000\n    i                 0.139    0.015    9.310    0.000\n    s                 0.003    0.001    5.839    0.000\n\n\n\n\n\nCode# 003_Quadratic growth curve model\nquadratic &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n           q =~ 0*lone1 + 1*lone2 + 9*lone3 + 16*lone4 + 36*lone5'\nfit_quadratic &lt;- growth(quadratic, data = data)\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_quadratic, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 76 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                46.671\n  Degrees of freedom                                 6\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.908\n  Tucker-Lewis Index (TLI)                       0.846\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -744.754\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1517.507\n  Bayesian (BIC)                              1570.308\n  Sample-size adjusted Bayesian (SABIC)       1525.902\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.145\n  90 Percent confidence interval - lower         0.108\n  90 Percent confidence interval - upper         0.185\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.998\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.074\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n  q =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             9.000                           \n    lone4            16.000                           \n    lone5            36.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s                -0.020    0.009   -2.179    0.029\n    q                 0.000    0.001    0.265    0.791\n  s ~~                                                \n    q                -0.002    0.001   -1.792    0.073\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n    i                 1.446    0.024   60.828    0.000\n    s                 0.017    0.014    1.284    0.199\n    q                -0.007    0.002   -3.384    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.037    0.014    2.584    0.010\n   .lone2             0.118    0.012    9.942    0.000\n   .lone3             0.144    0.014   10.115    0.000\n   .lone4             0.099    0.011    8.672    0.000\n   .lone5             0.099    0.027    3.684    0.000\n    i                 0.148    0.019    7.974    0.000\n    s                 0.018    0.007    2.697    0.007\n    q                 0.000    0.000    0.959    0.337"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#bilinearsplinepiecewisemultiphase-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#bilinearsplinepiecewisemultiphase-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Bilinear/Spline/Piecewise/Multiphase growth models",
    "text": "Bilinear/Spline/Piecewise/Multiphase growth models\nThe Quadratic growth curve model is specified by adding a second-order power of time to the Linear growth curve model, which means that there would be a high correlation between the power terms. This can be resolved by centering the intercept growth factor in the middle of the observation, but becomes more difficult when moving to higher-order polynomials. For this reason, it is recommended to examine the data if a Piecewise growth curve model could be an alternative solution. The most common type is the Bilinear growth curve model which joins two linear growth factors. It also goes by the name Spline growth model and Multiphase growth model. They can accommodate different linear or nonlinear growth functions by segmenting the period of observation with a knot point often called transition points when there are theoretical reasons to separate the observations into discrete phases - hence their name Multiphase growth model. For example, they can be used to model developmental changes that occur during pre-school, primary school and high school with transition points at when a child begins primary school and also at when s/he begins high school.\n\n\nModel 4_1\nModel 4_2\nModel 4_3\n\n\n\n\nCode# 004_Bilinear/Spline growth curve model\nbilinear &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s1 =~ 0*lone1 + 1*lone2 + 3*lone3 + 3*lone4 + 3*lone5\n           s2 =~ 0*lone1 + 0*lone2 + 0*lone3 + 1*lone4 + 3*lone5'\nfit_bilinear &lt;- growth(bilinear, data = data)\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_bilinear, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 67 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                40.781\n  Degrees of freedom                                 6\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.921\n  Tucker-Lewis Index (TLI)                       0.869\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -741.809\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1511.618\n  Bayesian (BIC)                              1564.418\n  Sample-size adjusted Bayesian (SABIC)       1520.012\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.134\n  90 Percent confidence interval - lower         0.097\n  90 Percent confidence interval - upper         0.175\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.991\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.074\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s1 =~                                               \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             3.000                           \n    lone5             3.000                           \n  s2 =~                                               \n    lone1             0.000                           \n    lone2             0.000                           \n    lone3             0.000                           \n    lone4             1.000                           \n    lone5             3.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s1               -0.015    0.005   -2.851    0.004\n    s2               -0.019    0.004   -5.012    0.000\n  s1 ~~                                               \n    s2                0.000    0.002    0.083    0.934\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n    i                 1.444    0.024   61.016    0.000\n    s1                0.007    0.008    0.807    0.420\n    s2               -0.059    0.008   -7.002    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.046    0.012    3.772    0.000\n   .lone2             0.114    0.011   10.134    0.000\n   .lone3             0.130    0.016    8.057    0.000\n   .lone4             0.106    0.011    9.719    0.000\n   .lone5             0.082    0.022    3.665    0.000\n    i                 0.140    0.017    8.385    0.000\n    s1                0.008    0.002    3.404    0.001\n    s2                0.002    0.004    0.571    0.568\n\n\n\n\n\nCode# 004_2_Bilinear/Spline growth curve model - 2\nbilinear_2 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s1 =~ -3*lone1 + -2*lone2 + 0*lone3 + 0*lone4 + 0*lone5\n           s2 =~ 0*lone1 + 0*lone2 + 0*lone3 + 1*lone4 + 3*lone5'\nfit_bilinear_2 &lt;- growth(bilinear_2, data = data)\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_bilinear_2, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 62 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                40.781\n  Degrees of freedom                                 6\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.921\n  Tucker-Lewis Index (TLI)                       0.869\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -741.809\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1511.618\n  Bayesian (BIC)                              1564.418\n  Sample-size adjusted Bayesian (SABIC)       1520.012\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.134\n  90 Percent confidence interval - lower         0.097\n  90 Percent confidence interval - upper         0.175\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.991\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.074\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s1 =~                                               \n    lone1            -3.000                           \n    lone2            -2.000                           \n    lone3             0.000                           \n    lone4             0.000                           \n    lone5             0.000                           \n  s2 =~                                               \n    lone1             0.000                           \n    lone2             0.000                           \n    lone3             0.000                           \n    lone4             1.000                           \n    lone5             3.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s1                0.010    0.005    2.009    0.045\n    s2               -0.018    0.006   -3.254    0.001\n  s1 ~~                                               \n    s2                0.000    0.002    0.083    0.934\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n    i                 1.465    0.025   57.734    0.000\n    s1                0.007    0.008    0.807    0.420\n    s2               -0.059    0.008   -7.002    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.046    0.012    3.772    0.000\n   .lone2             0.114    0.011   10.134    0.000\n   .lone3             0.130    0.016    8.057    0.000\n   .lone4             0.106    0.011    9.719    0.000\n   .lone5             0.082    0.022    3.665    0.000\n    i                 0.126    0.018    7.130    0.000\n    s1                0.008    0.002    3.404    0.001\n    s2                0.002    0.004    0.571    0.568\n\n\n\n\n\nCode# 004_3_Bilinear/Spline growth curve model - 3\nbilinear_3 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s1 =~ -3*lone1 + -3*lone2 + -3*lone3 + -2*lone4 + 0*lone5\n           s2 =~ -3*lone1 + -2*lone2 + 0*lone3 + 0*lone4 + 0*lone5'\nfit_bilinear_3 &lt;- growth(bilinear_3, data = data)\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_bilinear_3, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 68 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                40.781\n  Degrees of freedom                                 6\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               451.170\n  Degrees of freedom                                10\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.921\n  Tucker-Lewis Index (TLI)                       0.869\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -741.809\n  Loglikelihood unrestricted model (H1)       -721.418\n                                                      \n  Akaike (AIC)                                1511.618\n  Bayesian (BIC)                              1564.418\n  Sample-size adjusted Bayesian (SABIC)       1520.012\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.134\n  90 Percent confidence interval - lower         0.097\n  90 Percent confidence interval - upper         0.175\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.991\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.074\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s1 =~                                               \n    lone1            -3.000                           \n    lone2            -3.000                           \n    lone3            -3.000                           \n    lone4            -2.000                           \n    lone5             0.000                           \n  s2 =~                                               \n    lone1            -3.000                           \n    lone2            -2.000                           \n    lone3             0.000                           \n    lone4             0.000                           \n    lone5             0.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s1               -0.012    0.008   -1.377    0.168\n    s2                0.011    0.003    3.342    0.001\n  s1 ~~                                               \n    s2                0.000    0.002    0.083    0.934\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n    i                 1.288    0.019   68.489    0.000\n    s1               -0.059    0.008   -7.002    0.000\n    s2                0.007    0.008    0.807    0.420\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.046    0.012    3.772    0.000\n   .lone2             0.114    0.011   10.134    0.000\n   .lone3             0.130    0.016    8.057    0.000\n   .lone4             0.106    0.011    9.719    0.000\n   .lone5             0.082    0.022    3.665    0.000\n    i                 0.036    0.022    1.637    0.102\n    s1                0.002    0.004    0.571    0.568\n    s2                0.008    0.002    3.404    0.001"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#growth-models-with-time--varying-and-invariant-predictors-and-distal-outcomes",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#growth-models-with-time--varying-and-invariant-predictors-and-distal-outcomes",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Growth models with time- varying and invariant predictors and distal outcomes",
    "text": "Growth models with time- varying and invariant predictors and distal outcomes\nDynamic predictors that change across time can be incorporated into the growth model to simultaneously estimate the overall rate of change and the change from the time-varying predictors. These dynamic, time-varying predictors account for within-person changes by altering the trajectory of growth in an individual. Between-person differences in the within-person rate of change can be explained by the inclusion of time invariant predictors such as gender or experimental conditions. Growth factors can be hypothesized to predict distal outcomes that are measured after the growth process such as the rate of change in metacognitve therapy predicting recovery status in a 24-month follow up.\n\n\nModel 5\nModel 6\nModel 7\nModel 8\n\n\n\n\nCode# 005_Linear growth curve model with time-varying covariates \ntimevaryingcov &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n# Time-varying covariates\nlone1 ~ host1             #lone1 ~ eq*host1\nlone2 ~ host2             #lone2 ~ eq*host2\nlone3 ~ host3             #lone3 ~ eq*host3\nlone4 ~ host4             #lone4 ~ eq*host4\nlone5 ~ host5             #lone5 ~ eq*host5\n\n#Estimate the means of the TVC\nhost1 ~ 1\nhost2 ~ 1\nhost3 ~ 1\nhost4 ~ 1\nhost5 ~ 1\n\n#Estimate covariance between TVC\nhost1 ~~ host2 + host3 + host4 + host5\nhost2 ~~ host3 + host4 + host5\nhost3 ~~ host4 + host5\nhost4 ~~ host5'\n\nfit_timevaryingcov &lt;- growth(timevaryingcov, data = data)\nsummary(fit_timevaryingcov, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 113 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        35\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               103.191\n  Degrees of freedom                                30\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              2956.213\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.975\n  Tucker-Lewis Index (TLI)                       0.962\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -659.170\n  Loglikelihood unrestricted model (H1)       -607.575\n                                                      \n  Akaike (AIC)                                1388.340\n  Bayesian (BIC)                              1520.341\n  Sample-size adjusted Bayesian (SABIC)       1409.326\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.087\n  90 Percent confidence interval - lower         0.069\n  90 Percent confidence interval - upper         0.106\n  P-value H_0: RMSEA &lt;= 0.050                    0.001\n  P-value H_0: RMSEA &gt;= 0.080                    0.755\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.059\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lone1 ~                                             \n    host1             0.719    0.017   41.813    0.000\n  lone2 ~                                             \n    host2             0.722    0.014   52.466    0.000\n  lone3 ~                                             \n    host3             0.738    0.012   63.080    0.000\n  lone4 ~                                             \n    host4             0.735    0.015   48.645    0.000\n  lone5 ~                                             \n    host5             0.737    0.022   33.693    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  host1 ~~                                            \n    host2             0.161    0.018    8.703    0.000\n    host3             0.105    0.018    5.860    0.000\n    host4             0.053    0.013    4.153    0.000\n    host5             0.036    0.011    3.452    0.001\n  host2 ~~                                            \n    host3             0.158    0.021    7.358    0.000\n    host4             0.079    0.015    5.286    0.000\n    host5             0.052    0.012    4.247    0.000\n  host3 ~~                                            \n    host4             0.120    0.016    7.325    0.000\n    host5             0.069    0.013    5.280    0.000\n  host4 ~~                                            \n    host5             0.064    0.010    6.527    0.000\n  i ~~                                                \n    s                -0.003    0.001   -4.609    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    host1             1.432    0.028   51.297    0.000\n    host2             1.459    0.032   45.207    0.000\n    host3             1.535    0.034   45.422    0.000\n    host4             1.311    0.025   52.956    0.000\n    host5             1.294    0.021   62.524    0.000\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n    i                 0.414    0.026   15.690    0.000\n    s                -0.010    0.007   -1.399    0.162\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.024    0.003    7.834    0.000\n   .lone2             0.025    0.003    9.540    0.000\n   .lone3             0.038    0.003   11.346    0.000\n   .lone4             0.031    0.003   10.917    0.000\n   .lone5             0.017    0.003    5.695    0.000\n    host1             0.250    0.020   12.669    0.000\n    host2             0.334    0.026   12.669    0.000\n    host3             0.367    0.029   12.669    0.000\n    host4             0.197    0.016   12.669    0.000\n    host5             0.138    0.011   12.669    0.000\n    i                 0.028    0.003    8.206    0.000\n    s                 0.001    0.000    4.757    0.000\n\n\n\n\n\nCode# 006_Linear growth curve model with time invariant covariates \ntimeinvar &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n\n# Time invariant covariates\ni ~ female\ns ~ female'\nfit_timeinvar &lt;- growth(timeinvar, data = data)\nsummary(fit_timeinvar, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 55 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n                                                  Used       Total\n  Number of observations                           320         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                86.716\n  Degrees of freedom                                13\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               475.777\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.840\n  Tucker-Lewis Index (TLI)                       0.815\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -741.159\n  Loglikelihood unrestricted model (H1)       -697.801\n                                                      \n  Akaike (AIC)                                1506.319\n  Bayesian (BIC)                              1551.538\n  Sample-size adjusted Bayesian (SABIC)       1513.476\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.133\n  90 Percent confidence interval - lower         0.107\n  90 Percent confidence interval - upper         0.160\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.090\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~                                                 \n    female           -0.132    0.047   -2.804    0.005\n  s ~                                                 \n    female            0.007    0.009    0.784    0.433\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n .i ~~                                                \n   .s                -0.015    0.002   -6.079    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n   .i                 1.526    0.031   48.551    0.000\n   .s                -0.029    0.006   -4.999    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.062    0.010    6.025    0.000\n   .lone2             0.112    0.011   10.064    0.000\n   .lone3             0.171    0.015   11.628    0.000\n   .lone4             0.107    0.010   10.953    0.000\n   .lone5             0.051    0.010    5.322    0.000\n   .i                 0.134    0.015    9.164    0.000\n   .s                 0.003    0.001    5.522    0.000\n\n\n\n\n\nCode# 007_Linear growth curve model with time invariant and time-varying covariates \ntimeinvartimevar &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n                       s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n# Time-varying covariates held equal\nlone1 ~ eq*host1\nlone2 ~ eq*host2\nlone3 ~ eq*host3\nlone4 ~ eq*host4\nlone5 ~ eq*host5\n\n# Time invariant covariates\ni ~ female + pdu1 + ace1\ns ~ female + pdu1 + ace1\n    \n#Estimate the means of TVC and TIC\nhost1 ~ 1\nhost2 ~ 1\nhost3 ~ 1\nhost4 ~ 1\nhost5 ~ 1\nfemale ~ 1\npdu1 ~ 1\nace1 ~ 1\n\n#Estimate covariances between TIC with TVC\nace1 ~~ female + pdu1 + host1 + host2 + host3 + host4 + host5\nfemale ~~ pdu1 + host1 + host2 + host3 + host4 + host5\npdu1 ~~ host1 + host2 + host3 + host4 + host5\nhost1 ~~ host2 + host3 + host4 + host5\nhost2 ~~ host3 + host4 + host5\nhost3 ~~ host4 + host5\nhost4 ~~ host5\n\n#Fix covariances between TIC and growth factors to zero\ni ~~ 0*host1 \ni ~~ 0*host2 \ni ~~ 0*host3 \ni ~~ 0*host4\ni ~~ 0*host5\n\ns ~~ 0*host1 \ns ~~ 0*host2 \ns ~~ 0*host3 \ns ~~ 0*host4\ns ~~ 0*host5\n'\nfit_timeinvar_timevar &lt;- growth(timeinvartimevar, data = data)\nsummary(fit_timeinvar_timevar, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 117 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        65\n  Number of equality constraints                     4\n\n                                                  Used       Total\n  Number of observations                           320         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               102.364\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3080.206\n  Degrees of freedom                                78\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.980\n  Tucker-Lewis Index (TLI)                       0.964\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1389.597\n  Loglikelihood unrestricted model (H1)      -1338.415\n                                                      \n  Akaike (AIC)                                2901.193\n  Bayesian (BIC)                              3131.061\n  Sample-size adjusted Bayesian (SABIC)       2937.580\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.066\n  90 Percent confidence interval - lower         0.049\n  90 Percent confidence interval - upper         0.082\n  P-value H_0: RMSEA &lt;= 0.050                    0.056\n  P-value H_0: RMSEA &gt;= 0.080                    0.078\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.036\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  lone1 ~                                             \n    host1     (eq)    0.726    0.011   66.961    0.000\n  lone2 ~                                             \n    host2     (eq)    0.726    0.011   66.961    0.000\n  lone3 ~                                             \n    host3     (eq)    0.726    0.011   66.961    0.000\n  lone4 ~                                             \n    host4     (eq)    0.726    0.011   66.961    0.000\n  lone5 ~                                             \n    host5     (eq)    0.726    0.011   66.961    0.000\n  i ~                                                 \n    female           -0.130    0.021   -6.166    0.000\n    pdu1              0.006    0.015    0.409    0.683\n    ace1              0.082    0.021    3.828    0.000\n  s ~                                                 \n    female            0.008    0.005    1.752    0.080\n    pdu1              0.001    0.003    0.320    0.749\n    ace1             -0.003    0.005   -0.713    0.476\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  female ~~                                           \n    ace1             -0.002    0.014   -0.168    0.866\n  pdu1 ~~                                             \n    ace1              0.074    0.021    3.536    0.000\n  host1 ~~                                            \n    ace1              0.035    0.014    2.480    0.013\n  host2 ~~                                            \n    ace1              0.053    0.016    3.249    0.001\n  host3 ~~                                            \n    ace1              0.049    0.017    2.865    0.004\n  host4 ~~                                            \n    ace1              0.029    0.012    2.391    0.017\n  host5 ~~                                            \n    ace1              0.047    0.011    4.394    0.000\n  female ~~                                           \n    pdu1              0.015    0.020    0.719    0.472\n  host1 ~~                                            \n    female            0.004    0.014    0.256    0.798\n  host2 ~~                                            \n    female           -0.025    0.016   -1.578    0.114\n  host3 ~~                                            \n    female            0.007    0.017    0.426    0.670\n  host4 ~~                                            \n    female            0.008    0.012    0.682    0.495\n  host5 ~~                                            \n    female           -0.007    0.010   -0.719    0.472\n  host1 ~~                                            \n    pdu1              0.108    0.021    5.033    0.000\n  host2 ~~                                            \n    pdu1              0.107    0.024    4.378    0.000\n  host3 ~~                                            \n    pdu1              0.093    0.025    3.661    0.000\n  host4 ~~                                            \n    pdu1              0.050    0.018    2.767    0.006\n  host5 ~~                                            \n    pdu1              0.027    0.015    1.817    0.069\n  host1 ~~                                            \n    host2             0.161    0.019    8.683    0.000\n    host3             0.105    0.018    5.837    0.000\n    host4             0.054    0.013    4.345    0.000\n    host5             0.037    0.010    3.567    0.000\n  host2 ~~                                            \n    host3             0.157    0.021    7.330    0.000\n    host4             0.082    0.015    5.544    0.000\n    host5             0.054    0.012    4.409    0.000\n  host3 ~~                                            \n    host4             0.124    0.016    7.607    0.000\n    host5             0.071    0.013    5.459    0.000\n  host4 ~~                                            \n    host5             0.059    0.009    6.220    0.000\n .i ~~                                                \n    host1             0.000                           \n    host2             0.000                           \n    host3             0.000                           \n    host4             0.000                           \n    host5             0.000                           \n .s ~~                                                \n    host1             0.000                           \n    host2             0.000                           \n    host3             0.000                           \n    host4             0.000                           \n    host5             0.000                           \n .i ~~                                                \n   .s                -0.002    0.001   -4.287    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    host1             1.433    0.028   51.188    0.000\n    host2             1.460    0.032   45.155    0.000\n    host3             1.537    0.034   45.385    0.000\n    host4             1.306    0.024   53.812    0.000\n    host5             1.291    0.021   62.945    0.000\n    female            0.444    0.028   15.978    0.000\n    pdu1              2.079    0.041   50.747    0.000\n    ace1              1.949    0.028   69.642    0.000\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n   .i                 0.292    0.049    5.926    0.000\n   .s                -0.005    0.010   -0.489    0.625\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.024    0.003    8.113    0.000\n   .lone2             0.025    0.003    9.668    0.000\n   .lone3             0.038    0.003   11.402    0.000\n   .lone4             0.031    0.003   10.955    0.000\n   .lone5             0.017    0.003    5.726    0.000\n    host1             0.251    0.020   12.649    0.000\n    host2             0.335    0.026   12.649    0.000\n    host3             0.367    0.029   12.649    0.000\n    host4             0.188    0.015   12.649    0.000\n    host5             0.135    0.011   12.649    0.000\n    female            0.247    0.020   12.649    0.000\n    pdu1              0.537    0.042   12.649    0.000\n    ace1              0.251    0.020   12.649    0.000\n   .i                 0.022    0.003    7.396    0.000\n   .s                 0.001    0.000    4.673    0.000\n\n\n\n\n\nCode# 008_Linear growth curve model with growth factors predicting distal outcomes \ndistal &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n                       s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n\n# Regress distal outcome on growth factors\nsubs5 ~ i + s\n\n#Estimate the intercept of distal outcome (subs5)\nsubs5 ~ 1'\nfit_distal &lt;- growth(distal, data = data)\nsummary(fit_distal, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 62 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           290         442\n\nModel Test User Model:\n                                                      \n  Test statistic                                74.672\n  Degrees of freedom                                13\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               438.031\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.854\n  Tucker-Lewis Index (TLI)                       0.832\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1240.424\n  Loglikelihood unrestricted model (H1)      -1203.087\n                                                      \n  Akaike (AIC)                                2508.847\n  Bayesian (BIC)                              2560.226\n  Sample-size adjusted Bayesian (SABIC)       2515.829\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.128\n  90 Percent confidence interval - lower         0.101\n  90 Percent confidence interval - upper         0.157\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.998\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.086\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  subs5 ~                                             \n    i                 0.896    0.398    2.251    0.024\n    s                 5.889    3.222    1.828    0.068\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s                -0.015    0.003   -5.793    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .subs5            -0.006    0.539   -0.011    0.991\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n    i                 1.466    0.025   58.598    0.000\n    s                -0.023    0.004   -5.114    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .lone1             0.055    0.011    5.231    0.000\n   .lone2             0.118    0.012    9.727    0.000\n   .lone3             0.171    0.015   11.052    0.000\n   .lone4             0.122    0.012   10.569    0.000\n   .lone5             0.052    0.011    4.929    0.000\n   .subs5             2.365    0.200   11.825    0.000\n    i                 0.142    0.016    8.925    0.000\n    s                 0.003    0.001    5.308    0.000"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#multiple-group-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#multiple-group-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Multiple group growth models",
    "text": "Multiple group growth models\nA Multiple-group growth model approach offers greater flexibility in explaining between-person differences in the within-person rate of change than the Growth model with time invariant covariate. For example, the Wald test of differences in growth parameters can be tested within the multiple-group approach to explain whether, on average, the experimental group experience greater overall decline than the control group - thus providing insights into how and why individuals differ in their rate of change and by how much difference. The multiple-group approach can inform about differences in all the growth functions’ parameters - including the growth factors means, co/variances and residual variances.\n\n\nModel 9_1\nModel 9_2\nModel 9_3\nModel 9_4\n\n\n\n\nCode# 009_1_Multigroup LGCM M1 Invariance model - M1\nmultigroupM1 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n#Growth factor means constrained equal\ni ~ c(int, int)*1\ns ~ c(slp, slp)*1\n\n#Growth factor variances held equal\ni ~~ c(vint, vint)*i\ns ~~ c(vslp, vslp)*s\n\n#Growth factor covariances held equal\ni ~~ c(cvf, cvf)*s\n\n#Residual variances of observed items held equal\nlone1 ~~ c(res, res)*lone1\nlone2 ~~ c(res, res)*lone2\nlone3 ~~ c(res, res)*lone3\nlone4 ~~ c(res, res)*lone4\nlone5 ~~ c(res, res)*lone5\n'\nfit_multigroupM1 &lt;- growth(multigroupM1, data = data, group = \"female\")\n\nWarning in lav_data_full(data = data, group = group, cluster = cluster, : lavaan WARNING: group variable 'female' contains missing values\n\nCodesummary(fit_multigroupM1, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n  Number of equality constraints                    14\n\n  Number of observations per group:               Used       Total\n    0                                              178         222\n    1                                              142         193\n\nModel Test User Model:\n                                                      \n  Test statistic                               207.477\n  Degrees of freedom                                34\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    0                                           98.099\n    1                                          109.378\n\nModel Test Baseline Model:\n\n  Test statistic                               463.335\n  Degrees of freedom                                20\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.609\n  Tucker-Lewis Index (TLI)                       0.770\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -776.723\n  Loglikelihood unrestricted model (H1)       -672.984\n                                                      \n  Akaike (AIC)                                1565.445\n  Bayesian (BIC)                              1588.055\n  Sample-size adjusted Bayesian (SABIC)       1569.024\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.179\n  90 Percent confidence interval - lower         0.156\n  90 Percent confidence interval - upper         0.202\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.230\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [0]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s        (cvf)   -0.011    0.002   -4.425    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i        (int)    1.484    0.025   60.198    0.000\n    s        (slp)   -0.026    0.004   -5.932    0.000\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vint)    0.135    0.016    8.666    0.000\n    s       (vslp)    0.001    0.001    2.467    0.014\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\nGroup 2 [1]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s        (cvf)   -0.011    0.002   -4.425    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i        (int)    1.484    0.025   60.198    0.000\n    s        (slp)   -0.026    0.004   -5.932    0.000\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vint)    0.135    0.016    8.666    0.000\n    s       (vslp)    0.001    0.001    2.467    0.014\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\n\n\n\nCode# 009_2_Multigroup LGCM M2 Free factor means - M2\nmultigroupM2 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n#Growth factor means freely estimated\ni ~ c(intm, intf)*1\ns ~ c(slpm, slpf)*1\n\n#Growth factor variances held equal\ni ~~ c(vint, vint)*i\ns ~~ c(vslp, vslp)*s\n\n#Growth factor covariances held equal\ni ~~ c(cvf, cvf)*s\n\n#Residual variances of observed items held equal\nlone1 ~~ c(res, res)*lone1\nlone2 ~~ c(res, res)*lone2\nlone3 ~~ c(res, res)*lone3\nlone4 ~~ c(res, res)*lone4\nlone5 ~~ c(res, res)*lone5\n'\nfit_multigroupM2 &lt;- growth(multigroupM2, data = data, group = \"female\")\n\nWarning in lav_data_full(data = data, group = group, cluster = cluster, : lavaan WARNING: group variable 'female' contains missing values\n\nCodesummary(fit_multigroupM2, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 34 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n  Number of equality constraints                    12\n\n  Number of observations per group:               Used       Total\n    0                                              178         222\n    1                                              142         193\n\nModel Test User Model:\n                                                      \n  Test statistic                               196.543\n  Degrees of freedom                                32\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    0                                           94.352\n    1                                          102.191\n\nModel Test Baseline Model:\n\n  Test statistic                               463.335\n  Degrees of freedom                                20\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.629\n  Tucker-Lewis Index (TLI)                       0.768\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -771.255\n  Loglikelihood unrestricted model (H1)       -672.984\n                                                      \n  Akaike (AIC)                                1558.511\n  Bayesian (BIC)                              1588.657\n  Sample-size adjusted Bayesian (SABIC)       1563.283\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.179\n  90 Percent confidence interval - lower         0.156\n  90 Percent confidence interval - upper         0.204\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.213\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [0]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s        (cvf)   -0.010    0.002   -4.331    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intm)    1.550    0.033   47.589    0.000\n    s       (slpm)   -0.031    0.006   -5.236    0.000\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vint)    0.130    0.015    8.547    0.000\n    s       (vslp)    0.001    0.001    2.425    0.015\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\nGroup 2 [1]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s        (cvf)   -0.010    0.002   -4.331    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intf)    1.401    0.036   38.400    0.000\n    s       (slpf)   -0.020    0.007   -3.062    0.002\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vint)    0.130    0.015    8.547    0.000\n    s       (vslp)    0.001    0.001    2.425    0.015\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\n\n\n\nCode# 009_3_Multigroup LGCM M3 Free factor means and co/variances - M3\nmultigroupM3 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n#Growth factor means freely estimated\ni ~ c(intm, intf)*1\ns ~ c(slpm, slpf)*1\n\n#Growth factor variances freely estimated\ni ~~ c(vinm, vinf)*i\ns ~~ c(vslm, vslf)*s\n\n#Growth factor covariances freely estimated\ni ~~ c(covm, covf)*s\n\n#Residual variances of observed items held equal\nlone1 ~~ c(res, res)*lone1\nlone2 ~~ c(res, res)*lone2\nlone3 ~~ c(res, res)*lone3\nlone4 ~~ c(res, res)*lone4\nlone5 ~~ c(res, res)*lone5\n'\nfit_multigroupM3 &lt;- growth(multigroupM3, data = data, group = \"female\")\n\nWarning in lav_data_full(data = data, group = group, cluster = cluster, : lavaan WARNING: group variable 'female' contains missing values\n\nCodesummary(fit_multigroupM3, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 82 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n  Number of equality constraints                     9\n\n  Number of observations per group:               Used       Total\n    0                                              178         222\n    1                                              142         193\n\nModel Test User Model:\n                                                      \n  Test statistic                               186.447\n  Degrees of freedom                                29\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    0                                           90.667\n    1                                           95.780\n\nModel Test Baseline Model:\n\n  Test statistic                               463.335\n  Degrees of freedom                                20\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.645\n  Tucker-Lewis Index (TLI)                       0.755\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -766.208\n  Loglikelihood unrestricted model (H1)       -672.984\n                                                      \n  Akaike (AIC)                                1554.415\n  Bayesian (BIC)                              1595.867\n  Sample-size adjusted Bayesian (SABIC)       1560.977\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.184\n  90 Percent confidence interval - lower         0.159\n  90 Percent confidence interval - upper         0.210\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.177\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [0]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s       (covm)   -0.015    0.004   -4.140    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intm)    1.550    0.036   43.187    0.000\n    s       (slpm)   -0.031    0.006   -4.949    0.000\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vinm)    0.170    0.024    6.957    0.000\n    s       (vslm)    0.002    0.001    2.662    0.008\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\nGroup 2 [1]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s       (covf)   -0.004    0.003   -1.484    0.138\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intf)    1.401    0.031   44.901    0.000\n    s       (slpf)   -0.020    0.006   -3.321    0.001\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vinf)    0.079    0.017    4.753    0.000\n    s       (vslf)    0.000    0.001    0.569    0.569\n   .lone1    (res)    0.109    0.005   21.909    0.000\n   .lone2    (res)    0.109    0.005   21.909    0.000\n   .lone3    (res)    0.109    0.005   21.909    0.000\n   .lone4    (res)    0.109    0.005   21.909    0.000\n   .lone5    (res)    0.109    0.005   21.909    0.000\n\n\n\n\n\nCode# 009_4_Multigroup LGCM M4 Free factor means and co/variances - M4\nmultigroupM4 &lt;- ' i =~ 1*lone1 + 1*lone2 + 1*lone3 + 1*lone4 + 1*lone5\n           s =~ 0*lone1 + 1*lone2 + 3*lone3 + 4*lone4 + 6*lone5\n#Growth factor means freely estimated\ni ~ c(intm, intf)*1\ns ~ c(slpm, slpf)*1\n\n#Growth factor variances freely estimated\ni ~~ c(vinm, vinf)*i\ns ~~ c(vslm, vslf)*s\n\n#Growth factor covariances freely estimated\ni ~~ c(covm, covf)*s\n\n#Residual variances of observed items freely estimated\nlone1 ~~ c(rsm1, rsf1)*lone1\nlone2 ~~ c(rsm2, rsf2)*lone2\nlone3 ~~ c(rsm3, rsf3)*lone3\nlone4 ~~ c(rsm4, rsf4)*lone4\nlone5 ~~ c(rsm5, rsf5)*lone5\n'\nfit_multigroupM4 &lt;- growth(multigroupM4, data = data, group = \"female\")\n\nWarning in lav_data_full(data = data, group = group, cluster = cluster, : lavaan WARNING: group variable 'female' contains missing values\n\nCodesummary(fit_multigroupM4, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 66 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n  Number of observations per group:               Used       Total\n    0                                              178         222\n    1                                              142         193\n\nModel Test User Model:\n                                                      \n  Test statistic                               102.181\n  Degrees of freedom                                20\n  P-value (Chi-square)                           0.000\n  Test statistic for each group:\n    0                                           66.901\n    1                                           35.280\n\nModel Test Baseline Model:\n\n  Test statistic                               463.335\n  Degrees of freedom                                20\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.815\n  Tucker-Lewis Index (TLI)                       0.815\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -724.074\n  Loglikelihood unrestricted model (H1)       -672.984\n                                                      \n  Akaike (AIC)                                1488.149\n  Bayesian (BIC)                              1563.515\n  Sample-size adjusted Bayesian (SABIC)       1500.079\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.160\n  90 Percent confidence interval - lower         0.130\n  90 Percent confidence interval - upper         0.192\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.105\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [0]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s       (covm)   -0.016    0.004   -4.393    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intm)    1.528    0.034   44.501    0.000\n    s       (slpm)   -0.028    0.006   -4.727    0.000\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vinm)    0.160    0.023    6.803    0.000\n    s       (vslm)    0.003    0.001    3.483    0.000\n   .lone1   (rsm1)    0.074    0.016    4.563    0.000\n   .lone2   (rsm2)    0.143    0.019    7.686    0.000\n   .lone3   (rsm3)    0.165    0.019    8.496    0.000\n   .lone4   (rsm4)    0.124    0.015    8.199    0.000\n   .lone5   (rsm5)    0.067    0.015    4.608    0.000\n\n\nGroup 2 [1]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    lone1             1.000                           \n    lone2             1.000                           \n    lone3             1.000                           \n    lone4             1.000                           \n    lone5             1.000                           \n  s =~                                                \n    lone1             0.000                           \n    lone2             1.000                           \n    lone3             3.000                           \n    lone4             4.000                           \n    lone5             6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s       (covf)   -0.012    0.003   -4.260    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (intf)    1.389    0.030   45.598    0.000\n    s       (slpf)   -0.022    0.006   -3.679    0.000\n   .lone1             0.000                           \n   .lone2             0.000                           \n   .lone3             0.000                           \n   .lone4             0.000                           \n   .lone5             0.000                           \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i       (vinf)    0.101    0.016    6.178    0.000\n    s       (vslf)    0.003    0.001    4.637    0.000\n   .lone1   (rsf1)    0.049    0.012    4.133    0.000\n   .lone2   (rsf2)    0.071    0.011    6.315    0.000\n   .lone3   (rsf3)    0.176    0.022    7.952    0.000\n   .lone4   (rsf4)    0.088    0.012    7.338    0.000\n   .lone5   (rsf5)    0.027    0.011    2.346    0.019"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#test-of-parameter-constraints",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#test-of-parameter-constraints",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Test of parameter constraints",
    "text": "Test of parameter constraints\nFirst we test whether the intercept growth factors in both groups are significantly different using Model 9_4 since we freely estimated all model parameters in Model 9_4\n\nCodeconstint = 'intm - intf == 0'\nlavTestWald(fit_multigroupM4, constraints = constint)\n\n$stat\n[1] 9.144994\n\n$df\n[1] 1\n\n$p.value\n[1] 0.002493995\n\n$se\n[1] \"standard\"\n\n\nThen we also test whether the slope growth factors in both groups are significantly different using Model 9_4 since we freely estimated all model parameters in Model 9_4\n\nCode#Then we test whether \nconstslp = 'slpm - slpf ==0'\nlavTestWald(fit_multigroupM4, constraints = constslp)\n\n$stat\n[1] 0.5710977\n\n$df\n[1] 1\n\n$p.value\n[1] 0.449823\n\n$se\n[1] \"standard\""
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#modelling-co-development-and-multivariate-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#modelling-co-development-and-multivariate-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Modelling co-development and Multivariate growth models",
    "text": "Modelling co-development and Multivariate growth models\nModelling the co-development among different attributes such as the comorbidity of anxiety and depression is becoming more common. Multivariate growth models also called Parallel growth models can accommodate different growth functions among two or more attributes. Care must be taken and theoretical considerations must be prioritized when choosing between Multivariate growth curve models and the Growth curve models with time-varying covariates. The two are related but answer different research questions.\n\n\nModel 10_1\nModel 10_2\nModel 10_3\n\n\n\n\nCode# 010_1_Parallel growth curve models - anxiety and depression symptoms\nparallel &lt;- ' ia =~ 1*anx1 + 1*anx2 + 1*anx3 + 1*anx4 + 1*anx5\n                sa =~ 0*anx1 + 1*anx2 + 3*anx3 + 4*anx4 + 6*anx5\n                id =~ 1*dep1 + 1*dep2 + 1*dep3 + 1*dep4 + 1*dep5\n                sd =~ 0*dep1 + 1*dep2 + 3*dep3 + 4*dep4 + 6*dep5\n#Growth factor corelations \nia ~~ id + sa\nsd ~~ id + sa\nia ~~ 0*sd \nid ~~ 0*sa\n'\nfit_parallel &lt;- growth(parallel, data = data)\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_parallel, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 88 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        22\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               820.887\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1912.994\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.584\n  Tucker-Lewis Index (TLI)                       0.564\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1711.078\n  Loglikelihood unrestricted model (H1)      -1300.634\n                                                      \n  Akaike (AIC)                                3466.156\n  Bayesian (BIC)                              3549.128\n  Sample-size adjusted Bayesian (SABIC)       3479.347\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.237\n  90 Percent confidence interval - lower         0.223\n  90 Percent confidence interval - upper         0.252\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.357\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia =~                                               \n    anx1              1.000                           \n    anx2              1.000                           \n    anx3              1.000                           \n    anx4              1.000                           \n    anx5              1.000                           \n  sa =~                                               \n    anx1              0.000                           \n    anx2              1.000                           \n    anx3              3.000                           \n    anx4              4.000                           \n    anx5              6.000                           \n  id =~                                               \n    dep1              1.000                           \n    dep2              1.000                           \n    dep3              1.000                           \n    dep4              1.000                           \n    dep5              1.000                           \n  sd =~                                               \n    dep1              0.000                           \n    dep2              1.000                           \n    dep3              3.000                           \n    dep4              4.000                           \n    dep5              6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia ~~                                               \n    id                0.125    0.012   10.436    0.000\n    sa                0.000    0.002    0.109    0.913\n  id ~~                                               \n    sd                0.005    0.002    2.216    0.027\n  sa ~~                                               \n    sd                0.004    0.000    9.146    0.000\n  ia ~~                                               \n    sd                0.000                           \n  sa ~~                                               \n    id                0.000                           \n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.000                           \n   .anx2              0.000                           \n   .anx3              0.000                           \n   .anx4              0.000                           \n   .anx5              0.000                           \n   .dep1              0.000                           \n   .dep2              0.000                           \n   .dep3              0.000                           \n   .dep4              0.000                           \n   .dep5              0.000                           \n    ia                1.397    0.022   64.889    0.000\n    sa               -0.032    0.004   -7.842    0.000\n    id                1.545    0.027   56.861    0.000\n    sd               -0.014    0.005   -2.825    0.005\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.083    0.010    8.647    0.000\n   .anx2              0.122    0.011   11.095    0.000\n   .anx3              0.148    0.012   11.878    0.000\n   .anx4              0.103    0.009   11.541    0.000\n   .anx5              0.062    0.008    7.615    0.000\n   .dep1              0.103    0.012    8.309    0.000\n   .dep2              0.149    0.014   10.787    0.000\n   .dep3              0.241    0.020   11.889    0.000\n   .dep4              0.181    0.016   11.601    0.000\n   .dep5              0.156    0.017    9.292    0.000\n    ia                0.097    0.012    8.393    0.000\n    sa                0.002    0.000    3.997    0.000\n    id                0.171    0.019    8.956    0.000\n    sd                0.002    0.001    2.954    0.003\n\n\n\n\n\nCode# 010_2_Parallel growth curve models - anxiety and depression symptoms with autocorrelations\nparallelautocor &lt;- ' ia =~ 1*anx1 + 1*anx2 + 1*anx3 + 1*anx4 + 1*anx5\n                sa =~ 0*anx1 + 1*anx2 + 3*anx3 + 4*anx4 + 6*anx5\n                id =~ 1*dep1 + 1*dep2 + 1*dep3 + 1*dep4 + 1*dep5\n                sd =~ 0*dep1 + 1*dep2 + 3*dep3 + 4*dep4 + 6*dep5\n#Growth factor corelations \nia ~~ id + sa\nsd ~~ id + sa\nia ~~ 0*sd \nid ~~ 0*sa\n\n#Autocorrelations \nanx1 ~~ anx2\nanx2 ~~ anx3\nanx3 ~~ anx4\nanx4 ~~ anx5\n\ndep1 ~~ dep2\ndep2 ~~ dep3\ndep3 ~~ dep4\ndep4 ~~ dep5\n'\nfit_parallelautocor &lt;- growth(parallelautocor, data = data)\n\nWarning in lav_object_post_check(object): lavaan WARNING: covariance matrix of latent variables\n                is not positive definite;\n                use lavInspect(fit, \"cov.lv\") to investigate.\n\nCodesummary(fit_parallelautocor, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 97 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        30\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               797.045\n  Degrees of freedom                                35\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1912.994\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.592\n  Tucker-Lewis Index (TLI)                       0.475\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1699.157\n  Loglikelihood unrestricted model (H1)      -1300.634\n                                                      \n  Akaike (AIC)                                3458.314\n  Bayesian (BIC)                              3571.457\n  Sample-size adjusted Bayesian (SABIC)       3476.302\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.260\n  90 Percent confidence interval - lower         0.245\n  90 Percent confidence interval - upper         0.276\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.337\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia =~                                               \n    anx1              1.000                           \n    anx2              1.000                           \n    anx3              1.000                           \n    anx4              1.000                           \n    anx5              1.000                           \n  sa =~                                               \n    anx1              0.000                           \n    anx2              1.000                           \n    anx3              3.000                           \n    anx4              4.000                           \n    anx5              6.000                           \n  id =~                                               \n    dep1              1.000                           \n    dep2              1.000                           \n    dep3              1.000                           \n    dep4              1.000                           \n    dep5              1.000                           \n  sd =~                                               \n    dep1              0.000                           \n    dep2              1.000                           \n    dep3              3.000                           \n    dep4              4.000                           \n    dep5              6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia ~~                                               \n    id                0.120    0.012   10.344    0.000\n    sa                0.004    0.002    1.529    0.126\n  id ~~                                               \n    sd                0.007    0.004    1.748    0.080\n  sa ~~                                               \n    sd                0.004    0.000    9.109    0.000\n  ia ~~                                               \n    sd                0.000                           \n  sa ~~                                               \n    id                0.000                           \n .anx1 ~~                                             \n   .anx2              0.021    0.011    1.880    0.060\n .anx2 ~~                                             \n   .anx3              0.032    0.009    3.402    0.001\n .anx3 ~~                                             \n   .anx4             -0.000    0.008   -0.058    0.954\n .anx4 ~~                                             \n   .anx5             -0.012    0.009   -1.262    0.207\n .dep1 ~~                                             \n   .dep2              0.022    0.018    1.239    0.215\n .dep2 ~~                                             \n   .dep3              0.027    0.013    2.045    0.041\n .dep3 ~~                                             \n   .dep4              0.017    0.015    1.183    0.237\n .dep4 ~~                                             \n   .dep5             -0.039    0.016   -2.440    0.015\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.000                           \n   .anx2              0.000                           \n   .anx3              0.000                           \n   .anx4              0.000                           \n   .anx5              0.000                           \n   .dep1              0.000                           \n   .dep2              0.000                           \n   .dep3              0.000                           \n   .dep4              0.000                           \n   .dep5              0.000                           \n    ia                1.394    0.021   65.511    0.000\n    sa               -0.032    0.004   -8.005    0.000\n    id                1.543    0.027   57.239    0.000\n    sd               -0.017    0.005   -3.386    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.102    0.015    6.870    0.000\n   .anx2              0.145    0.014   10.330    0.000\n   .anx3              0.162    0.014   11.832    0.000\n   .anx4              0.091    0.010    9.176    0.000\n   .anx5              0.049    0.013    3.626    0.000\n   .dep1              0.116    0.023    5.122    0.000\n   .dep2              0.173    0.020    8.867    0.000\n   .dep3              0.252    0.022   11.625    0.000\n   .dep4              0.161    0.018    9.108    0.000\n   .dep5              0.119    0.025    4.742    0.000\n    ia                0.073    0.015    4.804    0.000\n    sa                0.002    0.001    2.197    0.028\n    id                0.147    0.026    5.720    0.000\n    sd                0.003    0.001    2.232    0.026\n\n\n\n\n\nCode# 010_3_Parallel growth curve models - anxiety and depression symptoms with cross-domain correlations \nparallelcross &lt;- ' ia =~ 1*anx1 + 1*anx2 + 1*anx3 + 1*anx4 + 1*anx5\n                sa =~ 0*anx1 + 1*anx2 + 3*anx3 + 4*anx4 + 6*anx5\n                id =~ 1*dep1 + 1*dep2 + 1*dep3 + 1*dep4 + 1*dep5\n                sd =~ 0*dep1 + 1*dep2 + 3*dep3 + 4*dep4 + 6*dep5\n#Growth factor corelations \nia ~~ id + sa\nsd ~~ id + sa\nia ~~ 0*sd \nid ~~ 0*sa\n\n#Cross domain correlations\nanx1 ~~ dep1\nanx2 ~~ dep2\nanx3 ~~ dep3\nanx4 ~~ dep4\nanx5 ~~ dep5\n'\nfit_parallelcross &lt;- growth(parallelcross, data = data)\nsummary(fit_parallelcross, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 103 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        27\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               161.219\n  Degrees of freedom                                38\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1912.994\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.934\n  Tucker-Lewis Index (TLI)                       0.922\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1381.244\n  Loglikelihood unrestricted model (H1)      -1300.634\n                                                      \n  Akaike (AIC)                                2816.487\n  Bayesian (BIC)                              2918.316\n  Sample-size adjusted Bayesian (SABIC)       2832.676\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.101\n  90 Percent confidence interval - lower         0.085\n  90 Percent confidence interval - upper         0.117\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.983\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.122\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia =~                                               \n    anx1              1.000                           \n    anx2              1.000                           \n    anx3              1.000                           \n    anx4              1.000                           \n    anx5              1.000                           \n  sa =~                                               \n    anx1              0.000                           \n    anx2              1.000                           \n    anx3              3.000                           \n    anx4              4.000                           \n    anx5              6.000                           \n  id =~                                               \n    dep1              1.000                           \n    dep2              1.000                           \n    dep3              1.000                           \n    dep4              1.000                           \n    dep5              1.000                           \n  sd =~                                               \n    dep1              0.000                           \n    dep2              1.000                           \n    dep3              3.000                           \n    dep4              4.000                           \n    dep5              6.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia ~~                                               \n    id                0.075    0.009    8.272    0.000\n    sa               -0.004    0.001   -2.790    0.005\n  id ~~                                               \n    sd               -0.002    0.002   -1.204    0.229\n  sa ~~                                               \n    sd                0.000    0.000    1.208    0.227\n  ia ~~                                               \n    sd                0.000                           \n  sa ~~                                               \n    id                0.000                           \n .anx1 ~~                                             \n   .dep1              0.082    0.011    7.655    0.000\n .anx2 ~~                                             \n   .dep2              0.105    0.012    8.565    0.000\n .anx3 ~~                                             \n   .dep3              0.130    0.015    8.939    0.000\n .anx4 ~~                                             \n   .dep4              0.103    0.011    8.982    0.000\n .anx5 ~~                                             \n   .dep5              0.056    0.011    4.900    0.000\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.000                           \n   .anx2              0.000                           \n   .anx3              0.000                           \n   .anx4              0.000                           \n   .anx5              0.000                           \n   .dep1              0.000                           \n   .dep2              0.000                           \n   .dep3              0.000                           \n   .dep4              0.000                           \n   .dep5              0.000                           \n    ia                1.394    0.021   66.266    0.000\n    sa               -0.031    0.004   -7.868    0.000\n    id                1.548    0.026   59.272    0.000\n    sd               -0.013    0.005   -2.773    0.006\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.109    0.012    9.157    0.000\n   .anx2              0.137    0.013   10.704    0.000\n   .anx3              0.154    0.013   11.374    0.000\n   .anx4              0.106    0.010   10.746    0.000\n   .anx5              0.056    0.010    5.820    0.000\n   .dep1              0.134    0.015    8.954    0.000\n   .dep2              0.171    0.016   10.473    0.000\n   .dep3              0.241    0.021   11.262    0.000\n   .dep4              0.187    0.017   10.745    0.000\n   .dep5              0.158    0.020    7.910    0.000\n    ia                0.080    0.010    8.242    0.000\n    sa                0.001    0.000    3.065    0.002\n    id                0.138    0.016    8.787    0.000\n    sd                0.001    0.001    1.222    0.222"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#sequentially-contingent-growth-models",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#sequentially-contingent-growth-models",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Sequentially contingent growth models",
    "text": "Sequentially contingent growth models\nGrowth in one attribute can predict the growth that occur in another attribute later in the developmental process. The rate of change in language development during pre-school may predict the rate of change in language skills during primary school. Sequentially contingent growth models offer flexibility in modelling such relations in the developmental process that occur in different stages, but might be contingent on each other.\n\nModel 11\n\n\n\nCode# 011_ Sequentially contingent growth curve model anxiety t1-t5 predicting depression t6-t10\nsequential &lt;- ' ia =~ 1*anx1 + 1*anx2 + 1*anx3 + 1*anx4 + 1*anx5\n                sa =~ 0*anx1 + 1*anx2 + 3*anx3 + 4*anx4 + 6*anx5\n                id =~ 1*dep6 + 1*dep7 + 1*dep8 + 1*dep9 + 1*dep10\n                sd =~ 0*dep6 + 1*dep7 + 2*dep8 + 3*dep9 + 4*dep10\n#Growth factor corelations \nia ~~ sa\nid ~~ sd\nia ~~ 0*sd \nid ~~ 0*sa\n\n#Growth factor regressions of depression on anxiety symptoms\nid ~ ia\nsd ~ sa\n'\n#Rename multiple columns using rename()\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nCodedata &lt;- data %&gt;% \n  rename(\"dep6\" = \"dep1\",\n         \"dep7\" = \"dep2\",\n         \"dep8\" = \"dep3\",\n         \"dep9\" = \"dep4\",\n         \"dep10\" = \"dep5\")\n\nfit_sequential &lt;- growth(sequential, data = data)\n\nWarning in lav_object_post_check(object): lavaan WARNING: some estimated lv\nvariances are negative\n\nCodesummary(fit_sequential, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 91 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        22\n\n                                                  Used       Total\n  Number of observations                           321         442\n\nModel Test User Model:\n                                                      \n  Test statistic                               688.159\n  Degrees of freedom                                43\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1912.994\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.655\n  Tucker-Lewis Index (TLI)                       0.639\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1644.714\n  Loglikelihood unrestricted model (H1)      -1300.634\n                                                      \n  Akaike (AIC)                                3333.428\n  Bayesian (BIC)                              3416.399\n  Sample-size adjusted Bayesian (SABIC)       3346.619\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.216\n  90 Percent confidence interval - lower         0.202\n  90 Percent confidence interval - upper         0.231\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.123\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia =~                                               \n    anx1              1.000                           \n    anx2              1.000                           \n    anx3              1.000                           \n    anx4              1.000                           \n    anx5              1.000                           \n  sa =~                                               \n    anx1              0.000                           \n    anx2              1.000                           \n    anx3              3.000                           \n    anx4              4.000                           \n    anx5              6.000                           \n  id =~                                               \n    dep6              1.000                           \n    dep7              1.000                           \n    dep8              1.000                           \n    dep9              1.000                           \n    dep10             1.000                           \n  sd =~                                               \n    dep6              0.000                           \n    dep7              1.000                           \n    dep8              2.000                           \n    dep9              3.000                           \n    dep10             4.000                           \n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  id ~                                                \n    ia                1.377    0.067   20.520    0.000\n  sd ~                                                \n    sa                2.253    0.186   12.082    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  ia ~~                                               \n    sa               -0.014    0.002   -7.039    0.000\n .id ~~                                               \n   .sd                0.020    0.004    5.271    0.000\n  ia ~~                                               \n   .sd                0.000                           \n  sa ~~                                               \n   .id                0.000                           \n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.000                           \n   .anx2              0.000                           \n   .anx3              0.000                           \n   .anx4              0.000                           \n   .anx5              0.000                           \n   .dep6              0.000                           \n   .dep7              0.000                           \n   .dep8              0.000                           \n   .dep9              0.000                           \n   .dep10             0.000                           \n    ia                1.396    0.023   60.533    0.000\n    sa               -0.032    0.005   -7.065    0.000\n   .id               -0.371    0.096   -3.869    0.000\n   .sd                0.049    0.010    5.111    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .anx1              0.077    0.008    9.449    0.000\n   .anx2              0.122    0.011   11.411    0.000\n   .anx3              0.151    0.013   11.961    0.000\n   .anx4              0.103    0.009   11.598    0.000\n   .anx5              0.052    0.007    7.836    0.000\n   .dep6              0.115    0.013    8.699    0.000\n   .dep7              0.148    0.013   11.037    0.000\n   .dep8              0.241    0.020   11.845    0.000\n   .dep9              0.185    0.016   11.602    0.000\n   .dep10             0.141    0.015    9.496    0.000\n    ia                0.122    0.013    9.684    0.000\n    sa                0.003    0.000    7.331    0.000\n   .id               -0.029    0.013   -2.301    0.021\n   .sd               -0.011    0.002   -6.125    0.000\n\n\n\n\n\n\n\n\n\n\n\nFeel free to contact me at frederick.anyan@ntnu.no for advise or invitation to present workshops in your own institution."
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "Latent Growth Curve Models (LGCM) & Growth Mixture Models (GMM) - Two-day Workshop\n\n\n\n\n\n\n\nLatent Growth Curve Models\n\n\nGrowth Mixture Models\n\n\nLatent Class Growth Models\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2021\n\n\nFrederick Anyan\n\n\n\n\n\n\n  \n\n\n\n\nLatent Growth Curve Models (LGCM): Applications with R\n\n\n\n\n\n\n\nLatent Growth Curve Models\n\n\nDynamic Models\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2023\n\n\nFrederick Anyan\n\n\n\n\n\n\n  \n\n\n\n\nLatent Growth Curve Models (LGCM): Applications with Mplus\n\n\n\n\n\n\n\nLatent Growth Curve Models\n\n\nDynamic Models\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nFrederick Anyan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Quantitative Methodology II (PSY2117 & PSYK4317)\n\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPrevious teaching activities\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2015\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/before_tenured.html",
    "href": "teaching/before_tenured.html",
    "title": "Previous teaching activities",
    "section": "",
    "text": "I was involved in co/teaching various undergraduate courses prior to becoming an Associate Professor\nNorwegian University of Science and Technology\n\n\nPSY3810: Innovative health promotion strategies in everyday settings\n\n\nPSY2900: Research in developmental psychology\n\n\nPSYPRO4315: Developmental psychology II\n\n\nPSY3100: Quantitative research methods\n\n\nPSY1014: Social psychology\n\n\nPSYPRO4114: Social psychology (professional psychology students)\n\n\nAustralian National University\n\n\nPSYC2001: Social psychology\n\n\nAshesi University\n\n\nSOAN229: Social research methods\n\n\nBUSA132: Organizational Behaviour\n\n\nSt. Karol School Of Nursing\n\n\nNURS364: Nursing research methods"
  },
  {
    "objectID": "teaching/teaching_tenured.html",
    "href": "teaching/teaching_tenured.html",
    "title": "Quantitative Methodology II (PSY2117 & PSYK4317)",
    "section": "",
    "text": "Quantitative Methodology II"
  },
  {
    "objectID": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#model-comparisons",
    "href": "workshops/NTNU_2023_01_Dec_R/LGCM_R.html#model-comparisons",
    "title": "Latent Growth Curve Models (LGCM): Applications with R",
    "section": "Model Comparisons",
    "text": "Model Comparisons\nModels 1, 2 and 3 can be compared since 1 and 2 are nested in (i.e., reduced forms of) Model 3. In this way, the best model to data correspondence can be determined through a chi-square difference test. However, a word of caution here is that, you should only compare models whose fit indices are acceptable. Therefore, in a real scenario, we would not compare Models 1 and 2 since they both do not reach acceptable model fit.\nWe would instead, nominate Model 3 as the best model representation of the data. The non-linear growth function in Model 3 reproduces the trajectory observed when examining observed means in the univariate descriptives.\n\nCodecompare_no_linear &lt;- anova(fit_nogrowth, fit_linear)\ncompare_no_linear\n\n\nChi-Squared Difference Test\n\n             Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(&gt;Chisq)    \nfit_linear   10 1538.1 1575.8  75.244                                          \nfit_nogrowth 13 1643.3 1669.7 186.433     111.19 0.33518       3  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe results (x2() = 111.19, p &lt; .001) show significant difference in model fit between Model 1 (no growth mode) and Model 2 (linear growth). Thus, Model 2, in which the linear growth factor is freely estimated (relative to Model 1) has improved data to model correspondence (or fits better) than Model 1. Remember that this is just an example of how to compare nested models, and that you should only compare models whose fit indices are acceptable."
  }
]