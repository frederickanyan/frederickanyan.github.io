---
title: 'Null Hypothesis Testing'
author: "Frederick Anyan"
date: 2023-05-01
categories: [Null hypothesis, Sample statistics, Population parameters]
image: "null.jpeg"
---

Researchers start their research by creating a null hypothesis, which is the assumption that there is no relationship between the variables being tested. They then collect data and use statistical tests to determine if the data is consistent with the null hypothesis, or if there is enough evidence to reject the null hypothesis. 

A researcher may select a sample of 750 students from the population of _all NTNU students_ to investigate the relationship between attending lectures and exam anxiety. Ideally, the researcher wants to make conclusions about the population of all NTNU students using _sample statistics_ which is computed based on the sample of 750 students. A sample statistic is a numerical summary from the sample data. Here, the mean of exam anxiety for the 750 students or the correlation between attending lectures and exam anxiety for the 750 students is a sample statistic. Its corresponding numeric value for all NTNU students is called a _parameter (or population parameter)_. Although the researcher works with a sample of 750 students, the ultimate interest is in the population of all NTNU students. But the parameter value is unknown unless the researcher can gather all NTNU students. 

Indeed, a hypothesis is stated in reference to the population (e.g., there is no difference in height between the population of males and females), but sample data is used to test the hypothesis, which is how inferences about the population are drawn from the sample data. 

It is almost impossible or could be very expensive and time consuming to test the entire population.

_So, what does the researcher do?_

The researcher uses sample statistics as estimates for the corresponding population parameters. But this has some problems due to sampling error or random variability. This is because whenever the researcher samples different groups of 750 students, the researcher may observe a mean of 4.50 for exam anxiety in Group 1 and 5.20 in Group 2 and yet still 3.75 in Group 3. This random variability in a sample statistic such as the mean of exam anxiety from sample to sample is called sampling error. 

_So, what does this mean for the researcherÂ´s conclusions?_

If the researcher makes conclusions based on the sample of 750 students, it will not be guaranteed that the conclusion will be observed in the population of all NTNU students due to sampling error. It could be that the mean of exam anxiety is not even close to any of the sample means and it could also be that the relationship between attending lectures and exam anxiety observed in the sample of 750 students, will not exist and that there will be no relationship between attending lectures and exam anxiety at all in the population. This would mean that the observed relationship between attending lectures and exam anxiety in the sample of 750 students is just due to sampling error or occurred by chance. This problem can be reduced or mitigated by power analysis and sample size calculations prior as part of the research design and prior to data calculation. 

Null hypothesis significance testing is a statistical technique used to determine if the results of a study occurred by chance, or if they are a true effect in the population. The general idea underpinning null hypothesis significance testing is based on the observed relationship in the sample data, which is that:

<ul>
  <li>The observed effect or relationship in the sample data reflects sampling error or very likely occurred by chance. Thus, no true effect or relationship exists in the population.</li>
  <li>The observed effect or relationship in the sample data reflects a true effect or relationship in the population. Thus, it is very unlikely to have occurred by chance.</li> 
</ul>

Let's say that a researcher starts with a null hypothesis that there is no relationship between attending lectures and exam anxiety, and collects data from 750 students of NTNU. The researcher must choose a level of significance (such as 0.05) that represents _the proportion of times (that, if the null hypothesis is true), a researcher will mistakenly reject the null hypothesis, or put simply, the probability of rejecting the null hypothesis in the long run (i.e., over several random samples from the population) if the null hypothesis is actually true._

If the null hypothesis is true (that, there is no relationship between attending lectures and exam anxiety), and a researcher mistakenly rejects it (therefore says that, there is a relationship between attending lectures and exam anxiety), this is called making a Type-1 error, and the probability of a researcher making this type of erroneous conclusion is set at 0.05 (as the alpha level).  Thus, the level of significance or alpha can also be understood as the probability of making a Type-1 error, supposing the null hypothesis is true. This is because the level of significance or alpha is the threshold below which the decision to reject the null hypothesis is made. Consequently, supposing that the null hypothesis is true, the probability of rejecting the null hypothesis, thereby making a Type-1 error is the significance level or alpha that was chosen for the hypothesis test. Here, the researcher mistakenly concludes that there is something (or there is an effect or relationship) when there is nothing (no effect or no relationship). There is another error that can be made in hypothesis testing. 

Let's briefly summarize the two types of errors in significance testing:

Suppose the null hypothesis is true:
<ul>
  <li> A Type-1 error occurs when the null hypothesis is rejected.</li>
</ul>

Suppose the null hypothesis is false:
<ul>
  <li> A Type-2 error occurs when the null hypothesis is not rejected.</li> 
</ul>

Going back to our example, if the p-value is less than the level of significance or alpha, the researcher concludes that there is evidence to reject the null hypothesis. For example, if a correlation test shows a very low p-value, say p < 0.05, this means that it is extremely or very unlikely that the results of the correlation test occurred by chance if the null hypothesis was true. _The p-value is the probability of observing the sample data or one that is more extreme, if the null hypothesis was true._ 

When the p-value, or the probability of observing the results given the null hypothesis, is less than the significance level or alpha, the researcher rejects the null hypothesis, and concludes that there is a significant relationship or effect between the variables being tested - that is, the relationship in the sample data reflects true effect or relationship in the population. For example, there is a significant relationship between attending lectures and exam anxiety in NTNU students.

Rejecting the null hypothesis doesn't necessarily 'prove' that the alternative hypothesis is true. It simply means that based on the available evidence - that is, based on the sample data, it is more likely that there is a relationship between attending lectures and exam anxiety than that there isn't. The decision to reject the null hypothesis is based on several factors, including the significance level or alpha, which specifies the maximum probability of falsely rejecting the null hypothesis if it is actually true in the population.  


